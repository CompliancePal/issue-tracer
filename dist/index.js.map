{"version":3,"file":"index.js","sources":["../webpack://typescript-action/./lib/domain/Entity.js","../webpack://typescript-action/./lib/domain/Issue.js","../webpack://typescript-action/./lib/main.js","../webpack://typescript-action/./lib/repo/Issues.js","../webpack://typescript-action/./node_modules/@actions/core/lib/command.js","../webpack://typescript-action/./node_modules/@actions/core/lib/core.js","../webpack://typescript-action/./node_modules/@actions/core/lib/file-command.js","../webpack://typescript-action/./node_modules/@actions/core/lib/utils.js","../webpack://typescript-action/./node_modules/@actions/github/lib/context.js","../webpack://typescript-action/./node_modules/@actions/github/lib/github.js","../webpack://typescript-action/./node_modules/@actions/github/lib/internal/utils.js","../webpack://typescript-action/./node_modules/@actions/github/lib/utils.js","../webpack://typescript-action/./node_modules/@actions/http-client/index.js","../webpack://typescript-action/./node_modules/@actions/http-client/proxy.js","../webpack://typescript-action/./node_modules/@octokit/auth-token/dist-node/index.js","../webpack://typescript-action/./node_modules/@octokit/core/dist-node/index.js","../webpack://typescript-action/./node_modules/@octokit/endpoint/dist-node/index.js","../webpack://typescript-action/./node_modules/@octokit/endpoint/node_modules/is-plain-object/dist/is-plain-object.js","../webpack://typescript-action/./node_modules/@octokit/graphql/dist-node/index.js","../webpack://typescript-action/./node_modules/@octokit/plugin-paginate-rest/dist-node/index.js","../webpack://typescript-action/./node_modules/@octokit/plugin-rest-endpoint-methods/dist-node/index.js","../webpack://typescript-action/./node_modules/@octokit/request-error/dist-node/index.js","../webpack://typescript-action/./node_modules/@octokit/request/dist-node/index.js","../webpack://typescript-action/./node_modules/@octokit/request/node_modules/is-plain-object/dist/is-plain-object.js","../webpack://typescript-action/./node_modules/bail/index.js","../webpack://typescript-action/./node_modules/before-after-hook/index.js","../webpack://typescript-action/./node_modules/before-after-hook/lib/add.js","../webpack://typescript-action/./node_modules/before-after-hook/lib/register.js","../webpack://typescript-action/./node_modules/before-after-hook/lib/remove.js","../webpack://typescript-action/./node_modules/deprecation/dist-node/index.js","../webpack://typescript-action/./node_modules/extend/index.js","../webpack://typescript-action/./node_modules/fault/index.js","../webpack://typescript-action/./node_modules/format/format.js","../webpack://typescript-action/./node_modules/is-plain-obj/index.js","../webpack://typescript-action/./node_modules/longest-streak/index.js","../webpack://typescript-action/./node_modules/mdast-util-from-markdown/dist/index.js","../webpack://typescript-action/./node_modules/mdast-util-from-markdown/index.js","../webpack://typescript-action/./node_modules/mdast-util-frontmatter/from-markdown.js","../webpack://typescript-action/./node_modules/mdast-util-frontmatter/to-markdown.js","../webpack://typescript-action/./node_modules/mdast-util-to-markdown/index.js","../webpack://typescript-action/./node_modules/mdast-util-to-markdown/lib/configure.js","../webpack://typescript-action/./node_modules/mdast-util-to-markdown/lib/handle/blockquote.js","../webpack://typescript-action/./node_modules/mdast-util-to-markdown/lib/handle/break.js","../webpack://typescript-action/./node_modules/mdast-util-to-markdown/lib/handle/code.js","../webpack://typescript-action/./node_modules/mdast-util-to-markdown/lib/handle/definition.js","../webpack://typescript-action/./node_modules/mdast-util-to-markdown/lib/handle/emphasis.js","../webpack://typescript-action/./node_modules/mdast-util-to-markdown/lib/handle/heading.js","../webpack://typescript-action/./node_modules/mdast-util-to-markdown/lib/handle/html.js","../webpack://typescript-action/./node_modules/mdast-util-to-markdown/lib/handle/image-reference.js","../webpack://typescript-action/./node_modules/mdast-util-to-markdown/lib/handle/image.js","../webpack://typescript-action/./node_modules/mdast-util-to-markdown/lib/handle/index.js","../webpack://typescript-action/./node_modules/mdast-util-to-markdown/lib/handle/inline-code.js","../webpack://typescript-action/./node_modules/mdast-util-to-markdown/lib/handle/link-reference.js","../webpack://typescript-action/./node_modules/mdast-util-to-markdown/lib/handle/link.js","../webpack://typescript-action/./node_modules/mdast-util-to-markdown/lib/handle/list-item.js","../webpack://typescript-action/./node_modules/mdast-util-to-markdown/lib/handle/list.js","../webpack://typescript-action/./node_modules/mdast-util-to-markdown/lib/handle/paragraph.js","../webpack://typescript-action/./node_modules/mdast-util-to-markdown/lib/handle/root.js","../webpack://typescript-action/./node_modules/mdast-util-to-markdown/lib/handle/strong.js","../webpack://typescript-action/./node_modules/mdast-util-to-markdown/lib/handle/text.js","../webpack://typescript-action/./node_modules/mdast-util-to-markdown/lib/handle/thematic-break.js","../webpack://typescript-action/./node_modules/mdast-util-to-markdown/lib/index.js","../webpack://typescript-action/./node_modules/mdast-util-to-markdown/lib/join.js","../webpack://typescript-action/./node_modules/mdast-util-to-markdown/lib/unsafe.js","../webpack://typescript-action/./node_modules/mdast-util-to-markdown/lib/util/association.js","../webpack://typescript-action/./node_modules/mdast-util-to-markdown/lib/util/check-bullet.js","../webpack://typescript-action/./node_modules/mdast-util-to-markdown/lib/util/check-emphasis.js","../webpack://typescript-action/./node_modules/mdast-util-to-markdown/lib/util/check-fence.js","../webpack://typescript-action/./node_modules/mdast-util-to-markdown/lib/util/check-list-item-indent.js","../webpack://typescript-action/./node_modules/mdast-util-to-markdown/lib/util/check-quote.js","../webpack://typescript-action/./node_modules/mdast-util-to-markdown/lib/util/check-rule-repeat.js","../webpack://typescript-action/./node_modules/mdast-util-to-markdown/lib/util/check-rule.js","../webpack://typescript-action/./node_modules/mdast-util-to-markdown/lib/util/check-strong.js","../webpack://typescript-action/./node_modules/mdast-util-to-markdown/lib/util/container-flow.js","../webpack://typescript-action/./node_modules/mdast-util-to-markdown/lib/util/container-phrasing.js","../webpack://typescript-action/./node_modules/mdast-util-to-markdown/lib/util/format-code-as-indented.js","../webpack://typescript-action/./node_modules/mdast-util-to-markdown/lib/util/format-heading-as-setext.js","../webpack://typescript-action/./node_modules/mdast-util-to-markdown/lib/util/format-link-as-autolink.js","../webpack://typescript-action/./node_modules/mdast-util-to-markdown/lib/util/indent-lines.js","../webpack://typescript-action/./node_modules/mdast-util-to-markdown/lib/util/pattern-compile.js","../webpack://typescript-action/./node_modules/mdast-util-to-markdown/lib/util/pattern-in-scope.js","../webpack://typescript-action/./node_modules/mdast-util-to-markdown/lib/util/safe.js","../webpack://typescript-action/./node_modules/mdast-util-to-string/index.js","../webpack://typescript-action/./node_modules/micromark-extension-frontmatter/index.js","../webpack://typescript-action/./node_modules/micromark-extension-frontmatter/lib/matters.js","../webpack://typescript-action/./node_modules/micromark-extension-frontmatter/lib/syntax.js","../webpack://typescript-action/./node_modules/micromark/dist/character/ascii-alpha.js","../webpack://typescript-action/./node_modules/micromark/dist/character/ascii-alphanumeric.js","../webpack://typescript-action/./node_modules/micromark/dist/character/ascii-atext.js","../webpack://typescript-action/./node_modules/micromark/dist/character/ascii-control.js","../webpack://typescript-action/./node_modules/micromark/dist/character/ascii-digit.js","../webpack://typescript-action/./node_modules/micromark/dist/character/ascii-hex-digit.js","../webpack://typescript-action/./node_modules/micromark/dist/character/ascii-punctuation.js","../webpack://typescript-action/./node_modules/micromark/dist/character/markdown-line-ending-or-space.js","../webpack://typescript-action/./node_modules/micromark/dist/character/markdown-line-ending.js","../webpack://typescript-action/./node_modules/micromark/dist/character/markdown-space.js","../webpack://typescript-action/./node_modules/micromark/dist/character/unicode-punctuation.js","../webpack://typescript-action/./node_modules/micromark/dist/character/unicode-whitespace.js","../webpack://typescript-action/./node_modules/micromark/dist/constant/assign.js","../webpack://typescript-action/./node_modules/micromark/dist/constant/from-char-code.js","../webpack://typescript-action/./node_modules/micromark/dist/constant/has-own-property.js","../webpack://typescript-action/./node_modules/micromark/dist/constant/html-block-names.js","../webpack://typescript-action/./node_modules/micromark/dist/constant/html-raw-names.js","../webpack://typescript-action/./node_modules/micromark/dist/constant/splice.js","../webpack://typescript-action/./node_modules/micromark/dist/constant/unicode-punctuation-regex.js","../webpack://typescript-action/./node_modules/micromark/dist/constructs.js","../webpack://typescript-action/./node_modules/micromark/dist/initialize/content.js","../webpack://typescript-action/./node_modules/micromark/dist/initialize/document.js","../webpack://typescript-action/./node_modules/micromark/dist/initialize/flow.js","../webpack://typescript-action/./node_modules/micromark/dist/initialize/text.js","../webpack://typescript-action/./node_modules/micromark/dist/parse.js","../webpack://typescript-action/./node_modules/micromark/dist/postprocess.js","../webpack://typescript-action/./node_modules/micromark/dist/preprocess.js","../webpack://typescript-action/./node_modules/micromark/dist/tokenize/attention.js","../webpack://typescript-action/./node_modules/micromark/dist/tokenize/autolink.js","../webpack://typescript-action/./node_modules/micromark/dist/tokenize/block-quote.js","../webpack://typescript-action/./node_modules/micromark/dist/tokenize/character-escape.js","../webpack://typescript-action/./node_modules/micromark/dist/tokenize/character-reference.js","../webpack://typescript-action/./node_modules/micromark/dist/tokenize/code-fenced.js","../webpack://typescript-action/./node_modules/micromark/dist/tokenize/code-indented.js","../webpack://typescript-action/./node_modules/micromark/dist/tokenize/code-text.js","../webpack://typescript-action/./node_modules/micromark/dist/tokenize/content.js","../webpack://typescript-action/./node_modules/micromark/dist/tokenize/definition.js","../webpack://typescript-action/./node_modules/micromark/dist/tokenize/factory-destination.js","../webpack://typescript-action/./node_modules/micromark/dist/tokenize/factory-label.js","../webpack://typescript-action/./node_modules/micromark/dist/tokenize/factory-space.js","../webpack://typescript-action/./node_modules/micromark/dist/tokenize/factory-title.js","../webpack://typescript-action/./node_modules/micromark/dist/tokenize/factory-whitespace.js","../webpack://typescript-action/./node_modules/micromark/dist/tokenize/hard-break-escape.js","../webpack://typescript-action/./node_modules/micromark/dist/tokenize/heading-atx.js","../webpack://typescript-action/./node_modules/micromark/dist/tokenize/html-flow.js","../webpack://typescript-action/./node_modules/micromark/dist/tokenize/html-text.js","../webpack://typescript-action/./node_modules/micromark/dist/tokenize/label-end.js","../webpack://typescript-action/./node_modules/micromark/dist/tokenize/label-start-image.js","../webpack://typescript-action/./node_modules/micromark/dist/tokenize/label-start-link.js","../webpack://typescript-action/./node_modules/micromark/dist/tokenize/line-ending.js","../webpack://typescript-action/./node_modules/micromark/dist/tokenize/list.js","../webpack://typescript-action/./node_modules/micromark/dist/tokenize/partial-blank-line.js","../webpack://typescript-action/./node_modules/micromark/dist/tokenize/setext-underline.js","../webpack://typescript-action/./node_modules/micromark/dist/tokenize/thematic-break.js","../webpack://typescript-action/./node_modules/micromark/dist/util/chunked-push.js","../webpack://typescript-action/./node_modules/micromark/dist/util/chunked-splice.js","../webpack://typescript-action/./node_modules/micromark/dist/util/classify-character.js","../webpack://typescript-action/./node_modules/micromark/dist/util/combine-extensions.js","../webpack://typescript-action/./node_modules/micromark/dist/util/create-tokenizer.js","../webpack://typescript-action/./node_modules/micromark/dist/util/miniflat.js","../webpack://typescript-action/./node_modules/micromark/dist/util/move-point.js","../webpack://typescript-action/./node_modules/micromark/dist/util/normalize-identifier.js","../webpack://typescript-action/./node_modules/micromark/dist/util/prefix-size.js","../webpack://typescript-action/./node_modules/micromark/dist/util/regex-check.js","../webpack://typescript-action/./node_modules/micromark/dist/util/resolve-all.js","../webpack://typescript-action/./node_modules/micromark/dist/util/safe-from-int.js","../webpack://typescript-action/./node_modules/micromark/dist/util/serialize-chunks.js","../webpack://typescript-action/./node_modules/micromark/dist/util/shallow.js","../webpack://typescript-action/./node_modules/micromark/dist/util/size-chunks.js","../webpack://typescript-action/./node_modules/micromark/dist/util/slice-chunks.js","../webpack://typescript-action/./node_modules/micromark/dist/util/subtokenize.js","../webpack://typescript-action/./node_modules/node-fetch/lib/index.js","../webpack://typescript-action/./node_modules/once/once.js","../webpack://typescript-action/./node_modules/parse-entities/decode-entity.js","../webpack://typescript-action/./node_modules/remark-frontmatter/index.js","../webpack://typescript-action/./node_modules/remark-parse/index.js","../webpack://typescript-action/./node_modules/remark-stringify/index.js","../webpack://typescript-action/./node_modules/repeat-string/index.js","../webpack://typescript-action/./node_modules/trough/index.js","../webpack://typescript-action/./node_modules/trough/wrap.js","../webpack://typescript-action/./node_modules/tunnel/index.js","../webpack://typescript-action/./node_modules/tunnel/lib/tunnel.js","../webpack://typescript-action/./node_modules/unified/index.js","../webpack://typescript-action/./node_modules/unified/node_modules/is-buffer/index.js","../webpack://typescript-action/./node_modules/unist-util-is/convert.js","../webpack://typescript-action/./node_modules/unist-util-stringify-position/index.js","../webpack://typescript-action/./node_modules/unist-util-visit-parents/color.js","../webpack://typescript-action/./node_modules/unist-util-visit-parents/index.js","../webpack://typescript-action/./node_modules/unist-util-visit/index.js","../webpack://typescript-action/./node_modules/universal-user-agent/dist-node/index.js","../webpack://typescript-action/./node_modules/vfile-message/index.js","../webpack://typescript-action/./node_modules/vfile/index.js","../webpack://typescript-action/./node_modules/vfile/lib/core.js","../webpack://typescript-action/./node_modules/vfile/lib/index.js","../webpack://typescript-action/./node_modules/vfile/lib/minpath.js","../webpack://typescript-action/./node_modules/vfile/lib/minproc.js","../webpack://typescript-action/./node_modules/vfile/node_modules/is-buffer/index.js","../webpack://typescript-action/./node_modules/wrappy/wrappy.js","../webpack://typescript-action/./node_modules/yaml/dist/Document-2cf6b08c.js","../webpack://typescript-action/./node_modules/yaml/dist/PlainValue-ec8e588e.js","../webpack://typescript-action/./node_modules/yaml/dist/Schema-42e9705c.js","../webpack://typescript-action/./node_modules/yaml/dist/index.js","../webpack://typescript-action/./node_modules/yaml/dist/parse-cst.js","../webpack://typescript-action/./node_modules/yaml/dist/resolveSeq-4a68b39b.js","../webpack://typescript-action/./node_modules/yaml/dist/warnings-39684f17.js","../webpack://typescript-action/./node_modules/yaml/index.js","../webpack://typescript-action/./node_modules/zwitch/index.js","../webpack://typescript-action/./node_modules/@vercel/ncc/dist/ncc/@@notfound.js","../webpack://typescript-action/external \"assert\"","../webpack://typescript-action/external \"events\"","../webpack://typescript-action/external \"fs\"","../webpack://typescript-action/external \"http\"","../webpack://typescript-action/external \"https\"","../webpack://typescript-action/external \"net\"","../webpack://typescript-action/external \"os\"","../webpack://typescript-action/external \"path\"","../webpack://typescript-action/external \"stream\"","../webpack://typescript-action/external \"tls\"","../webpack://typescript-action/external \"url\"","../webpack://typescript-action/external \"util\"","../webpack://typescript-action/external \"zlib\"","../webpack://typescript-action/webpack/bootstrap","../webpack://typescript-action/webpack/runtime/compat","../webpack://typescript-action/webpack/startup"],"sourcesContent":["\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.Entity = void 0;\nclass Entity {\n    constructor(props) {\n        this.props = props;\n    }\n}\nexports.Entity = Entity;\n","\"use strict\";\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.Issue = void 0;\nconst unified_1 = __importDefault(require(\"unified\"));\nconst remark_parse_1 = __importDefault(require(\"remark-parse\"));\nconst remark_frontmatter_1 = __importDefault(require(\"remark-frontmatter\"));\nconst remark_stringify_1 = __importDefault(require(\"remark-stringify\"));\nconst yaml_1 = __importDefault(require(\"yaml\"));\nconst unist_util_visit_1 = __importDefault(require(\"unist-util-visit\"));\nconst Entity_1 = require(\"./Entity\");\nclass Issue extends Entity_1.Entity {\n    constructor(issue, owner, repo) {\n        super(issue);\n        this.props = issue;\n        this.owner = owner;\n        this.repo = repo;\n        this.partOf = this.detectsPartOf();\n    }\n    get body() {\n        return this.props.body;\n    }\n    set body(content) {\n        this.props.body = content;\n    }\n    get labels() {\n        return Array.from(this.props.labels || []).map(label => label.name);\n    }\n    get id() {\n        return this.props.id;\n    }\n    get number() {\n        return this.props.number;\n    }\n    get isClosed() {\n        return this.props.state === 'closed';\n    }\n    get title() {\n        return this.props.title;\n    }\n    hasParent() {\n        return this.partOf !== undefined;\n    }\n    static fromEventPayload(event) {\n        const owner = event.repository.owner.login;\n        const repo = event.repository.name;\n        return new Issue(event.issue, owner, repo);\n    }\n    static fromApiPayload(payload, owner, repo) {\n        return new Issue(payload, owner, repo);\n    }\n    static parsePartOf(raw, owner, repo) {\n        const re = /^(([-\\w]+)\\/([-\\w]+))?#([0-9]+)$/;\n        const res = raw.match(re);\n        return res\n            ? {\n                owner: res[2] ? res[2] : owner,\n                repo: res[3] ? res[3] : repo,\n                issue_number: parseInt(res[4])\n            }\n            : undefined;\n    }\n    detectsPartOf() {\n        let partOf;\n        unified_1.default()\n            .use(remark_parse_1.default)\n            .use(remark_frontmatter_1.default, [\n            {\n                type: 'yaml',\n                marker: {\n                    open: '-',\n                    close: '-'\n                },\n                anywhere: true\n            }\n        ])\n            .use(() => {\n            return tree => {\n                unist_util_visit_1.default(tree, 'yaml', node => {\n                    const patched = node.value.replace(/partOf: (#[0-9]*)/, 'partOf: \"$1\"');\n                    node.data = yaml_1.default.parse(patched);\n                });\n            };\n        })\n            .use(() => {\n            return tree => {\n                unist_util_visit_1.default(tree, 'yaml', node => {\n                    if (node.data && node.data.partOf) {\n                        partOf = Issue.parsePartOf(node.data.partOf, this.owner, this.repo);\n                    }\n                });\n            };\n        })\n            .use(remark_stringify_1.default)\n            .processSync(this.props.body);\n        return partOf;\n    }\n}\nexports.Issue = Issue;\n","\"use strict\";\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst core = __importStar(require(\"@actions/core\"));\nconst github = __importStar(require(\"@actions/github\"));\nconst Issue_1 = require(\"./domain/Issue\");\nconst Issues_1 = require(\"./repo/Issues\");\nconst ghToken = process.env.GITHUB_TOKEN;\nfunction run() {\n    return __awaiter(this, void 0, void 0, function* () {\n        if (ghToken === undefined) {\n            core.setFailed(`GITHUB_TOKEN not provided`);\n            return;\n        }\n        try {\n            let issue, repo, relatedIssue;\n            switch (github.context.payload.action) {\n                case 'edited':\n                case 'opened':\n                case 'closed':\n                case 'reopened':\n                    issue = Issue_1.Issue.fromEventPayload(github.context.payload);\n                    core.info(`Issue ${issue.number} parsed successfuly`);\n                    if (issue.partOf === undefined) {\n                        core.info('Issue is not partOf other issues');\n                        return;\n                    }\n                    // TODO: get the related issue using the repo\n                    repo = new Issues_1.IssuesRepo(ghToken);\n                    relatedIssue = yield repo.get(issue.partOf);\n                    if (relatedIssue === undefined) {\n                        core.setFailed(`Action could not find the related issue `);\n                        return;\n                    }\n                    core.info(`Related issue ${relatedIssue.number} found sucessfuly`);\n                    relatedIssue.body = `## Traceability\\n\\n### Related issues\\n<!-- Section created by CompliancePal. Do not edit -->\\n\\n- [${issue.isClosed ? 'x' : ' '}] ${issue.title} (#${issue.number})`;\n                    // TODO: update the related issues section with this issue\n                    yield repo.save(relatedIssue);\n                    core.info(`Related issue ${relatedIssue.number} updated sucessfuly`);\n                    core.setOutput('partOf', issue.partOf);\n                    break;\n                default:\n            }\n        }\n        catch (error) {\n            core.setFailed(error.message);\n        }\n    });\n}\nrun();\n","\"use strict\";\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.IssuesRepo = void 0;\nconst github = __importStar(require(\"@actions/github\"));\nconst Issue_1 = require(\"../domain/Issue\");\nclass IssuesRepo {\n    constructor(token) {\n        this.token = token;\n    }\n    get({ owner, repo, issue_number }) {\n        return __awaiter(this, void 0, void 0, function* () {\n            try {\n                const gh = github.getOctokit(this.token);\n                const response = yield gh.issues.get({\n                    owner,\n                    repo,\n                    issue_number\n                });\n                return Issue_1.Issue.fromApiPayload(response.data, owner, repo);\n            }\n            catch (error) {\n                return;\n            }\n        });\n    }\n    save(issue) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const gh = github.getOctokit(this.token);\n            yield gh.issues.update({\n                owner: issue.owner,\n                repo: issue.repo,\n                issue_number: issue.number,\n                body: issue.body\n            });\n        });\n    }\n}\nexports.IssuesRepo = IssuesRepo;\n","\"use strict\";\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (Object.hasOwnProperty.call(mod, k)) result[k] = mod[k];\n    result[\"default\"] = mod;\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst os = __importStar(require(\"os\"));\nconst utils_1 = require(\"./utils\");\n/**\n * Commands\n *\n * Command Format:\n *   ::name key=value,key=value::message\n *\n * Examples:\n *   ::warning::This is the message\n *   ::set-env name=MY_VAR::some value\n */\nfunction issueCommand(command, properties, message) {\n    const cmd = new Command(command, properties, message);\n    process.stdout.write(cmd.toString() + os.EOL);\n}\nexports.issueCommand = issueCommand;\nfunction issue(name, message = '') {\n    issueCommand(name, {}, message);\n}\nexports.issue = issue;\nconst CMD_STRING = '::';\nclass Command {\n    constructor(command, properties, message) {\n        if (!command) {\n            command = 'missing.command';\n        }\n        this.command = command;\n        this.properties = properties;\n        this.message = message;\n    }\n    toString() {\n        let cmdStr = CMD_STRING + this.command;\n        if (this.properties && Object.keys(this.properties).length > 0) {\n            cmdStr += ' ';\n            let first = true;\n            for (const key in this.properties) {\n                if (this.properties.hasOwnProperty(key)) {\n                    const val = this.properties[key];\n                    if (val) {\n                        if (first) {\n                            first = false;\n                        }\n                        else {\n                            cmdStr += ',';\n                        }\n                        cmdStr += `${key}=${escapeProperty(val)}`;\n                    }\n                }\n            }\n        }\n        cmdStr += `${CMD_STRING}${escapeData(this.message)}`;\n        return cmdStr;\n    }\n}\nfunction escapeData(s) {\n    return utils_1.toCommandValue(s)\n        .replace(/%/g, '%25')\n        .replace(/\\r/g, '%0D')\n        .replace(/\\n/g, '%0A');\n}\nfunction escapeProperty(s) {\n    return utils_1.toCommandValue(s)\n        .replace(/%/g, '%25')\n        .replace(/\\r/g, '%0D')\n        .replace(/\\n/g, '%0A')\n        .replace(/:/g, '%3A')\n        .replace(/,/g, '%2C');\n}\n//# sourceMappingURL=command.js.map","\"use strict\";\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (Object.hasOwnProperty.call(mod, k)) result[k] = mod[k];\n    result[\"default\"] = mod;\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst command_1 = require(\"./command\");\nconst file_command_1 = require(\"./file-command\");\nconst utils_1 = require(\"./utils\");\nconst os = __importStar(require(\"os\"));\nconst path = __importStar(require(\"path\"));\n/**\n * The code to exit an action\n */\nvar ExitCode;\n(function (ExitCode) {\n    /**\n     * A code indicating that the action was successful\n     */\n    ExitCode[ExitCode[\"Success\"] = 0] = \"Success\";\n    /**\n     * A code indicating that the action was a failure\n     */\n    ExitCode[ExitCode[\"Failure\"] = 1] = \"Failure\";\n})(ExitCode = exports.ExitCode || (exports.ExitCode = {}));\n//-----------------------------------------------------------------------\n// Variables\n//-----------------------------------------------------------------------\n/**\n * Sets env variable for this action and future actions in the job\n * @param name the name of the variable to set\n * @param val the value of the variable. Non-string values will be converted to a string via JSON.stringify\n */\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\nfunction exportVariable(name, val) {\n    const convertedVal = utils_1.toCommandValue(val);\n    process.env[name] = convertedVal;\n    const filePath = process.env['GITHUB_ENV'] || '';\n    if (filePath) {\n        const delimiter = '_GitHubActionsFileCommandDelimeter_';\n        const commandValue = `${name}<<${delimiter}${os.EOL}${convertedVal}${os.EOL}${delimiter}`;\n        file_command_1.issueCommand('ENV', commandValue);\n    }\n    else {\n        command_1.issueCommand('set-env', { name }, convertedVal);\n    }\n}\nexports.exportVariable = exportVariable;\n/**\n * Registers a secret which will get masked from logs\n * @param secret value of the secret\n */\nfunction setSecret(secret) {\n    command_1.issueCommand('add-mask', {}, secret);\n}\nexports.setSecret = setSecret;\n/**\n * Prepends inputPath to the PATH (for this action and future actions)\n * @param inputPath\n */\nfunction addPath(inputPath) {\n    const filePath = process.env['GITHUB_PATH'] || '';\n    if (filePath) {\n        file_command_1.issueCommand('PATH', inputPath);\n    }\n    else {\n        command_1.issueCommand('add-path', {}, inputPath);\n    }\n    process.env['PATH'] = `${inputPath}${path.delimiter}${process.env['PATH']}`;\n}\nexports.addPath = addPath;\n/**\n * Gets the value of an input.  The value is also trimmed.\n *\n * @param     name     name of the input to get\n * @param     options  optional. See InputOptions.\n * @returns   string\n */\nfunction getInput(name, options) {\n    const val = process.env[`INPUT_${name.replace(/ /g, '_').toUpperCase()}`] || '';\n    if (options && options.required && !val) {\n        throw new Error(`Input required and not supplied: ${name}`);\n    }\n    return val.trim();\n}\nexports.getInput = getInput;\n/**\n * Sets the value of an output.\n *\n * @param     name     name of the output to set\n * @param     value    value to store. Non-string values will be converted to a string via JSON.stringify\n */\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\nfunction setOutput(name, value) {\n    command_1.issueCommand('set-output', { name }, value);\n}\nexports.setOutput = setOutput;\n/**\n * Enables or disables the echoing of commands into stdout for the rest of the step.\n * Echoing is disabled by default if ACTIONS_STEP_DEBUG is not set.\n *\n */\nfunction setCommandEcho(enabled) {\n    command_1.issue('echo', enabled ? 'on' : 'off');\n}\nexports.setCommandEcho = setCommandEcho;\n//-----------------------------------------------------------------------\n// Results\n//-----------------------------------------------------------------------\n/**\n * Sets the action status to failed.\n * When the action exits it will be with an exit code of 1\n * @param message add error issue message\n */\nfunction setFailed(message) {\n    process.exitCode = ExitCode.Failure;\n    error(message);\n}\nexports.setFailed = setFailed;\n//-----------------------------------------------------------------------\n// Logging Commands\n//-----------------------------------------------------------------------\n/**\n * Gets whether Actions Step Debug is on or not\n */\nfunction isDebug() {\n    return process.env['RUNNER_DEBUG'] === '1';\n}\nexports.isDebug = isDebug;\n/**\n * Writes debug message to user log\n * @param message debug message\n */\nfunction debug(message) {\n    command_1.issueCommand('debug', {}, message);\n}\nexports.debug = debug;\n/**\n * Adds an error issue\n * @param message error issue message. Errors will be converted to string via toString()\n */\nfunction error(message) {\n    command_1.issue('error', message instanceof Error ? message.toString() : message);\n}\nexports.error = error;\n/**\n * Adds an warning issue\n * @param message warning issue message. Errors will be converted to string via toString()\n */\nfunction warning(message) {\n    command_1.issue('warning', message instanceof Error ? message.toString() : message);\n}\nexports.warning = warning;\n/**\n * Writes info to log with console.log.\n * @param message info message\n */\nfunction info(message) {\n    process.stdout.write(message + os.EOL);\n}\nexports.info = info;\n/**\n * Begin an output group.\n *\n * Output until the next `groupEnd` will be foldable in this group\n *\n * @param name The name of the output group\n */\nfunction startGroup(name) {\n    command_1.issue('group', name);\n}\nexports.startGroup = startGroup;\n/**\n * End an output group.\n */\nfunction endGroup() {\n    command_1.issue('endgroup');\n}\nexports.endGroup = endGroup;\n/**\n * Wrap an asynchronous function call in a group.\n *\n * Returns the same type as the function itself.\n *\n * @param name The name of the group\n * @param fn The function to wrap in the group\n */\nfunction group(name, fn) {\n    return __awaiter(this, void 0, void 0, function* () {\n        startGroup(name);\n        let result;\n        try {\n            result = yield fn();\n        }\n        finally {\n            endGroup();\n        }\n        return result;\n    });\n}\nexports.group = group;\n//-----------------------------------------------------------------------\n// Wrapper action state\n//-----------------------------------------------------------------------\n/**\n * Saves state for current action, the state can only be retrieved by this action's post job execution.\n *\n * @param     name     name of the state to store\n * @param     value    value to store. Non-string values will be converted to a string via JSON.stringify\n */\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\nfunction saveState(name, value) {\n    command_1.issueCommand('save-state', { name }, value);\n}\nexports.saveState = saveState;\n/**\n * Gets the value of an state set by this action's main execution.\n *\n * @param     name     name of the state to get\n * @returns   string\n */\nfunction getState(name) {\n    return process.env[`STATE_${name}`] || '';\n}\nexports.getState = getState;\n//# sourceMappingURL=core.js.map","\"use strict\";\n// For internal use, subject to change.\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (Object.hasOwnProperty.call(mod, k)) result[k] = mod[k];\n    result[\"default\"] = mod;\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\n// We use any as a valid input type\n/* eslint-disable @typescript-eslint/no-explicit-any */\nconst fs = __importStar(require(\"fs\"));\nconst os = __importStar(require(\"os\"));\nconst utils_1 = require(\"./utils\");\nfunction issueCommand(command, message) {\n    const filePath = process.env[`GITHUB_${command}`];\n    if (!filePath) {\n        throw new Error(`Unable to find environment variable for file command ${command}`);\n    }\n    if (!fs.existsSync(filePath)) {\n        throw new Error(`Missing file at path: ${filePath}`);\n    }\n    fs.appendFileSync(filePath, `${utils_1.toCommandValue(message)}${os.EOL}`, {\n        encoding: 'utf8'\n    });\n}\nexports.issueCommand = issueCommand;\n//# sourceMappingURL=file-command.js.map","\"use strict\";\n// We use any as a valid input type\n/* eslint-disable @typescript-eslint/no-explicit-any */\nObject.defineProperty(exports, \"__esModule\", { value: true });\n/**\n * Sanitizes an input into a string so it can be passed into issueCommand safely\n * @param input input to sanitize into a string\n */\nfunction toCommandValue(input) {\n    if (input === null || input === undefined) {\n        return '';\n    }\n    else if (typeof input === 'string' || input instanceof String) {\n        return input;\n    }\n    return JSON.stringify(input);\n}\nexports.toCommandValue = toCommandValue;\n//# sourceMappingURL=utils.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.Context = void 0;\nconst fs_1 = require(\"fs\");\nconst os_1 = require(\"os\");\nclass Context {\n    /**\n     * Hydrate the context from the environment\n     */\n    constructor() {\n        this.payload = {};\n        if (process.env.GITHUB_EVENT_PATH) {\n            if (fs_1.existsSync(process.env.GITHUB_EVENT_PATH)) {\n                this.payload = JSON.parse(fs_1.readFileSync(process.env.GITHUB_EVENT_PATH, { encoding: 'utf8' }));\n            }\n            else {\n                const path = process.env.GITHUB_EVENT_PATH;\n                process.stdout.write(`GITHUB_EVENT_PATH ${path} does not exist${os_1.EOL}`);\n            }\n        }\n        this.eventName = process.env.GITHUB_EVENT_NAME;\n        this.sha = process.env.GITHUB_SHA;\n        this.ref = process.env.GITHUB_REF;\n        this.workflow = process.env.GITHUB_WORKFLOW;\n        this.action = process.env.GITHUB_ACTION;\n        this.actor = process.env.GITHUB_ACTOR;\n        this.job = process.env.GITHUB_JOB;\n        this.runNumber = parseInt(process.env.GITHUB_RUN_NUMBER, 10);\n        this.runId = parseInt(process.env.GITHUB_RUN_ID, 10);\n    }\n    get issue() {\n        const payload = this.payload;\n        return Object.assign(Object.assign({}, this.repo), { number: (payload.issue || payload.pull_request || payload).number });\n    }\n    get repo() {\n        if (process.env.GITHUB_REPOSITORY) {\n            const [owner, repo] = process.env.GITHUB_REPOSITORY.split('/');\n            return { owner, repo };\n        }\n        if (this.payload.repository) {\n            return {\n                owner: this.payload.repository.owner.login,\n                repo: this.payload.repository.name\n            };\n        }\n        throw new Error(\"context.repo requires a GITHUB_REPOSITORY environment variable like 'owner/repo'\");\n    }\n}\nexports.Context = Context;\n//# sourceMappingURL=context.js.map","\"use strict\";\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (Object.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.getOctokit = exports.context = void 0;\nconst Context = __importStar(require(\"./context\"));\nconst utils_1 = require(\"./utils\");\nexports.context = new Context.Context();\n/**\n * Returns a hydrated octokit ready to use for GitHub Actions\n *\n * @param     token    the repo PAT or GITHUB_TOKEN\n * @param     options  other options to set\n */\nfunction getOctokit(token, options) {\n    return new utils_1.GitHub(utils_1.getOctokitOptions(token, options));\n}\nexports.getOctokit = getOctokit;\n//# sourceMappingURL=github.js.map","\"use strict\";\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (Object.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.getApiBaseUrl = exports.getProxyAgent = exports.getAuthString = void 0;\nconst httpClient = __importStar(require(\"@actions/http-client\"));\nfunction getAuthString(token, options) {\n    if (!token && !options.auth) {\n        throw new Error('Parameter token or opts.auth is required');\n    }\n    else if (token && options.auth) {\n        throw new Error('Parameters token and opts.auth may not both be specified');\n    }\n    return typeof options.auth === 'string' ? options.auth : `token ${token}`;\n}\nexports.getAuthString = getAuthString;\nfunction getProxyAgent(destinationUrl) {\n    const hc = new httpClient.HttpClient();\n    return hc.getAgent(destinationUrl);\n}\nexports.getProxyAgent = getProxyAgent;\nfunction getApiBaseUrl() {\n    return process.env['GITHUB_API_URL'] || 'https://api.github.com';\n}\nexports.getApiBaseUrl = getApiBaseUrl;\n//# sourceMappingURL=utils.js.map","\"use strict\";\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (Object.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.getOctokitOptions = exports.GitHub = exports.context = void 0;\nconst Context = __importStar(require(\"./context\"));\nconst Utils = __importStar(require(\"./internal/utils\"));\n// octokit + plugins\nconst core_1 = require(\"@octokit/core\");\nconst plugin_rest_endpoint_methods_1 = require(\"@octokit/plugin-rest-endpoint-methods\");\nconst plugin_paginate_rest_1 = require(\"@octokit/plugin-paginate-rest\");\nexports.context = new Context.Context();\nconst baseUrl = Utils.getApiBaseUrl();\nconst defaults = {\n    baseUrl,\n    request: {\n        agent: Utils.getProxyAgent(baseUrl)\n    }\n};\nexports.GitHub = core_1.Octokit.plugin(plugin_rest_endpoint_methods_1.restEndpointMethods, plugin_paginate_rest_1.paginateRest).defaults(defaults);\n/**\n * Convience function to correctly format Octokit Options to pass into the constructor.\n *\n * @param     token    the repo PAT or GITHUB_TOKEN\n * @param     options  other options to set\n */\nfunction getOctokitOptions(token, options) {\n    const opts = Object.assign({}, options || {}); // Shallow clone - don't mutate the object provided by the caller\n    // Auth\n    const auth = Utils.getAuthString(token, opts);\n    if (auth) {\n        opts.auth = auth;\n    }\n    return opts;\n}\nexports.getOctokitOptions = getOctokitOptions;\n//# sourceMappingURL=utils.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst http = require(\"http\");\nconst https = require(\"https\");\nconst pm = require(\"./proxy\");\nlet tunnel;\nvar HttpCodes;\n(function (HttpCodes) {\n    HttpCodes[HttpCodes[\"OK\"] = 200] = \"OK\";\n    HttpCodes[HttpCodes[\"MultipleChoices\"] = 300] = \"MultipleChoices\";\n    HttpCodes[HttpCodes[\"MovedPermanently\"] = 301] = \"MovedPermanently\";\n    HttpCodes[HttpCodes[\"ResourceMoved\"] = 302] = \"ResourceMoved\";\n    HttpCodes[HttpCodes[\"SeeOther\"] = 303] = \"SeeOther\";\n    HttpCodes[HttpCodes[\"NotModified\"] = 304] = \"NotModified\";\n    HttpCodes[HttpCodes[\"UseProxy\"] = 305] = \"UseProxy\";\n    HttpCodes[HttpCodes[\"SwitchProxy\"] = 306] = \"SwitchProxy\";\n    HttpCodes[HttpCodes[\"TemporaryRedirect\"] = 307] = \"TemporaryRedirect\";\n    HttpCodes[HttpCodes[\"PermanentRedirect\"] = 308] = \"PermanentRedirect\";\n    HttpCodes[HttpCodes[\"BadRequest\"] = 400] = \"BadRequest\";\n    HttpCodes[HttpCodes[\"Unauthorized\"] = 401] = \"Unauthorized\";\n    HttpCodes[HttpCodes[\"PaymentRequired\"] = 402] = \"PaymentRequired\";\n    HttpCodes[HttpCodes[\"Forbidden\"] = 403] = \"Forbidden\";\n    HttpCodes[HttpCodes[\"NotFound\"] = 404] = \"NotFound\";\n    HttpCodes[HttpCodes[\"MethodNotAllowed\"] = 405] = \"MethodNotAllowed\";\n    HttpCodes[HttpCodes[\"NotAcceptable\"] = 406] = \"NotAcceptable\";\n    HttpCodes[HttpCodes[\"ProxyAuthenticationRequired\"] = 407] = \"ProxyAuthenticationRequired\";\n    HttpCodes[HttpCodes[\"RequestTimeout\"] = 408] = \"RequestTimeout\";\n    HttpCodes[HttpCodes[\"Conflict\"] = 409] = \"Conflict\";\n    HttpCodes[HttpCodes[\"Gone\"] = 410] = \"Gone\";\n    HttpCodes[HttpCodes[\"TooManyRequests\"] = 429] = \"TooManyRequests\";\n    HttpCodes[HttpCodes[\"InternalServerError\"] = 500] = \"InternalServerError\";\n    HttpCodes[HttpCodes[\"NotImplemented\"] = 501] = \"NotImplemented\";\n    HttpCodes[HttpCodes[\"BadGateway\"] = 502] = \"BadGateway\";\n    HttpCodes[HttpCodes[\"ServiceUnavailable\"] = 503] = \"ServiceUnavailable\";\n    HttpCodes[HttpCodes[\"GatewayTimeout\"] = 504] = \"GatewayTimeout\";\n})(HttpCodes = exports.HttpCodes || (exports.HttpCodes = {}));\nvar Headers;\n(function (Headers) {\n    Headers[\"Accept\"] = \"accept\";\n    Headers[\"ContentType\"] = \"content-type\";\n})(Headers = exports.Headers || (exports.Headers = {}));\nvar MediaTypes;\n(function (MediaTypes) {\n    MediaTypes[\"ApplicationJson\"] = \"application/json\";\n})(MediaTypes = exports.MediaTypes || (exports.MediaTypes = {}));\n/**\n * Returns the proxy URL, depending upon the supplied url and proxy environment variables.\n * @param serverUrl  The server URL where the request will be sent. For example, https://api.github.com\n */\nfunction getProxyUrl(serverUrl) {\n    let proxyUrl = pm.getProxyUrl(new URL(serverUrl));\n    return proxyUrl ? proxyUrl.href : '';\n}\nexports.getProxyUrl = getProxyUrl;\nconst HttpRedirectCodes = [\n    HttpCodes.MovedPermanently,\n    HttpCodes.ResourceMoved,\n    HttpCodes.SeeOther,\n    HttpCodes.TemporaryRedirect,\n    HttpCodes.PermanentRedirect\n];\nconst HttpResponseRetryCodes = [\n    HttpCodes.BadGateway,\n    HttpCodes.ServiceUnavailable,\n    HttpCodes.GatewayTimeout\n];\nconst RetryableHttpVerbs = ['OPTIONS', 'GET', 'DELETE', 'HEAD'];\nconst ExponentialBackoffCeiling = 10;\nconst ExponentialBackoffTimeSlice = 5;\nclass HttpClientError extends Error {\n    constructor(message, statusCode) {\n        super(message);\n        this.name = 'HttpClientError';\n        this.statusCode = statusCode;\n        Object.setPrototypeOf(this, HttpClientError.prototype);\n    }\n}\nexports.HttpClientError = HttpClientError;\nclass HttpClientResponse {\n    constructor(message) {\n        this.message = message;\n    }\n    readBody() {\n        return new Promise(async (resolve, reject) => {\n            let output = Buffer.alloc(0);\n            this.message.on('data', (chunk) => {\n                output = Buffer.concat([output, chunk]);\n            });\n            this.message.on('end', () => {\n                resolve(output.toString());\n            });\n        });\n    }\n}\nexports.HttpClientResponse = HttpClientResponse;\nfunction isHttps(requestUrl) {\n    let parsedUrl = new URL(requestUrl);\n    return parsedUrl.protocol === 'https:';\n}\nexports.isHttps = isHttps;\nclass HttpClient {\n    constructor(userAgent, handlers, requestOptions) {\n        this._ignoreSslError = false;\n        this._allowRedirects = true;\n        this._allowRedirectDowngrade = false;\n        this._maxRedirects = 50;\n        this._allowRetries = false;\n        this._maxRetries = 1;\n        this._keepAlive = false;\n        this._disposed = false;\n        this.userAgent = userAgent;\n        this.handlers = handlers || [];\n        this.requestOptions = requestOptions;\n        if (requestOptions) {\n            if (requestOptions.ignoreSslError != null) {\n                this._ignoreSslError = requestOptions.ignoreSslError;\n            }\n            this._socketTimeout = requestOptions.socketTimeout;\n            if (requestOptions.allowRedirects != null) {\n                this._allowRedirects = requestOptions.allowRedirects;\n            }\n            if (requestOptions.allowRedirectDowngrade != null) {\n                this._allowRedirectDowngrade = requestOptions.allowRedirectDowngrade;\n            }\n            if (requestOptions.maxRedirects != null) {\n                this._maxRedirects = Math.max(requestOptions.maxRedirects, 0);\n            }\n            if (requestOptions.keepAlive != null) {\n                this._keepAlive = requestOptions.keepAlive;\n            }\n            if (requestOptions.allowRetries != null) {\n                this._allowRetries = requestOptions.allowRetries;\n            }\n            if (requestOptions.maxRetries != null) {\n                this._maxRetries = requestOptions.maxRetries;\n            }\n        }\n    }\n    options(requestUrl, additionalHeaders) {\n        return this.request('OPTIONS', requestUrl, null, additionalHeaders || {});\n    }\n    get(requestUrl, additionalHeaders) {\n        return this.request('GET', requestUrl, null, additionalHeaders || {});\n    }\n    del(requestUrl, additionalHeaders) {\n        return this.request('DELETE', requestUrl, null, additionalHeaders || {});\n    }\n    post(requestUrl, data, additionalHeaders) {\n        return this.request('POST', requestUrl, data, additionalHeaders || {});\n    }\n    patch(requestUrl, data, additionalHeaders) {\n        return this.request('PATCH', requestUrl, data, additionalHeaders || {});\n    }\n    put(requestUrl, data, additionalHeaders) {\n        return this.request('PUT', requestUrl, data, additionalHeaders || {});\n    }\n    head(requestUrl, additionalHeaders) {\n        return this.request('HEAD', requestUrl, null, additionalHeaders || {});\n    }\n    sendStream(verb, requestUrl, stream, additionalHeaders) {\n        return this.request(verb, requestUrl, stream, additionalHeaders);\n    }\n    /**\n     * Gets a typed object from an endpoint\n     * Be aware that not found returns a null.  Other errors (4xx, 5xx) reject the promise\n     */\n    async getJson(requestUrl, additionalHeaders = {}) {\n        additionalHeaders[Headers.Accept] = this._getExistingOrDefaultHeader(additionalHeaders, Headers.Accept, MediaTypes.ApplicationJson);\n        let res = await this.get(requestUrl, additionalHeaders);\n        return this._processResponse(res, this.requestOptions);\n    }\n    async postJson(requestUrl, obj, additionalHeaders = {}) {\n        let data = JSON.stringify(obj, null, 2);\n        additionalHeaders[Headers.Accept] = this._getExistingOrDefaultHeader(additionalHeaders, Headers.Accept, MediaTypes.ApplicationJson);\n        additionalHeaders[Headers.ContentType] = this._getExistingOrDefaultHeader(additionalHeaders, Headers.ContentType, MediaTypes.ApplicationJson);\n        let res = await this.post(requestUrl, data, additionalHeaders);\n        return this._processResponse(res, this.requestOptions);\n    }\n    async putJson(requestUrl, obj, additionalHeaders = {}) {\n        let data = JSON.stringify(obj, null, 2);\n        additionalHeaders[Headers.Accept] = this._getExistingOrDefaultHeader(additionalHeaders, Headers.Accept, MediaTypes.ApplicationJson);\n        additionalHeaders[Headers.ContentType] = this._getExistingOrDefaultHeader(additionalHeaders, Headers.ContentType, MediaTypes.ApplicationJson);\n        let res = await this.put(requestUrl, data, additionalHeaders);\n        return this._processResponse(res, this.requestOptions);\n    }\n    async patchJson(requestUrl, obj, additionalHeaders = {}) {\n        let data = JSON.stringify(obj, null, 2);\n        additionalHeaders[Headers.Accept] = this._getExistingOrDefaultHeader(additionalHeaders, Headers.Accept, MediaTypes.ApplicationJson);\n        additionalHeaders[Headers.ContentType] = this._getExistingOrDefaultHeader(additionalHeaders, Headers.ContentType, MediaTypes.ApplicationJson);\n        let res = await this.patch(requestUrl, data, additionalHeaders);\n        return this._processResponse(res, this.requestOptions);\n    }\n    /**\n     * Makes a raw http request.\n     * All other methods such as get, post, patch, and request ultimately call this.\n     * Prefer get, del, post and patch\n     */\n    async request(verb, requestUrl, data, headers) {\n        if (this._disposed) {\n            throw new Error('Client has already been disposed.');\n        }\n        let parsedUrl = new URL(requestUrl);\n        let info = this._prepareRequest(verb, parsedUrl, headers);\n        // Only perform retries on reads since writes may not be idempotent.\n        let maxTries = this._allowRetries && RetryableHttpVerbs.indexOf(verb) != -1\n            ? this._maxRetries + 1\n            : 1;\n        let numTries = 0;\n        let response;\n        while (numTries < maxTries) {\n            response = await this.requestRaw(info, data);\n            // Check if it's an authentication challenge\n            if (response &&\n                response.message &&\n                response.message.statusCode === HttpCodes.Unauthorized) {\n                let authenticationHandler;\n                for (let i = 0; i < this.handlers.length; i++) {\n                    if (this.handlers[i].canHandleAuthentication(response)) {\n                        authenticationHandler = this.handlers[i];\n                        break;\n                    }\n                }\n                if (authenticationHandler) {\n                    return authenticationHandler.handleAuthentication(this, info, data);\n                }\n                else {\n                    // We have received an unauthorized response but have no handlers to handle it.\n                    // Let the response return to the caller.\n                    return response;\n                }\n            }\n            let redirectsRemaining = this._maxRedirects;\n            while (HttpRedirectCodes.indexOf(response.message.statusCode) != -1 &&\n                this._allowRedirects &&\n                redirectsRemaining > 0) {\n                const redirectUrl = response.message.headers['location'];\n                if (!redirectUrl) {\n                    // if there's no location to redirect to, we won't\n                    break;\n                }\n                let parsedRedirectUrl = new URL(redirectUrl);\n                if (parsedUrl.protocol == 'https:' &&\n                    parsedUrl.protocol != parsedRedirectUrl.protocol &&\n                    !this._allowRedirectDowngrade) {\n                    throw new Error('Redirect from HTTPS to HTTP protocol. This downgrade is not allowed for security reasons. If you want to allow this behavior, set the allowRedirectDowngrade option to true.');\n                }\n                // we need to finish reading the response before reassigning response\n                // which will leak the open socket.\n                await response.readBody();\n                // strip authorization header if redirected to a different hostname\n                if (parsedRedirectUrl.hostname !== parsedUrl.hostname) {\n                    for (let header in headers) {\n                        // header names are case insensitive\n                        if (header.toLowerCase() === 'authorization') {\n                            delete headers[header];\n                        }\n                    }\n                }\n                // let's make the request with the new redirectUrl\n                info = this._prepareRequest(verb, parsedRedirectUrl, headers);\n                response = await this.requestRaw(info, data);\n                redirectsRemaining--;\n            }\n            if (HttpResponseRetryCodes.indexOf(response.message.statusCode) == -1) {\n                // If not a retry code, return immediately instead of retrying\n                return response;\n            }\n            numTries += 1;\n            if (numTries < maxTries) {\n                await response.readBody();\n                await this._performExponentialBackoff(numTries);\n            }\n        }\n        return response;\n    }\n    /**\n     * Needs to be called if keepAlive is set to true in request options.\n     */\n    dispose() {\n        if (this._agent) {\n            this._agent.destroy();\n        }\n        this._disposed = true;\n    }\n    /**\n     * Raw request.\n     * @param info\n     * @param data\n     */\n    requestRaw(info, data) {\n        return new Promise((resolve, reject) => {\n            let callbackForResult = function (err, res) {\n                if (err) {\n                    reject(err);\n                }\n                resolve(res);\n            };\n            this.requestRawWithCallback(info, data, callbackForResult);\n        });\n    }\n    /**\n     * Raw request with callback.\n     * @param info\n     * @param data\n     * @param onResult\n     */\n    requestRawWithCallback(info, data, onResult) {\n        let socket;\n        if (typeof data === 'string') {\n            info.options.headers['Content-Length'] = Buffer.byteLength(data, 'utf8');\n        }\n        let callbackCalled = false;\n        let handleResult = (err, res) => {\n            if (!callbackCalled) {\n                callbackCalled = true;\n                onResult(err, res);\n            }\n        };\n        let req = info.httpModule.request(info.options, (msg) => {\n            let res = new HttpClientResponse(msg);\n            handleResult(null, res);\n        });\n        req.on('socket', sock => {\n            socket = sock;\n        });\n        // If we ever get disconnected, we want the socket to timeout eventually\n        req.setTimeout(this._socketTimeout || 3 * 60000, () => {\n            if (socket) {\n                socket.end();\n            }\n            handleResult(new Error('Request timeout: ' + info.options.path), null);\n        });\n        req.on('error', function (err) {\n            // err has statusCode property\n            // res should have headers\n            handleResult(err, null);\n        });\n        if (data && typeof data === 'string') {\n            req.write(data, 'utf8');\n        }\n        if (data && typeof data !== 'string') {\n            data.on('close', function () {\n                req.end();\n            });\n            data.pipe(req);\n        }\n        else {\n            req.end();\n        }\n    }\n    /**\n     * Gets an http agent. This function is useful when you need an http agent that handles\n     * routing through a proxy server - depending upon the url and proxy environment variables.\n     * @param serverUrl  The server URL where the request will be sent. For example, https://api.github.com\n     */\n    getAgent(serverUrl) {\n        let parsedUrl = new URL(serverUrl);\n        return this._getAgent(parsedUrl);\n    }\n    _prepareRequest(method, requestUrl, headers) {\n        const info = {};\n        info.parsedUrl = requestUrl;\n        const usingSsl = info.parsedUrl.protocol === 'https:';\n        info.httpModule = usingSsl ? https : http;\n        const defaultPort = usingSsl ? 443 : 80;\n        info.options = {};\n        info.options.host = info.parsedUrl.hostname;\n        info.options.port = info.parsedUrl.port\n            ? parseInt(info.parsedUrl.port)\n            : defaultPort;\n        info.options.path =\n            (info.parsedUrl.pathname || '') + (info.parsedUrl.search || '');\n        info.options.method = method;\n        info.options.headers = this._mergeHeaders(headers);\n        if (this.userAgent != null) {\n            info.options.headers['user-agent'] = this.userAgent;\n        }\n        info.options.agent = this._getAgent(info.parsedUrl);\n        // gives handlers an opportunity to participate\n        if (this.handlers) {\n            this.handlers.forEach(handler => {\n                handler.prepareRequest(info.options);\n            });\n        }\n        return info;\n    }\n    _mergeHeaders(headers) {\n        const lowercaseKeys = obj => Object.keys(obj).reduce((c, k) => ((c[k.toLowerCase()] = obj[k]), c), {});\n        if (this.requestOptions && this.requestOptions.headers) {\n            return Object.assign({}, lowercaseKeys(this.requestOptions.headers), lowercaseKeys(headers));\n        }\n        return lowercaseKeys(headers || {});\n    }\n    _getExistingOrDefaultHeader(additionalHeaders, header, _default) {\n        const lowercaseKeys = obj => Object.keys(obj).reduce((c, k) => ((c[k.toLowerCase()] = obj[k]), c), {});\n        let clientHeader;\n        if (this.requestOptions && this.requestOptions.headers) {\n            clientHeader = lowercaseKeys(this.requestOptions.headers)[header];\n        }\n        return additionalHeaders[header] || clientHeader || _default;\n    }\n    _getAgent(parsedUrl) {\n        let agent;\n        let proxyUrl = pm.getProxyUrl(parsedUrl);\n        let useProxy = proxyUrl && proxyUrl.hostname;\n        if (this._keepAlive && useProxy) {\n            agent = this._proxyAgent;\n        }\n        if (this._keepAlive && !useProxy) {\n            agent = this._agent;\n        }\n        // if agent is already assigned use that agent.\n        if (!!agent) {\n            return agent;\n        }\n        const usingSsl = parsedUrl.protocol === 'https:';\n        let maxSockets = 100;\n        if (!!this.requestOptions) {\n            maxSockets = this.requestOptions.maxSockets || http.globalAgent.maxSockets;\n        }\n        if (useProxy) {\n            // If using proxy, need tunnel\n            if (!tunnel) {\n                tunnel = require('tunnel');\n            }\n            const agentOptions = {\n                maxSockets: maxSockets,\n                keepAlive: this._keepAlive,\n                proxy: {\n                    proxyAuth: `${proxyUrl.username}:${proxyUrl.password}`,\n                    host: proxyUrl.hostname,\n                    port: proxyUrl.port\n                }\n            };\n            let tunnelAgent;\n            const overHttps = proxyUrl.protocol === 'https:';\n            if (usingSsl) {\n                tunnelAgent = overHttps ? tunnel.httpsOverHttps : tunnel.httpsOverHttp;\n            }\n            else {\n                tunnelAgent = overHttps ? tunnel.httpOverHttps : tunnel.httpOverHttp;\n            }\n            agent = tunnelAgent(agentOptions);\n            this._proxyAgent = agent;\n        }\n        // if reusing agent across request and tunneling agent isn't assigned create a new agent\n        if (this._keepAlive && !agent) {\n            const options = { keepAlive: this._keepAlive, maxSockets: maxSockets };\n            agent = usingSsl ? new https.Agent(options) : new http.Agent(options);\n            this._agent = agent;\n        }\n        // if not using private agent and tunnel agent isn't setup then use global agent\n        if (!agent) {\n            agent = usingSsl ? https.globalAgent : http.globalAgent;\n        }\n        if (usingSsl && this._ignoreSslError) {\n            // we don't want to set NODE_TLS_REJECT_UNAUTHORIZED=0 since that will affect request for entire process\n            // http.RequestOptions doesn't expose a way to modify RequestOptions.agent.options\n            // we have to cast it to any and change it directly\n            agent.options = Object.assign(agent.options || {}, {\n                rejectUnauthorized: false\n            });\n        }\n        return agent;\n    }\n    _performExponentialBackoff(retryNumber) {\n        retryNumber = Math.min(ExponentialBackoffCeiling, retryNumber);\n        const ms = ExponentialBackoffTimeSlice * Math.pow(2, retryNumber);\n        return new Promise(resolve => setTimeout(() => resolve(), ms));\n    }\n    static dateTimeDeserializer(key, value) {\n        if (typeof value === 'string') {\n            let a = new Date(value);\n            if (!isNaN(a.valueOf())) {\n                return a;\n            }\n        }\n        return value;\n    }\n    async _processResponse(res, options) {\n        return new Promise(async (resolve, reject) => {\n            const statusCode = res.message.statusCode;\n            const response = {\n                statusCode: statusCode,\n                result: null,\n                headers: {}\n            };\n            // not found leads to null obj returned\n            if (statusCode == HttpCodes.NotFound) {\n                resolve(response);\n            }\n            let obj;\n            let contents;\n            // get the result from the body\n            try {\n                contents = await res.readBody();\n                if (contents && contents.length > 0) {\n                    if (options && options.deserializeDates) {\n                        obj = JSON.parse(contents, HttpClient.dateTimeDeserializer);\n                    }\n                    else {\n                        obj = JSON.parse(contents);\n                    }\n                    response.result = obj;\n                }\n                response.headers = res.message.headers;\n            }\n            catch (err) {\n                // Invalid resource (contents not json);  leaving result obj null\n            }\n            // note that 3xx redirects are handled by the http layer.\n            if (statusCode > 299) {\n                let msg;\n                // if exception/error in body, attempt to get better error\n                if (obj && obj.message) {\n                    msg = obj.message;\n                }\n                else if (contents && contents.length > 0) {\n                    // it may be the case that the exception is in the body message as string\n                    msg = contents;\n                }\n                else {\n                    msg = 'Failed request: (' + statusCode + ')';\n                }\n                let err = new HttpClientError(msg, statusCode);\n                err.result = response.result;\n                reject(err);\n            }\n            else {\n                resolve(response);\n            }\n        });\n    }\n}\nexports.HttpClient = HttpClient;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nfunction getProxyUrl(reqUrl) {\n    let usingSsl = reqUrl.protocol === 'https:';\n    let proxyUrl;\n    if (checkBypass(reqUrl)) {\n        return proxyUrl;\n    }\n    let proxyVar;\n    if (usingSsl) {\n        proxyVar = process.env['https_proxy'] || process.env['HTTPS_PROXY'];\n    }\n    else {\n        proxyVar = process.env['http_proxy'] || process.env['HTTP_PROXY'];\n    }\n    if (proxyVar) {\n        proxyUrl = new URL(proxyVar);\n    }\n    return proxyUrl;\n}\nexports.getProxyUrl = getProxyUrl;\nfunction checkBypass(reqUrl) {\n    if (!reqUrl.hostname) {\n        return false;\n    }\n    let noProxy = process.env['no_proxy'] || process.env['NO_PROXY'] || '';\n    if (!noProxy) {\n        return false;\n    }\n    // Determine the request port\n    let reqPort;\n    if (reqUrl.port) {\n        reqPort = Number(reqUrl.port);\n    }\n    else if (reqUrl.protocol === 'http:') {\n        reqPort = 80;\n    }\n    else if (reqUrl.protocol === 'https:') {\n        reqPort = 443;\n    }\n    // Format the request hostname and hostname with port\n    let upperReqHosts = [reqUrl.hostname.toUpperCase()];\n    if (typeof reqPort === 'number') {\n        upperReqHosts.push(`${upperReqHosts[0]}:${reqPort}`);\n    }\n    // Compare request host against noproxy\n    for (let upperNoProxyItem of noProxy\n        .split(',')\n        .map(x => x.trim().toUpperCase())\n        .filter(x => x)) {\n        if (upperReqHosts.some(x => x === upperNoProxyItem)) {\n            return true;\n        }\n    }\n    return false;\n}\nexports.checkBypass = checkBypass;\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nasync function auth(token) {\n  const tokenType = token.split(/\\./).length === 3 ? \"app\" : /^v\\d+\\./.test(token) ? \"installation\" : \"oauth\";\n  return {\n    type: \"token\",\n    token: token,\n    tokenType\n  };\n}\n\n/**\n * Prefix token for usage in the Authorization header\n *\n * @param token OAuth token or JSON Web Token\n */\nfunction withAuthorizationPrefix(token) {\n  if (token.split(/\\./).length === 3) {\n    return `bearer ${token}`;\n  }\n\n  return `token ${token}`;\n}\n\nasync function hook(token, request, route, parameters) {\n  const endpoint = request.endpoint.merge(route, parameters);\n  endpoint.headers.authorization = withAuthorizationPrefix(token);\n  return request(endpoint);\n}\n\nconst createTokenAuth = function createTokenAuth(token) {\n  if (!token) {\n    throw new Error(\"[@octokit/auth-token] No token passed to createTokenAuth\");\n  }\n\n  if (typeof token !== \"string\") {\n    throw new Error(\"[@octokit/auth-token] Token passed to createTokenAuth is not a string\");\n  }\n\n  token = token.replace(/^(token|bearer) +/i, \"\");\n  return Object.assign(auth.bind(null, token), {\n    hook: hook.bind(null, token)\n  });\n};\n\nexports.createTokenAuth = createTokenAuth;\n//# sourceMappingURL=index.js.map\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar universalUserAgent = require('universal-user-agent');\nvar beforeAfterHook = require('before-after-hook');\nvar request = require('@octokit/request');\nvar graphql = require('@octokit/graphql');\nvar authToken = require('@octokit/auth-token');\n\nfunction _objectWithoutPropertiesLoose(source, excluded) {\n  if (source == null) return {};\n  var target = {};\n  var sourceKeys = Object.keys(source);\n  var key, i;\n\n  for (i = 0; i < sourceKeys.length; i++) {\n    key = sourceKeys[i];\n    if (excluded.indexOf(key) >= 0) continue;\n    target[key] = source[key];\n  }\n\n  return target;\n}\n\nfunction _objectWithoutProperties(source, excluded) {\n  if (source == null) return {};\n\n  var target = _objectWithoutPropertiesLoose(source, excluded);\n\n  var key, i;\n\n  if (Object.getOwnPropertySymbols) {\n    var sourceSymbolKeys = Object.getOwnPropertySymbols(source);\n\n    for (i = 0; i < sourceSymbolKeys.length; i++) {\n      key = sourceSymbolKeys[i];\n      if (excluded.indexOf(key) >= 0) continue;\n      if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue;\n      target[key] = source[key];\n    }\n  }\n\n  return target;\n}\n\nconst VERSION = \"3.2.5\";\n\nclass Octokit {\n  constructor(options = {}) {\n    const hook = new beforeAfterHook.Collection();\n    const requestDefaults = {\n      baseUrl: request.request.endpoint.DEFAULTS.baseUrl,\n      headers: {},\n      request: Object.assign({}, options.request, {\n        hook: hook.bind(null, \"request\")\n      }),\n      mediaType: {\n        previews: [],\n        format: \"\"\n      }\n    }; // prepend default user agent with `options.userAgent` if set\n\n    requestDefaults.headers[\"user-agent\"] = [options.userAgent, `octokit-core.js/${VERSION} ${universalUserAgent.getUserAgent()}`].filter(Boolean).join(\" \");\n\n    if (options.baseUrl) {\n      requestDefaults.baseUrl = options.baseUrl;\n    }\n\n    if (options.previews) {\n      requestDefaults.mediaType.previews = options.previews;\n    }\n\n    if (options.timeZone) {\n      requestDefaults.headers[\"time-zone\"] = options.timeZone;\n    }\n\n    this.request = request.request.defaults(requestDefaults);\n    this.graphql = graphql.withCustomRequest(this.request).defaults(requestDefaults);\n    this.log = Object.assign({\n      debug: () => {},\n      info: () => {},\n      warn: console.warn.bind(console),\n      error: console.error.bind(console)\n    }, options.log);\n    this.hook = hook; // (1) If neither `options.authStrategy` nor `options.auth` are set, the `octokit` instance\n    //     is unauthenticated. The `this.auth()` method is a no-op and no request hook is registered.\n    // (2) If only `options.auth` is set, use the default token authentication strategy.\n    // (3) If `options.authStrategy` is set then use it and pass in `options.auth`. Always pass own request as many strategies accept a custom request instance.\n    // TODO: type `options.auth` based on `options.authStrategy`.\n\n    if (!options.authStrategy) {\n      if (!options.auth) {\n        // (1)\n        this.auth = async () => ({\n          type: \"unauthenticated\"\n        });\n      } else {\n        // (2)\n        const auth = authToken.createTokenAuth(options.auth); // @ts-ignore  \\_()_/\n\n        hook.wrap(\"request\", auth.hook);\n        this.auth = auth;\n      }\n    } else {\n      const {\n        authStrategy\n      } = options,\n            otherOptions = _objectWithoutProperties(options, [\"authStrategy\"]);\n\n      const auth = authStrategy(Object.assign({\n        request: this.request,\n        log: this.log,\n        // we pass the current octokit instance as well as its constructor options\n        // to allow for authentication strategies that return a new octokit instance\n        // that shares the same internal state as the current one. The original\n        // requirement for this was the \"event-octokit\" authentication strategy\n        // of https://github.com/probot/octokit-auth-probot.\n        octokit: this,\n        octokitOptions: otherOptions\n      }, options.auth)); // @ts-ignore  \\_()_/\n\n      hook.wrap(\"request\", auth.hook);\n      this.auth = auth;\n    } // apply plugins\n    // https://stackoverflow.com/a/16345172\n\n\n    const classConstructor = this.constructor;\n    classConstructor.plugins.forEach(plugin => {\n      Object.assign(this, plugin(this, options));\n    });\n  }\n\n  static defaults(defaults) {\n    const OctokitWithDefaults = class extends this {\n      constructor(...args) {\n        const options = args[0] || {};\n\n        if (typeof defaults === \"function\") {\n          super(defaults(options));\n          return;\n        }\n\n        super(Object.assign({}, defaults, options, options.userAgent && defaults.userAgent ? {\n          userAgent: `${options.userAgent} ${defaults.userAgent}`\n        } : null));\n      }\n\n    };\n    return OctokitWithDefaults;\n  }\n  /**\n   * Attach a plugin (or many) to your Octokit instance.\n   *\n   * @example\n   * const API = Octokit.plugin(plugin1, plugin2, plugin3, ...)\n   */\n\n\n  static plugin(...newPlugins) {\n    var _a;\n\n    const currentPlugins = this.plugins;\n    const NewOctokit = (_a = class extends this {}, _a.plugins = currentPlugins.concat(newPlugins.filter(plugin => !currentPlugins.includes(plugin))), _a);\n    return NewOctokit;\n  }\n\n}\nOctokit.VERSION = VERSION;\nOctokit.plugins = [];\n\nexports.Octokit = Octokit;\n//# sourceMappingURL=index.js.map\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar isPlainObject = require('is-plain-object');\nvar universalUserAgent = require('universal-user-agent');\n\nfunction lowercaseKeys(object) {\n  if (!object) {\n    return {};\n  }\n\n  return Object.keys(object).reduce((newObj, key) => {\n    newObj[key.toLowerCase()] = object[key];\n    return newObj;\n  }, {});\n}\n\nfunction mergeDeep(defaults, options) {\n  const result = Object.assign({}, defaults);\n  Object.keys(options).forEach(key => {\n    if (isPlainObject.isPlainObject(options[key])) {\n      if (!(key in defaults)) Object.assign(result, {\n        [key]: options[key]\n      });else result[key] = mergeDeep(defaults[key], options[key]);\n    } else {\n      Object.assign(result, {\n        [key]: options[key]\n      });\n    }\n  });\n  return result;\n}\n\nfunction removeUndefinedProperties(obj) {\n  for (const key in obj) {\n    if (obj[key] === undefined) {\n      delete obj[key];\n    }\n  }\n\n  return obj;\n}\n\nfunction merge(defaults, route, options) {\n  if (typeof route === \"string\") {\n    let [method, url] = route.split(\" \");\n    options = Object.assign(url ? {\n      method,\n      url\n    } : {\n      url: method\n    }, options);\n  } else {\n    options = Object.assign({}, route);\n  } // lowercase header names before merging with defaults to avoid duplicates\n\n\n  options.headers = lowercaseKeys(options.headers); // remove properties with undefined values before merging\n\n  removeUndefinedProperties(options);\n  removeUndefinedProperties(options.headers);\n  const mergedOptions = mergeDeep(defaults || {}, options); // mediaType.previews arrays are merged, instead of overwritten\n\n  if (defaults && defaults.mediaType.previews.length) {\n    mergedOptions.mediaType.previews = defaults.mediaType.previews.filter(preview => !mergedOptions.mediaType.previews.includes(preview)).concat(mergedOptions.mediaType.previews);\n  }\n\n  mergedOptions.mediaType.previews = mergedOptions.mediaType.previews.map(preview => preview.replace(/-preview/, \"\"));\n  return mergedOptions;\n}\n\nfunction addQueryParameters(url, parameters) {\n  const separator = /\\?/.test(url) ? \"&\" : \"?\";\n  const names = Object.keys(parameters);\n\n  if (names.length === 0) {\n    return url;\n  }\n\n  return url + separator + names.map(name => {\n    if (name === \"q\") {\n      return \"q=\" + parameters.q.split(\"+\").map(encodeURIComponent).join(\"+\");\n    }\n\n    return `${name}=${encodeURIComponent(parameters[name])}`;\n  }).join(\"&\");\n}\n\nconst urlVariableRegex = /\\{[^}]+\\}/g;\n\nfunction removeNonChars(variableName) {\n  return variableName.replace(/^\\W+|\\W+$/g, \"\").split(/,/);\n}\n\nfunction extractUrlVariableNames(url) {\n  const matches = url.match(urlVariableRegex);\n\n  if (!matches) {\n    return [];\n  }\n\n  return matches.map(removeNonChars).reduce((a, b) => a.concat(b), []);\n}\n\nfunction omit(object, keysToOmit) {\n  return Object.keys(object).filter(option => !keysToOmit.includes(option)).reduce((obj, key) => {\n    obj[key] = object[key];\n    return obj;\n  }, {});\n}\n\n// Based on https://github.com/bramstein/url-template, licensed under BSD\n// TODO: create separate package.\n//\n// Copyright (c) 2012-2014, Bram Stein\n// All rights reserved.\n// Redistribution and use in source and binary forms, with or without\n// modification, are permitted provided that the following conditions\n// are met:\n//  1. Redistributions of source code must retain the above copyright\n//     notice, this list of conditions and the following disclaimer.\n//  2. Redistributions in binary form must reproduce the above copyright\n//     notice, this list of conditions and the following disclaimer in the\n//     documentation and/or other materials provided with the distribution.\n//  3. The name of the author may not be used to endorse or promote products\n//     derived from this software without specific prior written permission.\n// THIS SOFTWARE IS PROVIDED BY THE AUTHOR \"AS IS\" AND ANY EXPRESS OR IMPLIED\n// WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF\n// MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO\n// EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT,\n// INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,\n// BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY\n// OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING\n// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE,\n// EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n/* istanbul ignore file */\nfunction encodeReserved(str) {\n  return str.split(/(%[0-9A-Fa-f]{2})/g).map(function (part) {\n    if (!/%[0-9A-Fa-f]/.test(part)) {\n      part = encodeURI(part).replace(/%5B/g, \"[\").replace(/%5D/g, \"]\");\n    }\n\n    return part;\n  }).join(\"\");\n}\n\nfunction encodeUnreserved(str) {\n  return encodeURIComponent(str).replace(/[!'()*]/g, function (c) {\n    return \"%\" + c.charCodeAt(0).toString(16).toUpperCase();\n  });\n}\n\nfunction encodeValue(operator, value, key) {\n  value = operator === \"+\" || operator === \"#\" ? encodeReserved(value) : encodeUnreserved(value);\n\n  if (key) {\n    return encodeUnreserved(key) + \"=\" + value;\n  } else {\n    return value;\n  }\n}\n\nfunction isDefined(value) {\n  return value !== undefined && value !== null;\n}\n\nfunction isKeyOperator(operator) {\n  return operator === \";\" || operator === \"&\" || operator === \"?\";\n}\n\nfunction getValues(context, operator, key, modifier) {\n  var value = context[key],\n      result = [];\n\n  if (isDefined(value) && value !== \"\") {\n    if (typeof value === \"string\" || typeof value === \"number\" || typeof value === \"boolean\") {\n      value = value.toString();\n\n      if (modifier && modifier !== \"*\") {\n        value = value.substring(0, parseInt(modifier, 10));\n      }\n\n      result.push(encodeValue(operator, value, isKeyOperator(operator) ? key : \"\"));\n    } else {\n      if (modifier === \"*\") {\n        if (Array.isArray(value)) {\n          value.filter(isDefined).forEach(function (value) {\n            result.push(encodeValue(operator, value, isKeyOperator(operator) ? key : \"\"));\n          });\n        } else {\n          Object.keys(value).forEach(function (k) {\n            if (isDefined(value[k])) {\n              result.push(encodeValue(operator, value[k], k));\n            }\n          });\n        }\n      } else {\n        const tmp = [];\n\n        if (Array.isArray(value)) {\n          value.filter(isDefined).forEach(function (value) {\n            tmp.push(encodeValue(operator, value));\n          });\n        } else {\n          Object.keys(value).forEach(function (k) {\n            if (isDefined(value[k])) {\n              tmp.push(encodeUnreserved(k));\n              tmp.push(encodeValue(operator, value[k].toString()));\n            }\n          });\n        }\n\n        if (isKeyOperator(operator)) {\n          result.push(encodeUnreserved(key) + \"=\" + tmp.join(\",\"));\n        } else if (tmp.length !== 0) {\n          result.push(tmp.join(\",\"));\n        }\n      }\n    }\n  } else {\n    if (operator === \";\") {\n      if (isDefined(value)) {\n        result.push(encodeUnreserved(key));\n      }\n    } else if (value === \"\" && (operator === \"&\" || operator === \"?\")) {\n      result.push(encodeUnreserved(key) + \"=\");\n    } else if (value === \"\") {\n      result.push(\"\");\n    }\n  }\n\n  return result;\n}\n\nfunction parseUrl(template) {\n  return {\n    expand: expand.bind(null, template)\n  };\n}\n\nfunction expand(template, context) {\n  var operators = [\"+\", \"#\", \".\", \"/\", \";\", \"?\", \"&\"];\n  return template.replace(/\\{([^\\{\\}]+)\\}|([^\\{\\}]+)/g, function (_, expression, literal) {\n    if (expression) {\n      let operator = \"\";\n      const values = [];\n\n      if (operators.indexOf(expression.charAt(0)) !== -1) {\n        operator = expression.charAt(0);\n        expression = expression.substr(1);\n      }\n\n      expression.split(/,/g).forEach(function (variable) {\n        var tmp = /([^:\\*]*)(?::(\\d+)|(\\*))?/.exec(variable);\n        values.push(getValues(context, operator, tmp[1], tmp[2] || tmp[3]));\n      });\n\n      if (operator && operator !== \"+\") {\n        var separator = \",\";\n\n        if (operator === \"?\") {\n          separator = \"&\";\n        } else if (operator !== \"#\") {\n          separator = operator;\n        }\n\n        return (values.length !== 0 ? operator : \"\") + values.join(separator);\n      } else {\n        return values.join(\",\");\n      }\n    } else {\n      return encodeReserved(literal);\n    }\n  });\n}\n\nfunction parse(options) {\n  // https://fetch.spec.whatwg.org/#methods\n  let method = options.method.toUpperCase(); // replace :varname with {varname} to make it RFC 6570 compatible\n\n  let url = (options.url || \"/\").replace(/:([a-z]\\w+)/g, \"{$1}\");\n  let headers = Object.assign({}, options.headers);\n  let body;\n  let parameters = omit(options, [\"method\", \"baseUrl\", \"url\", \"headers\", \"request\", \"mediaType\"]); // extract variable names from URL to calculate remaining variables later\n\n  const urlVariableNames = extractUrlVariableNames(url);\n  url = parseUrl(url).expand(parameters);\n\n  if (!/^http/.test(url)) {\n    url = options.baseUrl + url;\n  }\n\n  const omittedParameters = Object.keys(options).filter(option => urlVariableNames.includes(option)).concat(\"baseUrl\");\n  const remainingParameters = omit(parameters, omittedParameters);\n  const isBinaryRequest = /application\\/octet-stream/i.test(headers.accept);\n\n  if (!isBinaryRequest) {\n    if (options.mediaType.format) {\n      // e.g. application/vnd.github.v3+json => application/vnd.github.v3.raw\n      headers.accept = headers.accept.split(/,/).map(preview => preview.replace(/application\\/vnd(\\.\\w+)(\\.v3)?(\\.\\w+)?(\\+json)?$/, `application/vnd$1$2.${options.mediaType.format}`)).join(\",\");\n    }\n\n    if (options.mediaType.previews.length) {\n      const previewsFromAcceptHeader = headers.accept.match(/[\\w-]+(?=-preview)/g) || [];\n      headers.accept = previewsFromAcceptHeader.concat(options.mediaType.previews).map(preview => {\n        const format = options.mediaType.format ? `.${options.mediaType.format}` : \"+json\";\n        return `application/vnd.github.${preview}-preview${format}`;\n      }).join(\",\");\n    }\n  } // for GET/HEAD requests, set URL query parameters from remaining parameters\n  // for PATCH/POST/PUT/DELETE requests, set request body from remaining parameters\n\n\n  if ([\"GET\", \"HEAD\"].includes(method)) {\n    url = addQueryParameters(url, remainingParameters);\n  } else {\n    if (\"data\" in remainingParameters) {\n      body = remainingParameters.data;\n    } else {\n      if (Object.keys(remainingParameters).length) {\n        body = remainingParameters;\n      } else {\n        headers[\"content-length\"] = 0;\n      }\n    }\n  } // default content-type for JSON if body is set\n\n\n  if (!headers[\"content-type\"] && typeof body !== \"undefined\") {\n    headers[\"content-type\"] = \"application/json; charset=utf-8\";\n  } // GitHub expects 'content-length: 0' header for PUT/PATCH requests without body.\n  // fetch does not allow to set `content-length` header, but we can set body to an empty string\n\n\n  if ([\"PATCH\", \"PUT\"].includes(method) && typeof body === \"undefined\") {\n    body = \"\";\n  } // Only return body/request keys if present\n\n\n  return Object.assign({\n    method,\n    url,\n    headers\n  }, typeof body !== \"undefined\" ? {\n    body\n  } : null, options.request ? {\n    request: options.request\n  } : null);\n}\n\nfunction endpointWithDefaults(defaults, route, options) {\n  return parse(merge(defaults, route, options));\n}\n\nfunction withDefaults(oldDefaults, newDefaults) {\n  const DEFAULTS = merge(oldDefaults, newDefaults);\n  const endpoint = endpointWithDefaults.bind(null, DEFAULTS);\n  return Object.assign(endpoint, {\n    DEFAULTS,\n    defaults: withDefaults.bind(null, DEFAULTS),\n    merge: merge.bind(null, DEFAULTS),\n    parse\n  });\n}\n\nconst VERSION = \"6.0.11\";\n\nconst userAgent = `octokit-endpoint.js/${VERSION} ${universalUserAgent.getUserAgent()}`; // DEFAULTS has all properties set that EndpointOptions has, except url.\n// So we use RequestParameters and add method as additional required property.\n\nconst DEFAULTS = {\n  method: \"GET\",\n  baseUrl: \"https://api.github.com\",\n  headers: {\n    accept: \"application/vnd.github.v3+json\",\n    \"user-agent\": userAgent\n  },\n  mediaType: {\n    format: \"\",\n    previews: []\n  }\n};\n\nconst endpoint = withDefaults(null, DEFAULTS);\n\nexports.endpoint = endpoint;\n//# sourceMappingURL=index.js.map\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\n/*!\n * is-plain-object <https://github.com/jonschlinkert/is-plain-object>\n *\n * Copyright (c) 2014-2017, Jon Schlinkert.\n * Released under the MIT License.\n */\n\nfunction isObject(o) {\n  return Object.prototype.toString.call(o) === '[object Object]';\n}\n\nfunction isPlainObject(o) {\n  var ctor,prot;\n\n  if (isObject(o) === false) return false;\n\n  // If has modified constructor\n  ctor = o.constructor;\n  if (ctor === undefined) return true;\n\n  // If has modified prototype\n  prot = ctor.prototype;\n  if (isObject(prot) === false) return false;\n\n  // If constructor does not have an Object-specific method\n  if (prot.hasOwnProperty('isPrototypeOf') === false) {\n    return false;\n  }\n\n  // Most likely a plain Object\n  return true;\n}\n\nexports.isPlainObject = isPlainObject;\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar request = require('@octokit/request');\nvar universalUserAgent = require('universal-user-agent');\n\nconst VERSION = \"4.6.0\";\n\nclass GraphqlError extends Error {\n  constructor(request, response) {\n    const message = response.data.errors[0].message;\n    super(message);\n    Object.assign(this, response.data);\n    Object.assign(this, {\n      headers: response.headers\n    });\n    this.name = \"GraphqlError\";\n    this.request = request; // Maintains proper stack trace (only available on V8)\n\n    /* istanbul ignore next */\n\n    if (Error.captureStackTrace) {\n      Error.captureStackTrace(this, this.constructor);\n    }\n  }\n\n}\n\nconst NON_VARIABLE_OPTIONS = [\"method\", \"baseUrl\", \"url\", \"headers\", \"request\", \"query\", \"mediaType\"];\nconst GHES_V3_SUFFIX_REGEX = /\\/api\\/v3\\/?$/;\nfunction graphql(request, query, options) {\n  if (typeof query === \"string\" && options && \"query\" in options) {\n    return Promise.reject(new Error(`[@octokit/graphql] \"query\" cannot be used as variable name`));\n  }\n\n  const parsedOptions = typeof query === \"string\" ? Object.assign({\n    query\n  }, options) : query;\n  const requestOptions = Object.keys(parsedOptions).reduce((result, key) => {\n    if (NON_VARIABLE_OPTIONS.includes(key)) {\n      result[key] = parsedOptions[key];\n      return result;\n    }\n\n    if (!result.variables) {\n      result.variables = {};\n    }\n\n    result.variables[key] = parsedOptions[key];\n    return result;\n  }, {}); // workaround for GitHub Enterprise baseUrl set with /api/v3 suffix\n  // https://github.com/octokit/auth-app.js/issues/111#issuecomment-657610451\n\n  const baseUrl = parsedOptions.baseUrl || request.endpoint.DEFAULTS.baseUrl;\n\n  if (GHES_V3_SUFFIX_REGEX.test(baseUrl)) {\n    requestOptions.url = baseUrl.replace(GHES_V3_SUFFIX_REGEX, \"/api/graphql\");\n  }\n\n  return request(requestOptions).then(response => {\n    if (response.data.errors) {\n      const headers = {};\n\n      for (const key of Object.keys(response.headers)) {\n        headers[key] = response.headers[key];\n      }\n\n      throw new GraphqlError(requestOptions, {\n        headers,\n        data: response.data\n      });\n    }\n\n    return response.data.data;\n  });\n}\n\nfunction withDefaults(request$1, newDefaults) {\n  const newRequest = request$1.defaults(newDefaults);\n\n  const newApi = (query, options) => {\n    return graphql(newRequest, query, options);\n  };\n\n  return Object.assign(newApi, {\n    defaults: withDefaults.bind(null, newRequest),\n    endpoint: request.request.endpoint\n  });\n}\n\nconst graphql$1 = withDefaults(request.request, {\n  headers: {\n    \"user-agent\": `octokit-graphql.js/${VERSION} ${universalUserAgent.getUserAgent()}`\n  },\n  method: \"POST\",\n  url: \"/graphql\"\n});\nfunction withCustomRequest(customRequest) {\n  return withDefaults(customRequest, {\n    method: \"POST\",\n    url: \"/graphql\"\n  });\n}\n\nexports.graphql = graphql$1;\nexports.withCustomRequest = withCustomRequest;\n//# sourceMappingURL=index.js.map\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nconst VERSION = \"2.11.0\";\n\n/**\n * Some list response that can be paginated have a different response structure\n *\n * They have a `total_count` key in the response (search also has `incomplete_results`,\n * /installation/repositories also has `repository_selection`), as well as a key with\n * the list of the items which name varies from endpoint to endpoint.\n *\n * Octokit normalizes these responses so that paginated results are always returned following\n * the same structure. One challenge is that if the list response has only one page, no Link\n * header is provided, so this header alone is not sufficient to check wether a response is\n * paginated or not.\n *\n * We check if a \"total_count\" key is present in the response data, but also make sure that\n * a \"url\" property is not, as the \"Get the combined status for a specific ref\" endpoint would\n * otherwise match: https://developer.github.com/v3/repos/statuses/#get-the-combined-status-for-a-specific-ref\n */\nfunction normalizePaginatedListResponse(response) {\n  const responseNeedsNormalization = \"total_count\" in response.data && !(\"url\" in response.data);\n  if (!responseNeedsNormalization) return response; // keep the additional properties intact as there is currently no other way\n  // to retrieve the same information.\n\n  const incompleteResults = response.data.incomplete_results;\n  const repositorySelection = response.data.repository_selection;\n  const totalCount = response.data.total_count;\n  delete response.data.incomplete_results;\n  delete response.data.repository_selection;\n  delete response.data.total_count;\n  const namespaceKey = Object.keys(response.data)[0];\n  const data = response.data[namespaceKey];\n  response.data = data;\n\n  if (typeof incompleteResults !== \"undefined\") {\n    response.data.incomplete_results = incompleteResults;\n  }\n\n  if (typeof repositorySelection !== \"undefined\") {\n    response.data.repository_selection = repositorySelection;\n  }\n\n  response.data.total_count = totalCount;\n  return response;\n}\n\nfunction iterator(octokit, route, parameters) {\n  const options = typeof route === \"function\" ? route.endpoint(parameters) : octokit.request.endpoint(route, parameters);\n  const requestMethod = typeof route === \"function\" ? route : octokit.request;\n  const method = options.method;\n  const headers = options.headers;\n  let url = options.url;\n  return {\n    [Symbol.asyncIterator]: () => ({\n      async next() {\n        if (!url) return {\n          done: true\n        };\n        const response = await requestMethod({\n          method,\n          url,\n          headers\n        });\n        const normalizedResponse = normalizePaginatedListResponse(response); // `response.headers.link` format:\n        // '<https://api.github.com/users/aseemk/followers?page=2>; rel=\"next\", <https://api.github.com/users/aseemk/followers?page=2>; rel=\"last\"'\n        // sets `url` to undefined if \"next\" URL is not present or `link` header is not set\n\n        url = ((normalizedResponse.headers.link || \"\").match(/<([^>]+)>;\\s*rel=\"next\"/) || [])[1];\n        return {\n          value: normalizedResponse\n        };\n      }\n\n    })\n  };\n}\n\nfunction paginate(octokit, route, parameters, mapFn) {\n  if (typeof parameters === \"function\") {\n    mapFn = parameters;\n    parameters = undefined;\n  }\n\n  return gather(octokit, [], iterator(octokit, route, parameters)[Symbol.asyncIterator](), mapFn);\n}\n\nfunction gather(octokit, results, iterator, mapFn) {\n  return iterator.next().then(result => {\n    if (result.done) {\n      return results;\n    }\n\n    let earlyExit = false;\n\n    function done() {\n      earlyExit = true;\n    }\n\n    results = results.concat(mapFn ? mapFn(result.value, done) : result.value.data);\n\n    if (earlyExit) {\n      return results;\n    }\n\n    return gather(octokit, results, iterator, mapFn);\n  });\n}\n\nconst composePaginateRest = Object.assign(paginate, {\n  iterator\n});\n\n/**\n * @param octokit Octokit instance\n * @param options Options passed to Octokit constructor\n */\n\nfunction paginateRest(octokit) {\n  return {\n    paginate: Object.assign(paginate.bind(null, octokit), {\n      iterator: iterator.bind(null, octokit)\n    })\n  };\n}\npaginateRest.VERSION = VERSION;\n\nexports.composePaginateRest = composePaginateRest;\nexports.paginateRest = paginateRest;\n//# sourceMappingURL=index.js.map\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nconst Endpoints = {\n  actions: {\n    addSelectedRepoToOrgSecret: [\"PUT /orgs/{org}/actions/secrets/{secret_name}/repositories/{repository_id}\"],\n    cancelWorkflowRun: [\"POST /repos/{owner}/{repo}/actions/runs/{run_id}/cancel\"],\n    createOrUpdateEnvironmentSecret: [\"PUT /repositories/{repository_id}/environments/{environment_name}/secrets/{secret_name}\"],\n    createOrUpdateOrgSecret: [\"PUT /orgs/{org}/actions/secrets/{secret_name}\"],\n    createOrUpdateRepoSecret: [\"PUT /repos/{owner}/{repo}/actions/secrets/{secret_name}\"],\n    createRegistrationTokenForOrg: [\"POST /orgs/{org}/actions/runners/registration-token\"],\n    createRegistrationTokenForRepo: [\"POST /repos/{owner}/{repo}/actions/runners/registration-token\"],\n    createRemoveTokenForOrg: [\"POST /orgs/{org}/actions/runners/remove-token\"],\n    createRemoveTokenForRepo: [\"POST /repos/{owner}/{repo}/actions/runners/remove-token\"],\n    createWorkflowDispatch: [\"POST /repos/{owner}/{repo}/actions/workflows/{workflow_id}/dispatches\"],\n    deleteArtifact: [\"DELETE /repos/{owner}/{repo}/actions/artifacts/{artifact_id}\"],\n    deleteEnvironmentSecret: [\"DELETE /repositories/{repository_id}/environments/{environment_name}/secrets/{secret_name}\"],\n    deleteOrgSecret: [\"DELETE /orgs/{org}/actions/secrets/{secret_name}\"],\n    deleteRepoSecret: [\"DELETE /repos/{owner}/{repo}/actions/secrets/{secret_name}\"],\n    deleteSelfHostedRunnerFromOrg: [\"DELETE /orgs/{org}/actions/runners/{runner_id}\"],\n    deleteSelfHostedRunnerFromRepo: [\"DELETE /repos/{owner}/{repo}/actions/runners/{runner_id}\"],\n    deleteWorkflowRun: [\"DELETE /repos/{owner}/{repo}/actions/runs/{run_id}\"],\n    deleteWorkflowRunLogs: [\"DELETE /repos/{owner}/{repo}/actions/runs/{run_id}/logs\"],\n    disableSelectedRepositoryGithubActionsOrganization: [\"DELETE /orgs/{org}/actions/permissions/repositories/{repository_id}\"],\n    disableWorkflow: [\"PUT /repos/{owner}/{repo}/actions/workflows/{workflow_id}/disable\"],\n    downloadArtifact: [\"GET /repos/{owner}/{repo}/actions/artifacts/{artifact_id}/{archive_format}\"],\n    downloadJobLogsForWorkflowRun: [\"GET /repos/{owner}/{repo}/actions/jobs/{job_id}/logs\"],\n    downloadWorkflowRunLogs: [\"GET /repos/{owner}/{repo}/actions/runs/{run_id}/logs\"],\n    enableSelectedRepositoryGithubActionsOrganization: [\"PUT /orgs/{org}/actions/permissions/repositories/{repository_id}\"],\n    enableWorkflow: [\"PUT /repos/{owner}/{repo}/actions/workflows/{workflow_id}/enable\"],\n    getAllowedActionsOrganization: [\"GET /orgs/{org}/actions/permissions/selected-actions\"],\n    getAllowedActionsRepository: [\"GET /repos/{owner}/{repo}/actions/permissions/selected-actions\"],\n    getArtifact: [\"GET /repos/{owner}/{repo}/actions/artifacts/{artifact_id}\"],\n    getEnvironmentPublicKey: [\"GET /repositories/{repository_id}/environments/{environment_name}/secrets/public-key\"],\n    getEnvironmentSecret: [\"GET /repositories/{repository_id}/environments/{environment_name}/secrets/{secret_name}\"],\n    getGithubActionsPermissionsOrganization: [\"GET /orgs/{org}/actions/permissions\"],\n    getGithubActionsPermissionsRepository: [\"GET /repos/{owner}/{repo}/actions/permissions\"],\n    getJobForWorkflowRun: [\"GET /repos/{owner}/{repo}/actions/jobs/{job_id}\"],\n    getOrgPublicKey: [\"GET /orgs/{org}/actions/secrets/public-key\"],\n    getOrgSecret: [\"GET /orgs/{org}/actions/secrets/{secret_name}\"],\n    getPendingDeploymentsForRun: [\"GET /repos/{owner}/{repo}/actions/runs/{run_id}/pending_deployments\"],\n    getRepoPermissions: [\"GET /repos/{owner}/{repo}/actions/permissions\", {}, {\n      renamed: [\"actions\", \"getGithubActionsPermissionsRepository\"]\n    }],\n    getRepoPublicKey: [\"GET /repos/{owner}/{repo}/actions/secrets/public-key\"],\n    getRepoSecret: [\"GET /repos/{owner}/{repo}/actions/secrets/{secret_name}\"],\n    getReviewsForRun: [\"GET /repos/{owner}/{repo}/actions/runs/{run_id}/approvals\"],\n    getSelfHostedRunnerForOrg: [\"GET /orgs/{org}/actions/runners/{runner_id}\"],\n    getSelfHostedRunnerForRepo: [\"GET /repos/{owner}/{repo}/actions/runners/{runner_id}\"],\n    getWorkflow: [\"GET /repos/{owner}/{repo}/actions/workflows/{workflow_id}\"],\n    getWorkflowRun: [\"GET /repos/{owner}/{repo}/actions/runs/{run_id}\"],\n    getWorkflowRunUsage: [\"GET /repos/{owner}/{repo}/actions/runs/{run_id}/timing\"],\n    getWorkflowUsage: [\"GET /repos/{owner}/{repo}/actions/workflows/{workflow_id}/timing\"],\n    listArtifactsForRepo: [\"GET /repos/{owner}/{repo}/actions/artifacts\"],\n    listEnvironmentSecrets: [\"GET /repositories/{repository_id}/environments/{environment_name}/secrets\"],\n    listJobsForWorkflowRun: [\"GET /repos/{owner}/{repo}/actions/runs/{run_id}/jobs\"],\n    listOrgSecrets: [\"GET /orgs/{org}/actions/secrets\"],\n    listRepoSecrets: [\"GET /repos/{owner}/{repo}/actions/secrets\"],\n    listRepoWorkflows: [\"GET /repos/{owner}/{repo}/actions/workflows\"],\n    listRunnerApplicationsForOrg: [\"GET /orgs/{org}/actions/runners/downloads\"],\n    listRunnerApplicationsForRepo: [\"GET /repos/{owner}/{repo}/actions/runners/downloads\"],\n    listSelectedReposForOrgSecret: [\"GET /orgs/{org}/actions/secrets/{secret_name}/repositories\"],\n    listSelectedRepositoriesEnabledGithubActionsOrganization: [\"GET /orgs/{org}/actions/permissions/repositories\"],\n    listSelfHostedRunnersForOrg: [\"GET /orgs/{org}/actions/runners\"],\n    listSelfHostedRunnersForRepo: [\"GET /repos/{owner}/{repo}/actions/runners\"],\n    listWorkflowRunArtifacts: [\"GET /repos/{owner}/{repo}/actions/runs/{run_id}/artifacts\"],\n    listWorkflowRuns: [\"GET /repos/{owner}/{repo}/actions/workflows/{workflow_id}/runs\"],\n    listWorkflowRunsForRepo: [\"GET /repos/{owner}/{repo}/actions/runs\"],\n    reRunWorkflow: [\"POST /repos/{owner}/{repo}/actions/runs/{run_id}/rerun\"],\n    removeSelectedRepoFromOrgSecret: [\"DELETE /orgs/{org}/actions/secrets/{secret_name}/repositories/{repository_id}\"],\n    reviewPendingDeploymentsForRun: [\"POST /repos/{owner}/{repo}/actions/runs/{run_id}/pending_deployments\"],\n    setAllowedActionsOrganization: [\"PUT /orgs/{org}/actions/permissions/selected-actions\"],\n    setAllowedActionsRepository: [\"PUT /repos/{owner}/{repo}/actions/permissions/selected-actions\"],\n    setGithubActionsPermissionsOrganization: [\"PUT /orgs/{org}/actions/permissions\"],\n    setGithubActionsPermissionsRepository: [\"PUT /repos/{owner}/{repo}/actions/permissions\"],\n    setSelectedReposForOrgSecret: [\"PUT /orgs/{org}/actions/secrets/{secret_name}/repositories\"],\n    setSelectedRepositoriesEnabledGithubActionsOrganization: [\"PUT /orgs/{org}/actions/permissions/repositories\"]\n  },\n  activity: {\n    checkRepoIsStarredByAuthenticatedUser: [\"GET /user/starred/{owner}/{repo}\"],\n    deleteRepoSubscription: [\"DELETE /repos/{owner}/{repo}/subscription\"],\n    deleteThreadSubscription: [\"DELETE /notifications/threads/{thread_id}/subscription\"],\n    getFeeds: [\"GET /feeds\"],\n    getRepoSubscription: [\"GET /repos/{owner}/{repo}/subscription\"],\n    getThread: [\"GET /notifications/threads/{thread_id}\"],\n    getThreadSubscriptionForAuthenticatedUser: [\"GET /notifications/threads/{thread_id}/subscription\"],\n    listEventsForAuthenticatedUser: [\"GET /users/{username}/events\"],\n    listNotificationsForAuthenticatedUser: [\"GET /notifications\"],\n    listOrgEventsForAuthenticatedUser: [\"GET /users/{username}/events/orgs/{org}\"],\n    listPublicEvents: [\"GET /events\"],\n    listPublicEventsForRepoNetwork: [\"GET /networks/{owner}/{repo}/events\"],\n    listPublicEventsForUser: [\"GET /users/{username}/events/public\"],\n    listPublicOrgEvents: [\"GET /orgs/{org}/events\"],\n    listReceivedEventsForUser: [\"GET /users/{username}/received_events\"],\n    listReceivedPublicEventsForUser: [\"GET /users/{username}/received_events/public\"],\n    listRepoEvents: [\"GET /repos/{owner}/{repo}/events\"],\n    listRepoNotificationsForAuthenticatedUser: [\"GET /repos/{owner}/{repo}/notifications\"],\n    listReposStarredByAuthenticatedUser: [\"GET /user/starred\"],\n    listReposStarredByUser: [\"GET /users/{username}/starred\"],\n    listReposWatchedByUser: [\"GET /users/{username}/subscriptions\"],\n    listStargazersForRepo: [\"GET /repos/{owner}/{repo}/stargazers\"],\n    listWatchedReposForAuthenticatedUser: [\"GET /user/subscriptions\"],\n    listWatchersForRepo: [\"GET /repos/{owner}/{repo}/subscribers\"],\n    markNotificationsAsRead: [\"PUT /notifications\"],\n    markRepoNotificationsAsRead: [\"PUT /repos/{owner}/{repo}/notifications\"],\n    markThreadAsRead: [\"PATCH /notifications/threads/{thread_id}\"],\n    setRepoSubscription: [\"PUT /repos/{owner}/{repo}/subscription\"],\n    setThreadSubscription: [\"PUT /notifications/threads/{thread_id}/subscription\"],\n    starRepoForAuthenticatedUser: [\"PUT /user/starred/{owner}/{repo}\"],\n    unstarRepoForAuthenticatedUser: [\"DELETE /user/starred/{owner}/{repo}\"]\n  },\n  apps: {\n    addRepoToInstallation: [\"PUT /user/installations/{installation_id}/repositories/{repository_id}\"],\n    checkToken: [\"POST /applications/{client_id}/token\"],\n    createContentAttachment: [\"POST /content_references/{content_reference_id}/attachments\", {\n      mediaType: {\n        previews: [\"corsair\"]\n      }\n    }],\n    createFromManifest: [\"POST /app-manifests/{code}/conversions\"],\n    createInstallationAccessToken: [\"POST /app/installations/{installation_id}/access_tokens\"],\n    deleteAuthorization: [\"DELETE /applications/{client_id}/grant\"],\n    deleteInstallation: [\"DELETE /app/installations/{installation_id}\"],\n    deleteToken: [\"DELETE /applications/{client_id}/token\"],\n    getAuthenticated: [\"GET /app\"],\n    getBySlug: [\"GET /apps/{app_slug}\"],\n    getInstallation: [\"GET /app/installations/{installation_id}\"],\n    getOrgInstallation: [\"GET /orgs/{org}/installation\"],\n    getRepoInstallation: [\"GET /repos/{owner}/{repo}/installation\"],\n    getSubscriptionPlanForAccount: [\"GET /marketplace_listing/accounts/{account_id}\"],\n    getSubscriptionPlanForAccountStubbed: [\"GET /marketplace_listing/stubbed/accounts/{account_id}\"],\n    getUserInstallation: [\"GET /users/{username}/installation\"],\n    getWebhookConfigForApp: [\"GET /app/hook/config\"],\n    listAccountsForPlan: [\"GET /marketplace_listing/plans/{plan_id}/accounts\"],\n    listAccountsForPlanStubbed: [\"GET /marketplace_listing/stubbed/plans/{plan_id}/accounts\"],\n    listInstallationReposForAuthenticatedUser: [\"GET /user/installations/{installation_id}/repositories\"],\n    listInstallations: [\"GET /app/installations\"],\n    listInstallationsForAuthenticatedUser: [\"GET /user/installations\"],\n    listPlans: [\"GET /marketplace_listing/plans\"],\n    listPlansStubbed: [\"GET /marketplace_listing/stubbed/plans\"],\n    listReposAccessibleToInstallation: [\"GET /installation/repositories\"],\n    listSubscriptionsForAuthenticatedUser: [\"GET /user/marketplace_purchases\"],\n    listSubscriptionsForAuthenticatedUserStubbed: [\"GET /user/marketplace_purchases/stubbed\"],\n    removeRepoFromInstallation: [\"DELETE /user/installations/{installation_id}/repositories/{repository_id}\"],\n    resetToken: [\"PATCH /applications/{client_id}/token\"],\n    revokeInstallationAccessToken: [\"DELETE /installation/token\"],\n    scopeToken: [\"POST /applications/{client_id}/token/scoped\"],\n    suspendInstallation: [\"PUT /app/installations/{installation_id}/suspended\"],\n    unsuspendInstallation: [\"DELETE /app/installations/{installation_id}/suspended\"],\n    updateWebhookConfigForApp: [\"PATCH /app/hook/config\"]\n  },\n  billing: {\n    getGithubActionsBillingOrg: [\"GET /orgs/{org}/settings/billing/actions\"],\n    getGithubActionsBillingUser: [\"GET /users/{username}/settings/billing/actions\"],\n    getGithubPackagesBillingOrg: [\"GET /orgs/{org}/settings/billing/packages\"],\n    getGithubPackagesBillingUser: [\"GET /users/{username}/settings/billing/packages\"],\n    getSharedStorageBillingOrg: [\"GET /orgs/{org}/settings/billing/shared-storage\"],\n    getSharedStorageBillingUser: [\"GET /users/{username}/settings/billing/shared-storage\"]\n  },\n  checks: {\n    create: [\"POST /repos/{owner}/{repo}/check-runs\"],\n    createSuite: [\"POST /repos/{owner}/{repo}/check-suites\"],\n    get: [\"GET /repos/{owner}/{repo}/check-runs/{check_run_id}\"],\n    getSuite: [\"GET /repos/{owner}/{repo}/check-suites/{check_suite_id}\"],\n    listAnnotations: [\"GET /repos/{owner}/{repo}/check-runs/{check_run_id}/annotations\"],\n    listForRef: [\"GET /repos/{owner}/{repo}/commits/{ref}/check-runs\"],\n    listForSuite: [\"GET /repos/{owner}/{repo}/check-suites/{check_suite_id}/check-runs\"],\n    listSuitesForRef: [\"GET /repos/{owner}/{repo}/commits/{ref}/check-suites\"],\n    rerequestSuite: [\"POST /repos/{owner}/{repo}/check-suites/{check_suite_id}/rerequest\"],\n    setSuitesPreferences: [\"PATCH /repos/{owner}/{repo}/check-suites/preferences\"],\n    update: [\"PATCH /repos/{owner}/{repo}/check-runs/{check_run_id}\"]\n  },\n  codeScanning: {\n    deleteAnalysis: [\"DELETE /repos/{owner}/{repo}/code-scanning/analyses/{analysis_id}{?confirm_delete}\"],\n    getAlert: [\"GET /repos/{owner}/{repo}/code-scanning/alerts/{alert_number}\", {}, {\n      renamedParameters: {\n        alert_id: \"alert_number\"\n      }\n    }],\n    getAnalysis: [\"GET /repos/{owner}/{repo}/code-scanning/analyses/{analysis_id}\"],\n    getSarif: [\"GET /repos/{owner}/{repo}/code-scanning/sarifs/{sarif_id}\"],\n    listAlertsForRepo: [\"GET /repos/{owner}/{repo}/code-scanning/alerts\"],\n    listAlertsInstances: [\"GET /repos/{owner}/{repo}/code-scanning/alerts/{alert_number}/instances\"],\n    listRecentAnalyses: [\"GET /repos/{owner}/{repo}/code-scanning/analyses\"],\n    updateAlert: [\"PATCH /repos/{owner}/{repo}/code-scanning/alerts/{alert_number}\"],\n    uploadSarif: [\"POST /repos/{owner}/{repo}/code-scanning/sarifs\"]\n  },\n  codesOfConduct: {\n    getAllCodesOfConduct: [\"GET /codes_of_conduct\", {\n      mediaType: {\n        previews: [\"scarlet-witch\"]\n      }\n    }],\n    getConductCode: [\"GET /codes_of_conduct/{key}\", {\n      mediaType: {\n        previews: [\"scarlet-witch\"]\n      }\n    }],\n    getForRepo: [\"GET /repos/{owner}/{repo}/community/code_of_conduct\", {\n      mediaType: {\n        previews: [\"scarlet-witch\"]\n      }\n    }]\n  },\n  emojis: {\n    get: [\"GET /emojis\"]\n  },\n  enterpriseAdmin: {\n    disableSelectedOrganizationGithubActionsEnterprise: [\"DELETE /enterprises/{enterprise}/actions/permissions/organizations/{org_id}\"],\n    enableSelectedOrganizationGithubActionsEnterprise: [\"PUT /enterprises/{enterprise}/actions/permissions/organizations/{org_id}\"],\n    getAllowedActionsEnterprise: [\"GET /enterprises/{enterprise}/actions/permissions/selected-actions\"],\n    getGithubActionsPermissionsEnterprise: [\"GET /enterprises/{enterprise}/actions/permissions\"],\n    listSelectedOrganizationsEnabledGithubActionsEnterprise: [\"GET /enterprises/{enterprise}/actions/permissions/organizations\"],\n    setAllowedActionsEnterprise: [\"PUT /enterprises/{enterprise}/actions/permissions/selected-actions\"],\n    setGithubActionsPermissionsEnterprise: [\"PUT /enterprises/{enterprise}/actions/permissions\"],\n    setSelectedOrganizationsEnabledGithubActionsEnterprise: [\"PUT /enterprises/{enterprise}/actions/permissions/organizations\"]\n  },\n  gists: {\n    checkIsStarred: [\"GET /gists/{gist_id}/star\"],\n    create: [\"POST /gists\"],\n    createComment: [\"POST /gists/{gist_id}/comments\"],\n    delete: [\"DELETE /gists/{gist_id}\"],\n    deleteComment: [\"DELETE /gists/{gist_id}/comments/{comment_id}\"],\n    fork: [\"POST /gists/{gist_id}/forks\"],\n    get: [\"GET /gists/{gist_id}\"],\n    getComment: [\"GET /gists/{gist_id}/comments/{comment_id}\"],\n    getRevision: [\"GET /gists/{gist_id}/{sha}\"],\n    list: [\"GET /gists\"],\n    listComments: [\"GET /gists/{gist_id}/comments\"],\n    listCommits: [\"GET /gists/{gist_id}/commits\"],\n    listForUser: [\"GET /users/{username}/gists\"],\n    listForks: [\"GET /gists/{gist_id}/forks\"],\n    listPublic: [\"GET /gists/public\"],\n    listStarred: [\"GET /gists/starred\"],\n    star: [\"PUT /gists/{gist_id}/star\"],\n    unstar: [\"DELETE /gists/{gist_id}/star\"],\n    update: [\"PATCH /gists/{gist_id}\"],\n    updateComment: [\"PATCH /gists/{gist_id}/comments/{comment_id}\"]\n  },\n  git: {\n    createBlob: [\"POST /repos/{owner}/{repo}/git/blobs\"],\n    createCommit: [\"POST /repos/{owner}/{repo}/git/commits\"],\n    createRef: [\"POST /repos/{owner}/{repo}/git/refs\"],\n    createTag: [\"POST /repos/{owner}/{repo}/git/tags\"],\n    createTree: [\"POST /repos/{owner}/{repo}/git/trees\"],\n    deleteRef: [\"DELETE /repos/{owner}/{repo}/git/refs/{ref}\"],\n    getBlob: [\"GET /repos/{owner}/{repo}/git/blobs/{file_sha}\"],\n    getCommit: [\"GET /repos/{owner}/{repo}/git/commits/{commit_sha}\"],\n    getRef: [\"GET /repos/{owner}/{repo}/git/ref/{ref}\"],\n    getTag: [\"GET /repos/{owner}/{repo}/git/tags/{tag_sha}\"],\n    getTree: [\"GET /repos/{owner}/{repo}/git/trees/{tree_sha}\"],\n    listMatchingRefs: [\"GET /repos/{owner}/{repo}/git/matching-refs/{ref}\"],\n    updateRef: [\"PATCH /repos/{owner}/{repo}/git/refs/{ref}\"]\n  },\n  gitignore: {\n    getAllTemplates: [\"GET /gitignore/templates\"],\n    getTemplate: [\"GET /gitignore/templates/{name}\"]\n  },\n  interactions: {\n    getRestrictionsForAuthenticatedUser: [\"GET /user/interaction-limits\"],\n    getRestrictionsForOrg: [\"GET /orgs/{org}/interaction-limits\"],\n    getRestrictionsForRepo: [\"GET /repos/{owner}/{repo}/interaction-limits\"],\n    getRestrictionsForYourPublicRepos: [\"GET /user/interaction-limits\", {}, {\n      renamed: [\"interactions\", \"getRestrictionsForAuthenticatedUser\"]\n    }],\n    removeRestrictionsForAuthenticatedUser: [\"DELETE /user/interaction-limits\"],\n    removeRestrictionsForOrg: [\"DELETE /orgs/{org}/interaction-limits\"],\n    removeRestrictionsForRepo: [\"DELETE /repos/{owner}/{repo}/interaction-limits\"],\n    removeRestrictionsForYourPublicRepos: [\"DELETE /user/interaction-limits\", {}, {\n      renamed: [\"interactions\", \"removeRestrictionsForAuthenticatedUser\"]\n    }],\n    setRestrictionsForAuthenticatedUser: [\"PUT /user/interaction-limits\"],\n    setRestrictionsForOrg: [\"PUT /orgs/{org}/interaction-limits\"],\n    setRestrictionsForRepo: [\"PUT /repos/{owner}/{repo}/interaction-limits\"],\n    setRestrictionsForYourPublicRepos: [\"PUT /user/interaction-limits\", {}, {\n      renamed: [\"interactions\", \"setRestrictionsForAuthenticatedUser\"]\n    }]\n  },\n  issues: {\n    addAssignees: [\"POST /repos/{owner}/{repo}/issues/{issue_number}/assignees\"],\n    addLabels: [\"POST /repos/{owner}/{repo}/issues/{issue_number}/labels\"],\n    checkUserCanBeAssigned: [\"GET /repos/{owner}/{repo}/assignees/{assignee}\"],\n    create: [\"POST /repos/{owner}/{repo}/issues\"],\n    createComment: [\"POST /repos/{owner}/{repo}/issues/{issue_number}/comments\"],\n    createLabel: [\"POST /repos/{owner}/{repo}/labels\"],\n    createMilestone: [\"POST /repos/{owner}/{repo}/milestones\"],\n    deleteComment: [\"DELETE /repos/{owner}/{repo}/issues/comments/{comment_id}\"],\n    deleteLabel: [\"DELETE /repos/{owner}/{repo}/labels/{name}\"],\n    deleteMilestone: [\"DELETE /repos/{owner}/{repo}/milestones/{milestone_number}\"],\n    get: [\"GET /repos/{owner}/{repo}/issues/{issue_number}\"],\n    getComment: [\"GET /repos/{owner}/{repo}/issues/comments/{comment_id}\"],\n    getEvent: [\"GET /repos/{owner}/{repo}/issues/events/{event_id}\"],\n    getLabel: [\"GET /repos/{owner}/{repo}/labels/{name}\"],\n    getMilestone: [\"GET /repos/{owner}/{repo}/milestones/{milestone_number}\"],\n    list: [\"GET /issues\"],\n    listAssignees: [\"GET /repos/{owner}/{repo}/assignees\"],\n    listComments: [\"GET /repos/{owner}/{repo}/issues/{issue_number}/comments\"],\n    listCommentsForRepo: [\"GET /repos/{owner}/{repo}/issues/comments\"],\n    listEvents: [\"GET /repos/{owner}/{repo}/issues/{issue_number}/events\"],\n    listEventsForRepo: [\"GET /repos/{owner}/{repo}/issues/events\"],\n    listEventsForTimeline: [\"GET /repos/{owner}/{repo}/issues/{issue_number}/timeline\", {\n      mediaType: {\n        previews: [\"mockingbird\"]\n      }\n    }],\n    listForAuthenticatedUser: [\"GET /user/issues\"],\n    listForOrg: [\"GET /orgs/{org}/issues\"],\n    listForRepo: [\"GET /repos/{owner}/{repo}/issues\"],\n    listLabelsForMilestone: [\"GET /repos/{owner}/{repo}/milestones/{milestone_number}/labels\"],\n    listLabelsForRepo: [\"GET /repos/{owner}/{repo}/labels\"],\n    listLabelsOnIssue: [\"GET /repos/{owner}/{repo}/issues/{issue_number}/labels\"],\n    listMilestones: [\"GET /repos/{owner}/{repo}/milestones\"],\n    lock: [\"PUT /repos/{owner}/{repo}/issues/{issue_number}/lock\"],\n    removeAllLabels: [\"DELETE /repos/{owner}/{repo}/issues/{issue_number}/labels\"],\n    removeAssignees: [\"DELETE /repos/{owner}/{repo}/issues/{issue_number}/assignees\"],\n    removeLabel: [\"DELETE /repos/{owner}/{repo}/issues/{issue_number}/labels/{name}\"],\n    setLabels: [\"PUT /repos/{owner}/{repo}/issues/{issue_number}/labels\"],\n    unlock: [\"DELETE /repos/{owner}/{repo}/issues/{issue_number}/lock\"],\n    update: [\"PATCH /repos/{owner}/{repo}/issues/{issue_number}\"],\n    updateComment: [\"PATCH /repos/{owner}/{repo}/issues/comments/{comment_id}\"],\n    updateLabel: [\"PATCH /repos/{owner}/{repo}/labels/{name}\"],\n    updateMilestone: [\"PATCH /repos/{owner}/{repo}/milestones/{milestone_number}\"]\n  },\n  licenses: {\n    get: [\"GET /licenses/{license}\"],\n    getAllCommonlyUsed: [\"GET /licenses\"],\n    getForRepo: [\"GET /repos/{owner}/{repo}/license\"]\n  },\n  markdown: {\n    render: [\"POST /markdown\"],\n    renderRaw: [\"POST /markdown/raw\", {\n      headers: {\n        \"content-type\": \"text/plain; charset=utf-8\"\n      }\n    }]\n  },\n  meta: {\n    get: [\"GET /meta\"],\n    getOctocat: [\"GET /octocat\"],\n    getZen: [\"GET /zen\"],\n    root: [\"GET /\"]\n  },\n  migrations: {\n    cancelImport: [\"DELETE /repos/{owner}/{repo}/import\"],\n    deleteArchiveForAuthenticatedUser: [\"DELETE /user/migrations/{migration_id}/archive\", {\n      mediaType: {\n        previews: [\"wyandotte\"]\n      }\n    }],\n    deleteArchiveForOrg: [\"DELETE /orgs/{org}/migrations/{migration_id}/archive\", {\n      mediaType: {\n        previews: [\"wyandotte\"]\n      }\n    }],\n    downloadArchiveForOrg: [\"GET /orgs/{org}/migrations/{migration_id}/archive\", {\n      mediaType: {\n        previews: [\"wyandotte\"]\n      }\n    }],\n    getArchiveForAuthenticatedUser: [\"GET /user/migrations/{migration_id}/archive\", {\n      mediaType: {\n        previews: [\"wyandotte\"]\n      }\n    }],\n    getCommitAuthors: [\"GET /repos/{owner}/{repo}/import/authors\"],\n    getImportStatus: [\"GET /repos/{owner}/{repo}/import\"],\n    getLargeFiles: [\"GET /repos/{owner}/{repo}/import/large_files\"],\n    getStatusForAuthenticatedUser: [\"GET /user/migrations/{migration_id}\", {\n      mediaType: {\n        previews: [\"wyandotte\"]\n      }\n    }],\n    getStatusForOrg: [\"GET /orgs/{org}/migrations/{migration_id}\", {\n      mediaType: {\n        previews: [\"wyandotte\"]\n      }\n    }],\n    listForAuthenticatedUser: [\"GET /user/migrations\", {\n      mediaType: {\n        previews: [\"wyandotte\"]\n      }\n    }],\n    listForOrg: [\"GET /orgs/{org}/migrations\", {\n      mediaType: {\n        previews: [\"wyandotte\"]\n      }\n    }],\n    listReposForOrg: [\"GET /orgs/{org}/migrations/{migration_id}/repositories\", {\n      mediaType: {\n        previews: [\"wyandotte\"]\n      }\n    }],\n    listReposForUser: [\"GET /user/migrations/{migration_id}/repositories\", {\n      mediaType: {\n        previews: [\"wyandotte\"]\n      }\n    }],\n    mapCommitAuthor: [\"PATCH /repos/{owner}/{repo}/import/authors/{author_id}\"],\n    setLfsPreference: [\"PATCH /repos/{owner}/{repo}/import/lfs\"],\n    startForAuthenticatedUser: [\"POST /user/migrations\"],\n    startForOrg: [\"POST /orgs/{org}/migrations\"],\n    startImport: [\"PUT /repos/{owner}/{repo}/import\"],\n    unlockRepoForAuthenticatedUser: [\"DELETE /user/migrations/{migration_id}/repos/{repo_name}/lock\", {\n      mediaType: {\n        previews: [\"wyandotte\"]\n      }\n    }],\n    unlockRepoForOrg: [\"DELETE /orgs/{org}/migrations/{migration_id}/repos/{repo_name}/lock\", {\n      mediaType: {\n        previews: [\"wyandotte\"]\n      }\n    }],\n    updateImport: [\"PATCH /repos/{owner}/{repo}/import\"]\n  },\n  orgs: {\n    blockUser: [\"PUT /orgs/{org}/blocks/{username}\"],\n    cancelInvitation: [\"DELETE /orgs/{org}/invitations/{invitation_id}\"],\n    checkBlockedUser: [\"GET /orgs/{org}/blocks/{username}\"],\n    checkMembershipForUser: [\"GET /orgs/{org}/members/{username}\"],\n    checkPublicMembershipForUser: [\"GET /orgs/{org}/public_members/{username}\"],\n    convertMemberToOutsideCollaborator: [\"PUT /orgs/{org}/outside_collaborators/{username}\"],\n    createInvitation: [\"POST /orgs/{org}/invitations\"],\n    createWebhook: [\"POST /orgs/{org}/hooks\"],\n    deleteWebhook: [\"DELETE /orgs/{org}/hooks/{hook_id}\"],\n    get: [\"GET /orgs/{org}\"],\n    getMembershipForAuthenticatedUser: [\"GET /user/memberships/orgs/{org}\"],\n    getMembershipForUser: [\"GET /orgs/{org}/memberships/{username}\"],\n    getWebhook: [\"GET /orgs/{org}/hooks/{hook_id}\"],\n    getWebhookConfigForOrg: [\"GET /orgs/{org}/hooks/{hook_id}/config\"],\n    list: [\"GET /organizations\"],\n    listAppInstallations: [\"GET /orgs/{org}/installations\"],\n    listBlockedUsers: [\"GET /orgs/{org}/blocks\"],\n    listFailedInvitations: [\"GET /orgs/{org}/failed_invitations\"],\n    listForAuthenticatedUser: [\"GET /user/orgs\"],\n    listForUser: [\"GET /users/{username}/orgs\"],\n    listInvitationTeams: [\"GET /orgs/{org}/invitations/{invitation_id}/teams\"],\n    listMembers: [\"GET /orgs/{org}/members\"],\n    listMembershipsForAuthenticatedUser: [\"GET /user/memberships/orgs\"],\n    listOutsideCollaborators: [\"GET /orgs/{org}/outside_collaborators\"],\n    listPendingInvitations: [\"GET /orgs/{org}/invitations\"],\n    listPublicMembers: [\"GET /orgs/{org}/public_members\"],\n    listWebhooks: [\"GET /orgs/{org}/hooks\"],\n    pingWebhook: [\"POST /orgs/{org}/hooks/{hook_id}/pings\"],\n    removeMember: [\"DELETE /orgs/{org}/members/{username}\"],\n    removeMembershipForUser: [\"DELETE /orgs/{org}/memberships/{username}\"],\n    removeOutsideCollaborator: [\"DELETE /orgs/{org}/outside_collaborators/{username}\"],\n    removePublicMembershipForAuthenticatedUser: [\"DELETE /orgs/{org}/public_members/{username}\"],\n    setMembershipForUser: [\"PUT /orgs/{org}/memberships/{username}\"],\n    setPublicMembershipForAuthenticatedUser: [\"PUT /orgs/{org}/public_members/{username}\"],\n    unblockUser: [\"DELETE /orgs/{org}/blocks/{username}\"],\n    update: [\"PATCH /orgs/{org}\"],\n    updateMembershipForAuthenticatedUser: [\"PATCH /user/memberships/orgs/{org}\"],\n    updateWebhook: [\"PATCH /orgs/{org}/hooks/{hook_id}\"],\n    updateWebhookConfigForOrg: [\"PATCH /orgs/{org}/hooks/{hook_id}/config\"]\n  },\n  packages: {\n    deletePackageForAuthenticatedUser: [\"DELETE /user/packages/{package_type}/{package_name}\"],\n    deletePackageForOrg: [\"DELETE /orgs/{org}/packages/{package_type}/{package_name}\"],\n    deletePackageVersionForAuthenticatedUser: [\"DELETE /user/packages/{package_type}/{package_name}/versions/{package_version_id}\"],\n    deletePackageVersionForOrg: [\"DELETE /orgs/{org}/packages/{package_type}/{package_name}/versions/{package_version_id}\"],\n    getAllPackageVersionsForAPackageOwnedByAnOrg: [\"GET /orgs/{org}/packages/{package_type}/{package_name}/versions\"],\n    getAllPackageVersionsForAPackageOwnedByTheAuthenticatedUser: [\"GET /user/packages/{package_type}/{package_name}/versions\"],\n    getAllPackageVersionsForPackageOwnedByUser: [\"GET /users/{username}/packages/{package_type}/{package_name}/versions\"],\n    getPackageForAuthenticatedUser: [\"GET /user/packages/{package_type}/{package_name}\"],\n    getPackageForOrganization: [\"GET /orgs/{org}/packages/{package_type}/{package_name}\"],\n    getPackageForUser: [\"GET /users/{username}/packages/{package_type}/{package_name}\"],\n    getPackageVersionForAuthenticatedUser: [\"GET /user/packages/{package_type}/{package_name}/versions/{package_version_id}\"],\n    getPackageVersionForOrganization: [\"GET /orgs/{org}/packages/{package_type}/{package_name}/versions/{package_version_id}\"],\n    getPackageVersionForUser: [\"GET /users/{username}/packages/{package_type}/{package_name}/versions/{package_version_id}\"],\n    restorePackageForAuthenticatedUser: [\"POST /user/packages/{package_type}/{package_name}/restore\"],\n    restorePackageForOrg: [\"POST /orgs/{org}/packages/{package_type}/{package_name}/restore\"],\n    restorePackageVersionForAuthenticatedUser: [\"POST /user/packages/{package_type}/{package_name}/versions/{package_version_id}/restore\"],\n    restorePackageVersionForOrg: [\"POST /orgs/{org}/packages/{package_type}/{package_name}/versions/{package_version_id}/restore\"]\n  },\n  projects: {\n    addCollaborator: [\"PUT /projects/{project_id}/collaborators/{username}\", {\n      mediaType: {\n        previews: [\"inertia\"]\n      }\n    }],\n    createCard: [\"POST /projects/columns/{column_id}/cards\", {\n      mediaType: {\n        previews: [\"inertia\"]\n      }\n    }],\n    createColumn: [\"POST /projects/{project_id}/columns\", {\n      mediaType: {\n        previews: [\"inertia\"]\n      }\n    }],\n    createForAuthenticatedUser: [\"POST /user/projects\", {\n      mediaType: {\n        previews: [\"inertia\"]\n      }\n    }],\n    createForOrg: [\"POST /orgs/{org}/projects\", {\n      mediaType: {\n        previews: [\"inertia\"]\n      }\n    }],\n    createForRepo: [\"POST /repos/{owner}/{repo}/projects\", {\n      mediaType: {\n        previews: [\"inertia\"]\n      }\n    }],\n    delete: [\"DELETE /projects/{project_id}\", {\n      mediaType: {\n        previews: [\"inertia\"]\n      }\n    }],\n    deleteCard: [\"DELETE /projects/columns/cards/{card_id}\", {\n      mediaType: {\n        previews: [\"inertia\"]\n      }\n    }],\n    deleteColumn: [\"DELETE /projects/columns/{column_id}\", {\n      mediaType: {\n        previews: [\"inertia\"]\n      }\n    }],\n    get: [\"GET /projects/{project_id}\", {\n      mediaType: {\n        previews: [\"inertia\"]\n      }\n    }],\n    getCard: [\"GET /projects/columns/cards/{card_id}\", {\n      mediaType: {\n        previews: [\"inertia\"]\n      }\n    }],\n    getColumn: [\"GET /projects/columns/{column_id}\", {\n      mediaType: {\n        previews: [\"inertia\"]\n      }\n    }],\n    getPermissionForUser: [\"GET /projects/{project_id}/collaborators/{username}/permission\", {\n      mediaType: {\n        previews: [\"inertia\"]\n      }\n    }],\n    listCards: [\"GET /projects/columns/{column_id}/cards\", {\n      mediaType: {\n        previews: [\"inertia\"]\n      }\n    }],\n    listCollaborators: [\"GET /projects/{project_id}/collaborators\", {\n      mediaType: {\n        previews: [\"inertia\"]\n      }\n    }],\n    listColumns: [\"GET /projects/{project_id}/columns\", {\n      mediaType: {\n        previews: [\"inertia\"]\n      }\n    }],\n    listForOrg: [\"GET /orgs/{org}/projects\", {\n      mediaType: {\n        previews: [\"inertia\"]\n      }\n    }],\n    listForRepo: [\"GET /repos/{owner}/{repo}/projects\", {\n      mediaType: {\n        previews: [\"inertia\"]\n      }\n    }],\n    listForUser: [\"GET /users/{username}/projects\", {\n      mediaType: {\n        previews: [\"inertia\"]\n      }\n    }],\n    moveCard: [\"POST /projects/columns/cards/{card_id}/moves\", {\n      mediaType: {\n        previews: [\"inertia\"]\n      }\n    }],\n    moveColumn: [\"POST /projects/columns/{column_id}/moves\", {\n      mediaType: {\n        previews: [\"inertia\"]\n      }\n    }],\n    removeCollaborator: [\"DELETE /projects/{project_id}/collaborators/{username}\", {\n      mediaType: {\n        previews: [\"inertia\"]\n      }\n    }],\n    update: [\"PATCH /projects/{project_id}\", {\n      mediaType: {\n        previews: [\"inertia\"]\n      }\n    }],\n    updateCard: [\"PATCH /projects/columns/cards/{card_id}\", {\n      mediaType: {\n        previews: [\"inertia\"]\n      }\n    }],\n    updateColumn: [\"PATCH /projects/columns/{column_id}\", {\n      mediaType: {\n        previews: [\"inertia\"]\n      }\n    }]\n  },\n  pulls: {\n    checkIfMerged: [\"GET /repos/{owner}/{repo}/pulls/{pull_number}/merge\"],\n    create: [\"POST /repos/{owner}/{repo}/pulls\"],\n    createReplyForReviewComment: [\"POST /repos/{owner}/{repo}/pulls/{pull_number}/comments/{comment_id}/replies\"],\n    createReview: [\"POST /repos/{owner}/{repo}/pulls/{pull_number}/reviews\"],\n    createReviewComment: [\"POST /repos/{owner}/{repo}/pulls/{pull_number}/comments\"],\n    deletePendingReview: [\"DELETE /repos/{owner}/{repo}/pulls/{pull_number}/reviews/{review_id}\"],\n    deleteReviewComment: [\"DELETE /repos/{owner}/{repo}/pulls/comments/{comment_id}\"],\n    dismissReview: [\"PUT /repos/{owner}/{repo}/pulls/{pull_number}/reviews/{review_id}/dismissals\"],\n    get: [\"GET /repos/{owner}/{repo}/pulls/{pull_number}\"],\n    getReview: [\"GET /repos/{owner}/{repo}/pulls/{pull_number}/reviews/{review_id}\"],\n    getReviewComment: [\"GET /repos/{owner}/{repo}/pulls/comments/{comment_id}\"],\n    list: [\"GET /repos/{owner}/{repo}/pulls\"],\n    listCommentsForReview: [\"GET /repos/{owner}/{repo}/pulls/{pull_number}/reviews/{review_id}/comments\"],\n    listCommits: [\"GET /repos/{owner}/{repo}/pulls/{pull_number}/commits\"],\n    listFiles: [\"GET /repos/{owner}/{repo}/pulls/{pull_number}/files\"],\n    listRequestedReviewers: [\"GET /repos/{owner}/{repo}/pulls/{pull_number}/requested_reviewers\"],\n    listReviewComments: [\"GET /repos/{owner}/{repo}/pulls/{pull_number}/comments\"],\n    listReviewCommentsForRepo: [\"GET /repos/{owner}/{repo}/pulls/comments\"],\n    listReviews: [\"GET /repos/{owner}/{repo}/pulls/{pull_number}/reviews\"],\n    merge: [\"PUT /repos/{owner}/{repo}/pulls/{pull_number}/merge\"],\n    removeRequestedReviewers: [\"DELETE /repos/{owner}/{repo}/pulls/{pull_number}/requested_reviewers\"],\n    requestReviewers: [\"POST /repos/{owner}/{repo}/pulls/{pull_number}/requested_reviewers\"],\n    submitReview: [\"POST /repos/{owner}/{repo}/pulls/{pull_number}/reviews/{review_id}/events\"],\n    update: [\"PATCH /repos/{owner}/{repo}/pulls/{pull_number}\"],\n    updateBranch: [\"PUT /repos/{owner}/{repo}/pulls/{pull_number}/update-branch\", {\n      mediaType: {\n        previews: [\"lydian\"]\n      }\n    }],\n    updateReview: [\"PUT /repos/{owner}/{repo}/pulls/{pull_number}/reviews/{review_id}\"],\n    updateReviewComment: [\"PATCH /repos/{owner}/{repo}/pulls/comments/{comment_id}\"]\n  },\n  rateLimit: {\n    get: [\"GET /rate_limit\"]\n  },\n  reactions: {\n    createForCommitComment: [\"POST /repos/{owner}/{repo}/comments/{comment_id}/reactions\", {\n      mediaType: {\n        previews: [\"squirrel-girl\"]\n      }\n    }],\n    createForIssue: [\"POST /repos/{owner}/{repo}/issues/{issue_number}/reactions\", {\n      mediaType: {\n        previews: [\"squirrel-girl\"]\n      }\n    }],\n    createForIssueComment: [\"POST /repos/{owner}/{repo}/issues/comments/{comment_id}/reactions\", {\n      mediaType: {\n        previews: [\"squirrel-girl\"]\n      }\n    }],\n    createForPullRequestReviewComment: [\"POST /repos/{owner}/{repo}/pulls/comments/{comment_id}/reactions\", {\n      mediaType: {\n        previews: [\"squirrel-girl\"]\n      }\n    }],\n    createForTeamDiscussionCommentInOrg: [\"POST /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/comments/{comment_number}/reactions\", {\n      mediaType: {\n        previews: [\"squirrel-girl\"]\n      }\n    }],\n    createForTeamDiscussionInOrg: [\"POST /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/reactions\", {\n      mediaType: {\n        previews: [\"squirrel-girl\"]\n      }\n    }],\n    deleteForCommitComment: [\"DELETE /repos/{owner}/{repo}/comments/{comment_id}/reactions/{reaction_id}\", {\n      mediaType: {\n        previews: [\"squirrel-girl\"]\n      }\n    }],\n    deleteForIssue: [\"DELETE /repos/{owner}/{repo}/issues/{issue_number}/reactions/{reaction_id}\", {\n      mediaType: {\n        previews: [\"squirrel-girl\"]\n      }\n    }],\n    deleteForIssueComment: [\"DELETE /repos/{owner}/{repo}/issues/comments/{comment_id}/reactions/{reaction_id}\", {\n      mediaType: {\n        previews: [\"squirrel-girl\"]\n      }\n    }],\n    deleteForPullRequestComment: [\"DELETE /repos/{owner}/{repo}/pulls/comments/{comment_id}/reactions/{reaction_id}\", {\n      mediaType: {\n        previews: [\"squirrel-girl\"]\n      }\n    }],\n    deleteForTeamDiscussion: [\"DELETE /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/reactions/{reaction_id}\", {\n      mediaType: {\n        previews: [\"squirrel-girl\"]\n      }\n    }],\n    deleteForTeamDiscussionComment: [\"DELETE /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/comments/{comment_number}/reactions/{reaction_id}\", {\n      mediaType: {\n        previews: [\"squirrel-girl\"]\n      }\n    }],\n    deleteLegacy: [\"DELETE /reactions/{reaction_id}\", {\n      mediaType: {\n        previews: [\"squirrel-girl\"]\n      }\n    }, {\n      deprecated: \"octokit.reactions.deleteLegacy() is deprecated, see https://docs.github.com/rest/reference/reactions/#delete-a-reaction-legacy\"\n    }],\n    listForCommitComment: [\"GET /repos/{owner}/{repo}/comments/{comment_id}/reactions\", {\n      mediaType: {\n        previews: [\"squirrel-girl\"]\n      }\n    }],\n    listForIssue: [\"GET /repos/{owner}/{repo}/issues/{issue_number}/reactions\", {\n      mediaType: {\n        previews: [\"squirrel-girl\"]\n      }\n    }],\n    listForIssueComment: [\"GET /repos/{owner}/{repo}/issues/comments/{comment_id}/reactions\", {\n      mediaType: {\n        previews: [\"squirrel-girl\"]\n      }\n    }],\n    listForPullRequestReviewComment: [\"GET /repos/{owner}/{repo}/pulls/comments/{comment_id}/reactions\", {\n      mediaType: {\n        previews: [\"squirrel-girl\"]\n      }\n    }],\n    listForTeamDiscussionCommentInOrg: [\"GET /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/comments/{comment_number}/reactions\", {\n      mediaType: {\n        previews: [\"squirrel-girl\"]\n      }\n    }],\n    listForTeamDiscussionInOrg: [\"GET /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/reactions\", {\n      mediaType: {\n        previews: [\"squirrel-girl\"]\n      }\n    }]\n  },\n  repos: {\n    acceptInvitation: [\"PATCH /user/repository_invitations/{invitation_id}\"],\n    addAppAccessRestrictions: [\"POST /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/apps\", {}, {\n      mapToData: \"apps\"\n    }],\n    addCollaborator: [\"PUT /repos/{owner}/{repo}/collaborators/{username}\"],\n    addStatusCheckContexts: [\"POST /repos/{owner}/{repo}/branches/{branch}/protection/required_status_checks/contexts\", {}, {\n      mapToData: \"contexts\"\n    }],\n    addTeamAccessRestrictions: [\"POST /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/teams\", {}, {\n      mapToData: \"teams\"\n    }],\n    addUserAccessRestrictions: [\"POST /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/users\", {}, {\n      mapToData: \"users\"\n    }],\n    checkCollaborator: [\"GET /repos/{owner}/{repo}/collaborators/{username}\"],\n    checkVulnerabilityAlerts: [\"GET /repos/{owner}/{repo}/vulnerability-alerts\", {\n      mediaType: {\n        previews: [\"dorian\"]\n      }\n    }],\n    compareCommits: [\"GET /repos/{owner}/{repo}/compare/{base}...{head}\"],\n    createCommitComment: [\"POST /repos/{owner}/{repo}/commits/{commit_sha}/comments\"],\n    createCommitSignatureProtection: [\"POST /repos/{owner}/{repo}/branches/{branch}/protection/required_signatures\", {\n      mediaType: {\n        previews: [\"zzzax\"]\n      }\n    }],\n    createCommitStatus: [\"POST /repos/{owner}/{repo}/statuses/{sha}\"],\n    createDeployKey: [\"POST /repos/{owner}/{repo}/keys\"],\n    createDeployment: [\"POST /repos/{owner}/{repo}/deployments\"],\n    createDeploymentStatus: [\"POST /repos/{owner}/{repo}/deployments/{deployment_id}/statuses\"],\n    createDispatchEvent: [\"POST /repos/{owner}/{repo}/dispatches\"],\n    createForAuthenticatedUser: [\"POST /user/repos\"],\n    createFork: [\"POST /repos/{owner}/{repo}/forks\"],\n    createInOrg: [\"POST /orgs/{org}/repos\"],\n    createOrUpdateEnvironment: [\"PUT /repos/{owner}/{repo}/environments/{environment_name}\"],\n    createOrUpdateFileContents: [\"PUT /repos/{owner}/{repo}/contents/{path}\"],\n    createPagesSite: [\"POST /repos/{owner}/{repo}/pages\", {\n      mediaType: {\n        previews: [\"switcheroo\"]\n      }\n    }],\n    createRelease: [\"POST /repos/{owner}/{repo}/releases\"],\n    createUsingTemplate: [\"POST /repos/{template_owner}/{template_repo}/generate\", {\n      mediaType: {\n        previews: [\"baptiste\"]\n      }\n    }],\n    createWebhook: [\"POST /repos/{owner}/{repo}/hooks\"],\n    declineInvitation: [\"DELETE /user/repository_invitations/{invitation_id}\"],\n    delete: [\"DELETE /repos/{owner}/{repo}\"],\n    deleteAccessRestrictions: [\"DELETE /repos/{owner}/{repo}/branches/{branch}/protection/restrictions\"],\n    deleteAdminBranchProtection: [\"DELETE /repos/{owner}/{repo}/branches/{branch}/protection/enforce_admins\"],\n    deleteAnEnvironment: [\"DELETE /repos/{owner}/{repo}/environments/{environment_name}\"],\n    deleteBranchProtection: [\"DELETE /repos/{owner}/{repo}/branches/{branch}/protection\"],\n    deleteCommitComment: [\"DELETE /repos/{owner}/{repo}/comments/{comment_id}\"],\n    deleteCommitSignatureProtection: [\"DELETE /repos/{owner}/{repo}/branches/{branch}/protection/required_signatures\", {\n      mediaType: {\n        previews: [\"zzzax\"]\n      }\n    }],\n    deleteDeployKey: [\"DELETE /repos/{owner}/{repo}/keys/{key_id}\"],\n    deleteDeployment: [\"DELETE /repos/{owner}/{repo}/deployments/{deployment_id}\"],\n    deleteFile: [\"DELETE /repos/{owner}/{repo}/contents/{path}\"],\n    deleteInvitation: [\"DELETE /repos/{owner}/{repo}/invitations/{invitation_id}\"],\n    deletePagesSite: [\"DELETE /repos/{owner}/{repo}/pages\", {\n      mediaType: {\n        previews: [\"switcheroo\"]\n      }\n    }],\n    deletePullRequestReviewProtection: [\"DELETE /repos/{owner}/{repo}/branches/{branch}/protection/required_pull_request_reviews\"],\n    deleteRelease: [\"DELETE /repos/{owner}/{repo}/releases/{release_id}\"],\n    deleteReleaseAsset: [\"DELETE /repos/{owner}/{repo}/releases/assets/{asset_id}\"],\n    deleteWebhook: [\"DELETE /repos/{owner}/{repo}/hooks/{hook_id}\"],\n    disableAutomatedSecurityFixes: [\"DELETE /repos/{owner}/{repo}/automated-security-fixes\", {\n      mediaType: {\n        previews: [\"london\"]\n      }\n    }],\n    disableVulnerabilityAlerts: [\"DELETE /repos/{owner}/{repo}/vulnerability-alerts\", {\n      mediaType: {\n        previews: [\"dorian\"]\n      }\n    }],\n    downloadArchive: [\"GET /repos/{owner}/{repo}/zipball/{ref}\", {}, {\n      renamed: [\"repos\", \"downloadZipballArchive\"]\n    }],\n    downloadTarballArchive: [\"GET /repos/{owner}/{repo}/tarball/{ref}\"],\n    downloadZipballArchive: [\"GET /repos/{owner}/{repo}/zipball/{ref}\"],\n    enableAutomatedSecurityFixes: [\"PUT /repos/{owner}/{repo}/automated-security-fixes\", {\n      mediaType: {\n        previews: [\"london\"]\n      }\n    }],\n    enableVulnerabilityAlerts: [\"PUT /repos/{owner}/{repo}/vulnerability-alerts\", {\n      mediaType: {\n        previews: [\"dorian\"]\n      }\n    }],\n    get: [\"GET /repos/{owner}/{repo}\"],\n    getAccessRestrictions: [\"GET /repos/{owner}/{repo}/branches/{branch}/protection/restrictions\"],\n    getAdminBranchProtection: [\"GET /repos/{owner}/{repo}/branches/{branch}/protection/enforce_admins\"],\n    getAllEnvironments: [\"GET /repos/{owner}/{repo}/environments\"],\n    getAllStatusCheckContexts: [\"GET /repos/{owner}/{repo}/branches/{branch}/protection/required_status_checks/contexts\"],\n    getAllTopics: [\"GET /repos/{owner}/{repo}/topics\", {\n      mediaType: {\n        previews: [\"mercy\"]\n      }\n    }],\n    getAppsWithAccessToProtectedBranch: [\"GET /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/apps\"],\n    getBranch: [\"GET /repos/{owner}/{repo}/branches/{branch}\"],\n    getBranchProtection: [\"GET /repos/{owner}/{repo}/branches/{branch}/protection\"],\n    getClones: [\"GET /repos/{owner}/{repo}/traffic/clones\"],\n    getCodeFrequencyStats: [\"GET /repos/{owner}/{repo}/stats/code_frequency\"],\n    getCollaboratorPermissionLevel: [\"GET /repos/{owner}/{repo}/collaborators/{username}/permission\"],\n    getCombinedStatusForRef: [\"GET /repos/{owner}/{repo}/commits/{ref}/status\"],\n    getCommit: [\"GET /repos/{owner}/{repo}/commits/{ref}\"],\n    getCommitActivityStats: [\"GET /repos/{owner}/{repo}/stats/commit_activity\"],\n    getCommitComment: [\"GET /repos/{owner}/{repo}/comments/{comment_id}\"],\n    getCommitSignatureProtection: [\"GET /repos/{owner}/{repo}/branches/{branch}/protection/required_signatures\", {\n      mediaType: {\n        previews: [\"zzzax\"]\n      }\n    }],\n    getCommunityProfileMetrics: [\"GET /repos/{owner}/{repo}/community/profile\"],\n    getContent: [\"GET /repos/{owner}/{repo}/contents/{path}\"],\n    getContributorsStats: [\"GET /repos/{owner}/{repo}/stats/contributors\"],\n    getDeployKey: [\"GET /repos/{owner}/{repo}/keys/{key_id}\"],\n    getDeployment: [\"GET /repos/{owner}/{repo}/deployments/{deployment_id}\"],\n    getDeploymentStatus: [\"GET /repos/{owner}/{repo}/deployments/{deployment_id}/statuses/{status_id}\"],\n    getEnvironment: [\"GET /repos/{owner}/{repo}/environments/{environment_name}\"],\n    getLatestPagesBuild: [\"GET /repos/{owner}/{repo}/pages/builds/latest\"],\n    getLatestRelease: [\"GET /repos/{owner}/{repo}/releases/latest\"],\n    getPages: [\"GET /repos/{owner}/{repo}/pages\"],\n    getPagesBuild: [\"GET /repos/{owner}/{repo}/pages/builds/{build_id}\"],\n    getParticipationStats: [\"GET /repos/{owner}/{repo}/stats/participation\"],\n    getPullRequestReviewProtection: [\"GET /repos/{owner}/{repo}/branches/{branch}/protection/required_pull_request_reviews\"],\n    getPunchCardStats: [\"GET /repos/{owner}/{repo}/stats/punch_card\"],\n    getReadme: [\"GET /repos/{owner}/{repo}/readme\"],\n    getRelease: [\"GET /repos/{owner}/{repo}/releases/{release_id}\"],\n    getReleaseAsset: [\"GET /repos/{owner}/{repo}/releases/assets/{asset_id}\"],\n    getReleaseByTag: [\"GET /repos/{owner}/{repo}/releases/tags/{tag}\"],\n    getStatusChecksProtection: [\"GET /repos/{owner}/{repo}/branches/{branch}/protection/required_status_checks\"],\n    getTeamsWithAccessToProtectedBranch: [\"GET /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/teams\"],\n    getTopPaths: [\"GET /repos/{owner}/{repo}/traffic/popular/paths\"],\n    getTopReferrers: [\"GET /repos/{owner}/{repo}/traffic/popular/referrers\"],\n    getUsersWithAccessToProtectedBranch: [\"GET /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/users\"],\n    getViews: [\"GET /repos/{owner}/{repo}/traffic/views\"],\n    getWebhook: [\"GET /repos/{owner}/{repo}/hooks/{hook_id}\"],\n    getWebhookConfigForRepo: [\"GET /repos/{owner}/{repo}/hooks/{hook_id}/config\"],\n    listBranches: [\"GET /repos/{owner}/{repo}/branches\"],\n    listBranchesForHeadCommit: [\"GET /repos/{owner}/{repo}/commits/{commit_sha}/branches-where-head\", {\n      mediaType: {\n        previews: [\"groot\"]\n      }\n    }],\n    listCollaborators: [\"GET /repos/{owner}/{repo}/collaborators\"],\n    listCommentsForCommit: [\"GET /repos/{owner}/{repo}/commits/{commit_sha}/comments\"],\n    listCommitCommentsForRepo: [\"GET /repos/{owner}/{repo}/comments\"],\n    listCommitStatusesForRef: [\"GET /repos/{owner}/{repo}/commits/{ref}/statuses\"],\n    listCommits: [\"GET /repos/{owner}/{repo}/commits\"],\n    listContributors: [\"GET /repos/{owner}/{repo}/contributors\"],\n    listDeployKeys: [\"GET /repos/{owner}/{repo}/keys\"],\n    listDeploymentStatuses: [\"GET /repos/{owner}/{repo}/deployments/{deployment_id}/statuses\"],\n    listDeployments: [\"GET /repos/{owner}/{repo}/deployments\"],\n    listForAuthenticatedUser: [\"GET /user/repos\"],\n    listForOrg: [\"GET /orgs/{org}/repos\"],\n    listForUser: [\"GET /users/{username}/repos\"],\n    listForks: [\"GET /repos/{owner}/{repo}/forks\"],\n    listInvitations: [\"GET /repos/{owner}/{repo}/invitations\"],\n    listInvitationsForAuthenticatedUser: [\"GET /user/repository_invitations\"],\n    listLanguages: [\"GET /repos/{owner}/{repo}/languages\"],\n    listPagesBuilds: [\"GET /repos/{owner}/{repo}/pages/builds\"],\n    listPublic: [\"GET /repositories\"],\n    listPullRequestsAssociatedWithCommit: [\"GET /repos/{owner}/{repo}/commits/{commit_sha}/pulls\", {\n      mediaType: {\n        previews: [\"groot\"]\n      }\n    }],\n    listReleaseAssets: [\"GET /repos/{owner}/{repo}/releases/{release_id}/assets\"],\n    listReleases: [\"GET /repos/{owner}/{repo}/releases\"],\n    listTags: [\"GET /repos/{owner}/{repo}/tags\"],\n    listTeams: [\"GET /repos/{owner}/{repo}/teams\"],\n    listWebhooks: [\"GET /repos/{owner}/{repo}/hooks\"],\n    merge: [\"POST /repos/{owner}/{repo}/merges\"],\n    pingWebhook: [\"POST /repos/{owner}/{repo}/hooks/{hook_id}/pings\"],\n    removeAppAccessRestrictions: [\"DELETE /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/apps\", {}, {\n      mapToData: \"apps\"\n    }],\n    removeCollaborator: [\"DELETE /repos/{owner}/{repo}/collaborators/{username}\"],\n    removeStatusCheckContexts: [\"DELETE /repos/{owner}/{repo}/branches/{branch}/protection/required_status_checks/contexts\", {}, {\n      mapToData: \"contexts\"\n    }],\n    removeStatusCheckProtection: [\"DELETE /repos/{owner}/{repo}/branches/{branch}/protection/required_status_checks\"],\n    removeTeamAccessRestrictions: [\"DELETE /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/teams\", {}, {\n      mapToData: \"teams\"\n    }],\n    removeUserAccessRestrictions: [\"DELETE /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/users\", {}, {\n      mapToData: \"users\"\n    }],\n    renameBranch: [\"POST /repos/{owner}/{repo}/branches/{branch}/rename\"],\n    replaceAllTopics: [\"PUT /repos/{owner}/{repo}/topics\", {\n      mediaType: {\n        previews: [\"mercy\"]\n      }\n    }],\n    requestPagesBuild: [\"POST /repos/{owner}/{repo}/pages/builds\"],\n    setAdminBranchProtection: [\"POST /repos/{owner}/{repo}/branches/{branch}/protection/enforce_admins\"],\n    setAppAccessRestrictions: [\"PUT /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/apps\", {}, {\n      mapToData: \"apps\"\n    }],\n    setStatusCheckContexts: [\"PUT /repos/{owner}/{repo}/branches/{branch}/protection/required_status_checks/contexts\", {}, {\n      mapToData: \"contexts\"\n    }],\n    setTeamAccessRestrictions: [\"PUT /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/teams\", {}, {\n      mapToData: \"teams\"\n    }],\n    setUserAccessRestrictions: [\"PUT /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/users\", {}, {\n      mapToData: \"users\"\n    }],\n    testPushWebhook: [\"POST /repos/{owner}/{repo}/hooks/{hook_id}/tests\"],\n    transfer: [\"POST /repos/{owner}/{repo}/transfer\"],\n    update: [\"PATCH /repos/{owner}/{repo}\"],\n    updateBranchProtection: [\"PUT /repos/{owner}/{repo}/branches/{branch}/protection\"],\n    updateCommitComment: [\"PATCH /repos/{owner}/{repo}/comments/{comment_id}\"],\n    updateInformationAboutPagesSite: [\"PUT /repos/{owner}/{repo}/pages\"],\n    updateInvitation: [\"PATCH /repos/{owner}/{repo}/invitations/{invitation_id}\"],\n    updatePullRequestReviewProtection: [\"PATCH /repos/{owner}/{repo}/branches/{branch}/protection/required_pull_request_reviews\"],\n    updateRelease: [\"PATCH /repos/{owner}/{repo}/releases/{release_id}\"],\n    updateReleaseAsset: [\"PATCH /repos/{owner}/{repo}/releases/assets/{asset_id}\"],\n    updateStatusCheckPotection: [\"PATCH /repos/{owner}/{repo}/branches/{branch}/protection/required_status_checks\", {}, {\n      renamed: [\"repos\", \"updateStatusCheckProtection\"]\n    }],\n    updateStatusCheckProtection: [\"PATCH /repos/{owner}/{repo}/branches/{branch}/protection/required_status_checks\"],\n    updateWebhook: [\"PATCH /repos/{owner}/{repo}/hooks/{hook_id}\"],\n    updateWebhookConfigForRepo: [\"PATCH /repos/{owner}/{repo}/hooks/{hook_id}/config\"],\n    uploadReleaseAsset: [\"POST /repos/{owner}/{repo}/releases/{release_id}/assets{?name,label}\", {\n      baseUrl: \"https://uploads.github.com\"\n    }]\n  },\n  search: {\n    code: [\"GET /search/code\"],\n    commits: [\"GET /search/commits\", {\n      mediaType: {\n        previews: [\"cloak\"]\n      }\n    }],\n    issuesAndPullRequests: [\"GET /search/issues\"],\n    labels: [\"GET /search/labels\"],\n    repos: [\"GET /search/repositories\"],\n    topics: [\"GET /search/topics\", {\n      mediaType: {\n        previews: [\"mercy\"]\n      }\n    }],\n    users: [\"GET /search/users\"]\n  },\n  secretScanning: {\n    getAlert: [\"GET /repos/{owner}/{repo}/secret-scanning/alerts/{alert_number}\"],\n    listAlertsForRepo: [\"GET /repos/{owner}/{repo}/secret-scanning/alerts\"],\n    updateAlert: [\"PATCH /repos/{owner}/{repo}/secret-scanning/alerts/{alert_number}\"]\n  },\n  teams: {\n    addOrUpdateMembershipForUserInOrg: [\"PUT /orgs/{org}/teams/{team_slug}/memberships/{username}\"],\n    addOrUpdateProjectPermissionsInOrg: [\"PUT /orgs/{org}/teams/{team_slug}/projects/{project_id}\", {\n      mediaType: {\n        previews: [\"inertia\"]\n      }\n    }],\n    addOrUpdateRepoPermissionsInOrg: [\"PUT /orgs/{org}/teams/{team_slug}/repos/{owner}/{repo}\"],\n    checkPermissionsForProjectInOrg: [\"GET /orgs/{org}/teams/{team_slug}/projects/{project_id}\", {\n      mediaType: {\n        previews: [\"inertia\"]\n      }\n    }],\n    checkPermissionsForRepoInOrg: [\"GET /orgs/{org}/teams/{team_slug}/repos/{owner}/{repo}\"],\n    create: [\"POST /orgs/{org}/teams\"],\n    createDiscussionCommentInOrg: [\"POST /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/comments\"],\n    createDiscussionInOrg: [\"POST /orgs/{org}/teams/{team_slug}/discussions\"],\n    deleteDiscussionCommentInOrg: [\"DELETE /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/comments/{comment_number}\"],\n    deleteDiscussionInOrg: [\"DELETE /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}\"],\n    deleteInOrg: [\"DELETE /orgs/{org}/teams/{team_slug}\"],\n    getByName: [\"GET /orgs/{org}/teams/{team_slug}\"],\n    getDiscussionCommentInOrg: [\"GET /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/comments/{comment_number}\"],\n    getDiscussionInOrg: [\"GET /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}\"],\n    getMembershipForUserInOrg: [\"GET /orgs/{org}/teams/{team_slug}/memberships/{username}\"],\n    list: [\"GET /orgs/{org}/teams\"],\n    listChildInOrg: [\"GET /orgs/{org}/teams/{team_slug}/teams\"],\n    listDiscussionCommentsInOrg: [\"GET /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/comments\"],\n    listDiscussionsInOrg: [\"GET /orgs/{org}/teams/{team_slug}/discussions\"],\n    listForAuthenticatedUser: [\"GET /user/teams\"],\n    listMembersInOrg: [\"GET /orgs/{org}/teams/{team_slug}/members\"],\n    listPendingInvitationsInOrg: [\"GET /orgs/{org}/teams/{team_slug}/invitations\"],\n    listProjectsInOrg: [\"GET /orgs/{org}/teams/{team_slug}/projects\", {\n      mediaType: {\n        previews: [\"inertia\"]\n      }\n    }],\n    listReposInOrg: [\"GET /orgs/{org}/teams/{team_slug}/repos\"],\n    removeMembershipForUserInOrg: [\"DELETE /orgs/{org}/teams/{team_slug}/memberships/{username}\"],\n    removeProjectInOrg: [\"DELETE /orgs/{org}/teams/{team_slug}/projects/{project_id}\"],\n    removeRepoInOrg: [\"DELETE /orgs/{org}/teams/{team_slug}/repos/{owner}/{repo}\"],\n    updateDiscussionCommentInOrg: [\"PATCH /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/comments/{comment_number}\"],\n    updateDiscussionInOrg: [\"PATCH /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}\"],\n    updateInOrg: [\"PATCH /orgs/{org}/teams/{team_slug}\"]\n  },\n  users: {\n    addEmailForAuthenticated: [\"POST /user/emails\"],\n    block: [\"PUT /user/blocks/{username}\"],\n    checkBlocked: [\"GET /user/blocks/{username}\"],\n    checkFollowingForUser: [\"GET /users/{username}/following/{target_user}\"],\n    checkPersonIsFollowedByAuthenticated: [\"GET /user/following/{username}\"],\n    createGpgKeyForAuthenticated: [\"POST /user/gpg_keys\"],\n    createPublicSshKeyForAuthenticated: [\"POST /user/keys\"],\n    deleteEmailForAuthenticated: [\"DELETE /user/emails\"],\n    deleteGpgKeyForAuthenticated: [\"DELETE /user/gpg_keys/{gpg_key_id}\"],\n    deletePublicSshKeyForAuthenticated: [\"DELETE /user/keys/{key_id}\"],\n    follow: [\"PUT /user/following/{username}\"],\n    getAuthenticated: [\"GET /user\"],\n    getByUsername: [\"GET /users/{username}\"],\n    getContextForUser: [\"GET /users/{username}/hovercard\"],\n    getGpgKeyForAuthenticated: [\"GET /user/gpg_keys/{gpg_key_id}\"],\n    getPublicSshKeyForAuthenticated: [\"GET /user/keys/{key_id}\"],\n    list: [\"GET /users\"],\n    listBlockedByAuthenticated: [\"GET /user/blocks\"],\n    listEmailsForAuthenticated: [\"GET /user/emails\"],\n    listFollowedByAuthenticated: [\"GET /user/following\"],\n    listFollowersForAuthenticatedUser: [\"GET /user/followers\"],\n    listFollowersForUser: [\"GET /users/{username}/followers\"],\n    listFollowingForUser: [\"GET /users/{username}/following\"],\n    listGpgKeysForAuthenticated: [\"GET /user/gpg_keys\"],\n    listGpgKeysForUser: [\"GET /users/{username}/gpg_keys\"],\n    listPublicEmailsForAuthenticated: [\"GET /user/public_emails\"],\n    listPublicKeysForUser: [\"GET /users/{username}/keys\"],\n    listPublicSshKeysForAuthenticated: [\"GET /user/keys\"],\n    setPrimaryEmailVisibilityForAuthenticated: [\"PATCH /user/email/visibility\"],\n    unblock: [\"DELETE /user/blocks/{username}\"],\n    unfollow: [\"DELETE /user/following/{username}\"],\n    updateAuthenticated: [\"PATCH /user\"]\n  }\n};\n\nconst VERSION = \"4.13.5\";\n\nfunction endpointsToMethods(octokit, endpointsMap) {\n  const newMethods = {};\n\n  for (const [scope, endpoints] of Object.entries(endpointsMap)) {\n    for (const [methodName, endpoint] of Object.entries(endpoints)) {\n      const [route, defaults, decorations] = endpoint;\n      const [method, url] = route.split(/ /);\n      const endpointDefaults = Object.assign({\n        method,\n        url\n      }, defaults);\n\n      if (!newMethods[scope]) {\n        newMethods[scope] = {};\n      }\n\n      const scopeMethods = newMethods[scope];\n\n      if (decorations) {\n        scopeMethods[methodName] = decorate(octokit, scope, methodName, endpointDefaults, decorations);\n        continue;\n      }\n\n      scopeMethods[methodName] = octokit.request.defaults(endpointDefaults);\n    }\n  }\n\n  return newMethods;\n}\n\nfunction decorate(octokit, scope, methodName, defaults, decorations) {\n  const requestWithDefaults = octokit.request.defaults(defaults);\n  /* istanbul ignore next */\n\n  function withDecorations(...args) {\n    // @ts-ignore https://github.com/microsoft/TypeScript/issues/25488\n    let options = requestWithDefaults.endpoint.merge(...args); // There are currently no other decorations than `.mapToData`\n\n    if (decorations.mapToData) {\n      options = Object.assign({}, options, {\n        data: options[decorations.mapToData],\n        [decorations.mapToData]: undefined\n      });\n      return requestWithDefaults(options);\n    }\n\n    if (decorations.renamed) {\n      const [newScope, newMethodName] = decorations.renamed;\n      octokit.log.warn(`octokit.${scope}.${methodName}() has been renamed to octokit.${newScope}.${newMethodName}()`);\n    }\n\n    if (decorations.deprecated) {\n      octokit.log.warn(decorations.deprecated);\n    }\n\n    if (decorations.renamedParameters) {\n      // @ts-ignore https://github.com/microsoft/TypeScript/issues/25488\n      const options = requestWithDefaults.endpoint.merge(...args);\n\n      for (const [name, alias] of Object.entries(decorations.renamedParameters)) {\n        if (name in options) {\n          octokit.log.warn(`\"${name}\" parameter is deprecated for \"octokit.${scope}.${methodName}()\". Use \"${alias}\" instead`);\n\n          if (!(alias in options)) {\n            options[alias] = options[name];\n          }\n\n          delete options[name];\n        }\n      }\n\n      return requestWithDefaults(options);\n    } // @ts-ignore https://github.com/microsoft/TypeScript/issues/25488\n\n\n    return requestWithDefaults(...args);\n  }\n\n  return Object.assign(withDecorations, requestWithDefaults);\n}\n\nfunction restEndpointMethods(octokit) {\n  return endpointsToMethods(octokit, Endpoints);\n}\nrestEndpointMethods.VERSION = VERSION;\n\nexports.restEndpointMethods = restEndpointMethods;\n//# sourceMappingURL=index.js.map\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nfunction _interopDefault (ex) { return (ex && (typeof ex === 'object') && 'default' in ex) ? ex['default'] : ex; }\n\nvar deprecation = require('deprecation');\nvar once = _interopDefault(require('once'));\n\nconst logOnce = once(deprecation => console.warn(deprecation));\n/**\n * Error with extra properties to help with debugging\n */\n\nclass RequestError extends Error {\n  constructor(message, statusCode, options) {\n    super(message); // Maintains proper stack trace (only available on V8)\n\n    /* istanbul ignore next */\n\n    if (Error.captureStackTrace) {\n      Error.captureStackTrace(this, this.constructor);\n    }\n\n    this.name = \"HttpError\";\n    this.status = statusCode;\n    Object.defineProperty(this, \"code\", {\n      get() {\n        logOnce(new deprecation.Deprecation(\"[@octokit/request-error] `error.code` is deprecated, use `error.status`.\"));\n        return statusCode;\n      }\n\n    });\n    this.headers = options.headers || {}; // redact request credentials without mutating original request options\n\n    const requestCopy = Object.assign({}, options.request);\n\n    if (options.request.headers.authorization) {\n      requestCopy.headers = Object.assign({}, options.request.headers, {\n        authorization: options.request.headers.authorization.replace(/ .*$/, \" [REDACTED]\")\n      });\n    }\n\n    requestCopy.url = requestCopy.url // client_id & client_secret can be passed as URL query parameters to increase rate limit\n    // see https://developer.github.com/v3/#increasing-the-unauthenticated-rate-limit-for-oauth-applications\n    .replace(/\\bclient_secret=\\w+/g, \"client_secret=[REDACTED]\") // OAuth tokens can be passed as URL query parameters, although it is not recommended\n    // see https://developer.github.com/v3/#oauth2-token-sent-in-a-header\n    .replace(/\\baccess_token=\\w+/g, \"access_token=[REDACTED]\");\n    this.request = requestCopy;\n  }\n\n}\n\nexports.RequestError = RequestError;\n//# sourceMappingURL=index.js.map\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nfunction _interopDefault (ex) { return (ex && (typeof ex === 'object') && 'default' in ex) ? ex['default'] : ex; }\n\nvar endpoint = require('@octokit/endpoint');\nvar universalUserAgent = require('universal-user-agent');\nvar isPlainObject = require('is-plain-object');\nvar nodeFetch = _interopDefault(require('node-fetch'));\nvar requestError = require('@octokit/request-error');\n\nconst VERSION = \"5.4.14\";\n\nfunction getBufferResponse(response) {\n  return response.arrayBuffer();\n}\n\nfunction fetchWrapper(requestOptions) {\n  if (isPlainObject.isPlainObject(requestOptions.body) || Array.isArray(requestOptions.body)) {\n    requestOptions.body = JSON.stringify(requestOptions.body);\n  }\n\n  let headers = {};\n  let status;\n  let url;\n  const fetch = requestOptions.request && requestOptions.request.fetch || nodeFetch;\n  return fetch(requestOptions.url, Object.assign({\n    method: requestOptions.method,\n    body: requestOptions.body,\n    headers: requestOptions.headers,\n    redirect: requestOptions.redirect\n  }, requestOptions.request)).then(response => {\n    url = response.url;\n    status = response.status;\n\n    for (const keyAndValue of response.headers) {\n      headers[keyAndValue[0]] = keyAndValue[1];\n    }\n\n    if (status === 204 || status === 205) {\n      return;\n    } // GitHub API returns 200 for HEAD requests\n\n\n    if (requestOptions.method === \"HEAD\") {\n      if (status < 400) {\n        return;\n      }\n\n      throw new requestError.RequestError(response.statusText, status, {\n        headers,\n        request: requestOptions\n      });\n    }\n\n    if (status === 304) {\n      throw new requestError.RequestError(\"Not modified\", status, {\n        headers,\n        request: requestOptions\n      });\n    }\n\n    if (status >= 400) {\n      return response.text().then(message => {\n        const error = new requestError.RequestError(message, status, {\n          headers,\n          request: requestOptions\n        });\n\n        try {\n          let responseBody = JSON.parse(error.message);\n          Object.assign(error, responseBody);\n          let errors = responseBody.errors; // Assumption `errors` would always be in Array format\n\n          error.message = error.message + \": \" + errors.map(JSON.stringify).join(\", \");\n        } catch (e) {// ignore, see octokit/rest.js#684\n        }\n\n        throw error;\n      });\n    }\n\n    const contentType = response.headers.get(\"content-type\");\n\n    if (/application\\/json/.test(contentType)) {\n      return response.json();\n    }\n\n    if (!contentType || /^text\\/|charset=utf-8$/.test(contentType)) {\n      return response.text();\n    }\n\n    return getBufferResponse(response);\n  }).then(data => {\n    return {\n      status,\n      url,\n      headers,\n      data\n    };\n  }).catch(error => {\n    if (error instanceof requestError.RequestError) {\n      throw error;\n    }\n\n    throw new requestError.RequestError(error.message, 500, {\n      headers,\n      request: requestOptions\n    });\n  });\n}\n\nfunction withDefaults(oldEndpoint, newDefaults) {\n  const endpoint = oldEndpoint.defaults(newDefaults);\n\n  const newApi = function (route, parameters) {\n    const endpointOptions = endpoint.merge(route, parameters);\n\n    if (!endpointOptions.request || !endpointOptions.request.hook) {\n      return fetchWrapper(endpoint.parse(endpointOptions));\n    }\n\n    const request = (route, parameters) => {\n      return fetchWrapper(endpoint.parse(endpoint.merge(route, parameters)));\n    };\n\n    Object.assign(request, {\n      endpoint,\n      defaults: withDefaults.bind(null, endpoint)\n    });\n    return endpointOptions.request.hook(request, endpointOptions);\n  };\n\n  return Object.assign(newApi, {\n    endpoint,\n    defaults: withDefaults.bind(null, endpoint)\n  });\n}\n\nconst request = withDefaults(endpoint.endpoint, {\n  headers: {\n    \"user-agent\": `octokit-request.js/${VERSION} ${universalUserAgent.getUserAgent()}`\n  }\n});\n\nexports.request = request;\n//# sourceMappingURL=index.js.map\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\n/*!\n * is-plain-object <https://github.com/jonschlinkert/is-plain-object>\n *\n * Copyright (c) 2014-2017, Jon Schlinkert.\n * Released under the MIT License.\n */\n\nfunction isObject(o) {\n  return Object.prototype.toString.call(o) === '[object Object]';\n}\n\nfunction isPlainObject(o) {\n  var ctor,prot;\n\n  if (isObject(o) === false) return false;\n\n  // If has modified constructor\n  ctor = o.constructor;\n  if (ctor === undefined) return true;\n\n  // If has modified prototype\n  prot = ctor.prototype;\n  if (isObject(prot) === false) return false;\n\n  // If constructor does not have an Object-specific method\n  if (prot.hasOwnProperty('isPrototypeOf') === false) {\n    return false;\n  }\n\n  // Most likely a plain Object\n  return true;\n}\n\nexports.isPlainObject = isPlainObject;\n","'use strict'\n\nmodule.exports = bail\n\nfunction bail(err) {\n  if (err) {\n    throw err\n  }\n}\n","var register = require('./lib/register')\nvar addHook = require('./lib/add')\nvar removeHook = require('./lib/remove')\n\n// bind with array of arguments: https://stackoverflow.com/a/21792913\nvar bind = Function.bind\nvar bindable = bind.bind(bind)\n\nfunction bindApi (hook, state, name) {\n  var removeHookRef = bindable(removeHook, null).apply(null, name ? [state, name] : [state])\n  hook.api = { remove: removeHookRef }\n  hook.remove = removeHookRef\n\n  ;['before', 'error', 'after', 'wrap'].forEach(function (kind) {\n    var args = name ? [state, kind, name] : [state, kind]\n    hook[kind] = hook.api[kind] = bindable(addHook, null).apply(null, args)\n  })\n}\n\nfunction HookSingular () {\n  var singularHookName = 'h'\n  var singularHookState = {\n    registry: {}\n  }\n  var singularHook = register.bind(null, singularHookState, singularHookName)\n  bindApi(singularHook, singularHookState, singularHookName)\n  return singularHook\n}\n\nfunction HookCollection () {\n  var state = {\n    registry: {}\n  }\n\n  var hook = register.bind(null, state)\n  bindApi(hook, state)\n\n  return hook\n}\n\nvar collectionHookDeprecationMessageDisplayed = false\nfunction Hook () {\n  if (!collectionHookDeprecationMessageDisplayed) {\n    console.warn('[before-after-hook]: \"Hook()\" repurposing warning, use \"Hook.Collection()\". Read more: https://git.io/upgrade-before-after-hook-to-1.4')\n    collectionHookDeprecationMessageDisplayed = true\n  }\n  return HookCollection()\n}\n\nHook.Singular = HookSingular.bind()\nHook.Collection = HookCollection.bind()\n\nmodule.exports = Hook\n// expose constructors as a named property for TypeScript\nmodule.exports.Hook = Hook\nmodule.exports.Singular = Hook.Singular\nmodule.exports.Collection = Hook.Collection\n","module.exports = addHook;\n\nfunction addHook(state, kind, name, hook) {\n  var orig = hook;\n  if (!state.registry[name]) {\n    state.registry[name] = [];\n  }\n\n  if (kind === \"before\") {\n    hook = function (method, options) {\n      return Promise.resolve()\n        .then(orig.bind(null, options))\n        .then(method.bind(null, options));\n    };\n  }\n\n  if (kind === \"after\") {\n    hook = function (method, options) {\n      var result;\n      return Promise.resolve()\n        .then(method.bind(null, options))\n        .then(function (result_) {\n          result = result_;\n          return orig(result, options);\n        })\n        .then(function () {\n          return result;\n        });\n    };\n  }\n\n  if (kind === \"error\") {\n    hook = function (method, options) {\n      return Promise.resolve()\n        .then(method.bind(null, options))\n        .catch(function (error) {\n          return orig(error, options);\n        });\n    };\n  }\n\n  state.registry[name].push({\n    hook: hook,\n    orig: orig,\n  });\n}\n","module.exports = register;\n\nfunction register(state, name, method, options) {\n  if (typeof method !== \"function\") {\n    throw new Error(\"method for before hook must be a function\");\n  }\n\n  if (!options) {\n    options = {};\n  }\n\n  if (Array.isArray(name)) {\n    return name.reverse().reduce(function (callback, name) {\n      return register.bind(null, state, name, callback, options);\n    }, method)();\n  }\n\n  return Promise.resolve().then(function () {\n    if (!state.registry[name]) {\n      return method(options);\n    }\n\n    return state.registry[name].reduce(function (method, registered) {\n      return registered.hook.bind(null, method, options);\n    }, method)();\n  });\n}\n","module.exports = removeHook;\n\nfunction removeHook(state, name, method) {\n  if (!state.registry[name]) {\n    return;\n  }\n\n  var index = state.registry[name]\n    .map(function (registered) {\n      return registered.orig;\n    })\n    .indexOf(method);\n\n  if (index === -1) {\n    return;\n  }\n\n  state.registry[name].splice(index, 1);\n}\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nclass Deprecation extends Error {\n  constructor(message) {\n    super(message); // Maintains proper stack trace (only available on V8)\n\n    /* istanbul ignore next */\n\n    if (Error.captureStackTrace) {\n      Error.captureStackTrace(this, this.constructor);\n    }\n\n    this.name = 'Deprecation';\n  }\n\n}\n\nexports.Deprecation = Deprecation;\n","'use strict';\n\nvar hasOwn = Object.prototype.hasOwnProperty;\nvar toStr = Object.prototype.toString;\nvar defineProperty = Object.defineProperty;\nvar gOPD = Object.getOwnPropertyDescriptor;\n\nvar isArray = function isArray(arr) {\n\tif (typeof Array.isArray === 'function') {\n\t\treturn Array.isArray(arr);\n\t}\n\n\treturn toStr.call(arr) === '[object Array]';\n};\n\nvar isPlainObject = function isPlainObject(obj) {\n\tif (!obj || toStr.call(obj) !== '[object Object]') {\n\t\treturn false;\n\t}\n\n\tvar hasOwnConstructor = hasOwn.call(obj, 'constructor');\n\tvar hasIsPrototypeOf = obj.constructor && obj.constructor.prototype && hasOwn.call(obj.constructor.prototype, 'isPrototypeOf');\n\t// Not own constructor property must be Object\n\tif (obj.constructor && !hasOwnConstructor && !hasIsPrototypeOf) {\n\t\treturn false;\n\t}\n\n\t// Own properties are enumerated firstly, so to speed up,\n\t// if last one is own, then all properties are own.\n\tvar key;\n\tfor (key in obj) { /**/ }\n\n\treturn typeof key === 'undefined' || hasOwn.call(obj, key);\n};\n\n// If name is '__proto__', and Object.defineProperty is available, define __proto__ as an own property on target\nvar setProperty = function setProperty(target, options) {\n\tif (defineProperty && options.name === '__proto__') {\n\t\tdefineProperty(target, options.name, {\n\t\t\tenumerable: true,\n\t\t\tconfigurable: true,\n\t\t\tvalue: options.newValue,\n\t\t\twritable: true\n\t\t});\n\t} else {\n\t\ttarget[options.name] = options.newValue;\n\t}\n};\n\n// Return undefined instead of __proto__ if '__proto__' is not an own property\nvar getProperty = function getProperty(obj, name) {\n\tif (name === '__proto__') {\n\t\tif (!hasOwn.call(obj, name)) {\n\t\t\treturn void 0;\n\t\t} else if (gOPD) {\n\t\t\t// In early versions of node, obj['__proto__'] is buggy when obj has\n\t\t\t// __proto__ as an own property. Object.getOwnPropertyDescriptor() works.\n\t\t\treturn gOPD(obj, name).value;\n\t\t}\n\t}\n\n\treturn obj[name];\n};\n\nmodule.exports = function extend() {\n\tvar options, name, src, copy, copyIsArray, clone;\n\tvar target = arguments[0];\n\tvar i = 1;\n\tvar length = arguments.length;\n\tvar deep = false;\n\n\t// Handle a deep copy situation\n\tif (typeof target === 'boolean') {\n\t\tdeep = target;\n\t\ttarget = arguments[1] || {};\n\t\t// skip the boolean and the target\n\t\ti = 2;\n\t}\n\tif (target == null || (typeof target !== 'object' && typeof target !== 'function')) {\n\t\ttarget = {};\n\t}\n\n\tfor (; i < length; ++i) {\n\t\toptions = arguments[i];\n\t\t// Only deal with non-null/undefined values\n\t\tif (options != null) {\n\t\t\t// Extend the base object\n\t\t\tfor (name in options) {\n\t\t\t\tsrc = getProperty(target, name);\n\t\t\t\tcopy = getProperty(options, name);\n\n\t\t\t\t// Prevent never-ending loop\n\t\t\t\tif (target !== copy) {\n\t\t\t\t\t// Recurse if we're merging plain objects or arrays\n\t\t\t\t\tif (deep && copy && (isPlainObject(copy) || (copyIsArray = isArray(copy)))) {\n\t\t\t\t\t\tif (copyIsArray) {\n\t\t\t\t\t\t\tcopyIsArray = false;\n\t\t\t\t\t\t\tclone = src && isArray(src) ? src : [];\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tclone = src && isPlainObject(src) ? src : {};\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// Never move original objects, clone them\n\t\t\t\t\t\tsetProperty(target, { name: name, newValue: extend(deep, clone, copy) });\n\n\t\t\t\t\t// Don't bring in undefined values\n\t\t\t\t\t} else if (typeof copy !== 'undefined') {\n\t\t\t\t\t\tsetProperty(target, { name: name, newValue: copy });\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// Return the modified object\n\treturn target;\n};\n","'use strict'\n\nvar formatter = require('format')\n\nvar fault = create(Error)\n\nmodule.exports = fault\n\nfault.eval = create(EvalError)\nfault.range = create(RangeError)\nfault.reference = create(ReferenceError)\nfault.syntax = create(SyntaxError)\nfault.type = create(TypeError)\nfault.uri = create(URIError)\n\nfault.create = create\n\n// Create a new `EConstructor`, with the formatted `format` as a first argument.\nfunction create(EConstructor) {\n  FormattedError.displayName = EConstructor.displayName || EConstructor.name\n\n  return FormattedError\n\n  function FormattedError(format) {\n    if (format) {\n      format = formatter.apply(null, arguments)\n    }\n\n    return new EConstructor(format)\n  }\n}\n","//\n// format - printf-like string formatting for JavaScript\n// github.com/samsonjs/format\n// @_sjs\n//\n// Copyright 2010 - 2013 Sami Samhuri <sami@samhuri.net>\n//\n// MIT License\n// http://sjs.mit-license.org\n//\n\n;(function() {\n\n  //// Export the API\n  var namespace;\n\n  // CommonJS / Node module\n  if (typeof module !== 'undefined') {\n    namespace = module.exports = format;\n  }\n\n  // Browsers and other environments\n  else {\n    // Get the global object. Works in ES3, ES5, and ES5 strict mode.\n    namespace = (function(){ return this || (1,eval)('this') }());\n  }\n\n  namespace.format = format;\n  namespace.vsprintf = vsprintf;\n\n  if (typeof console !== 'undefined' && typeof console.log === 'function') {\n    namespace.printf = printf;\n  }\n\n  function printf(/* ... */) {\n    console.log(format.apply(null, arguments));\n  }\n\n  function vsprintf(fmt, replacements) {\n    return format.apply(null, [fmt].concat(replacements));\n  }\n\n  function format(fmt) {\n    var argIndex = 1 // skip initial format argument\n      , args = [].slice.call(arguments)\n      , i = 0\n      , n = fmt.length\n      , result = ''\n      , c\n      , escaped = false\n      , arg\n      , tmp\n      , leadingZero = false\n      , precision\n      , nextArg = function() { return args[argIndex++]; }\n      , slurpNumber = function() {\n          var digits = '';\n          while (/\\d/.test(fmt[i])) {\n            digits += fmt[i++];\n            c = fmt[i];\n          }\n          return digits.length > 0 ? parseInt(digits) : null;\n        }\n      ;\n    for (; i < n; ++i) {\n      c = fmt[i];\n      if (escaped) {\n        escaped = false;\n        if (c == '.') {\n          leadingZero = false;\n          c = fmt[++i];\n        }\n        else if (c == '0' && fmt[i + 1] == '.') {\n          leadingZero = true;\n          i += 2;\n          c = fmt[i];\n        }\n        else {\n          leadingZero = true;\n        }\n        precision = slurpNumber();\n        switch (c) {\n        case 'b': // number in binary\n          result += parseInt(nextArg(), 10).toString(2);\n          break;\n        case 'c': // character\n          arg = nextArg();\n          if (typeof arg === 'string' || arg instanceof String)\n            result += arg;\n          else\n            result += String.fromCharCode(parseInt(arg, 10));\n          break;\n        case 'd': // number in decimal\n          result += parseInt(nextArg(), 10);\n          break;\n        case 'f': // floating point number\n          tmp = String(parseFloat(nextArg()).toFixed(precision || 6));\n          result += leadingZero ? tmp : tmp.replace(/^0/, '');\n          break;\n        case 'j': // JSON\n          result += JSON.stringify(nextArg());\n          break;\n        case 'o': // number in octal\n          result += '0' + parseInt(nextArg(), 10).toString(8);\n          break;\n        case 's': // string\n          result += nextArg();\n          break;\n        case 'x': // lowercase hexadecimal\n          result += '0x' + parseInt(nextArg(), 10).toString(16);\n          break;\n        case 'X': // uppercase hexadecimal\n          result += '0x' + parseInt(nextArg(), 10).toString(16).toUpperCase();\n          break;\n        default:\n          result += c;\n          break;\n        }\n      } else if (c === '%') {\n        escaped = true;\n      } else {\n        result += c;\n      }\n    }\n    return result;\n  }\n\n}());\n","'use strict';\n\nmodule.exports = value => {\n\tif (Object.prototype.toString.call(value) !== '[object Object]') {\n\t\treturn false;\n\t}\n\n\tconst prototype = Object.getPrototypeOf(value);\n\treturn prototype === null || prototype === Object.prototype;\n};\n","'use strict'\n\nmodule.exports = longestStreak\n\n// Get the count of the longest repeating streak of `character` in `value`.\nfunction longestStreak(value, character) {\n  var count = 0\n  var maximum = 0\n  var expected\n  var index\n\n  if (typeof character !== 'string' || character.length !== 1) {\n    throw new Error('Expected character')\n  }\n\n  value = String(value)\n  index = value.indexOf(character)\n  expected = index\n\n  while (index !== -1) {\n    count++\n\n    if (index === expected) {\n      if (count > maximum) {\n        maximum = count\n      }\n    } else {\n      count = 1\n    }\n\n    expected = index + 1\n    index = value.indexOf(character, expected)\n  }\n\n  return maximum\n}\n","'use strict'\n\nmodule.exports = fromMarkdown\n\n// These three are compiled away in the `dist/`\n\nvar toString = require('mdast-util-to-string')\nvar assign = require('micromark/dist/constant/assign')\nvar own = require('micromark/dist/constant/has-own-property')\nvar normalizeIdentifier = require('micromark/dist/util/normalize-identifier')\nvar safeFromInt = require('micromark/dist/util/safe-from-int')\nvar parser = require('micromark/dist/parse')\nvar preprocessor = require('micromark/dist/preprocess')\nvar postprocess = require('micromark/dist/postprocess')\nvar decode = require('parse-entities/decode-entity')\nvar stringifyPosition = require('unist-util-stringify-position')\n\nfunction fromMarkdown(value, encoding, options) {\n  if (typeof encoding !== 'string') {\n    options = encoding\n    encoding = undefined\n  }\n\n  return compiler(options)(\n    postprocess(\n      parser(options).document().write(preprocessor()(value, encoding, true))\n    )\n  )\n}\n\n// Note this compiler only understand complete buffering, not streaming.\nfunction compiler(options) {\n  var settings = options || {}\n  var config = configure(\n    {\n      transforms: [],\n      canContainEols: [\n        'emphasis',\n        'fragment',\n        'heading',\n        'paragraph',\n        'strong'\n      ],\n\n      enter: {\n        autolink: opener(link),\n        autolinkProtocol: onenterdata,\n        autolinkEmail: onenterdata,\n        atxHeading: opener(heading),\n        blockQuote: opener(blockQuote),\n        characterEscape: onenterdata,\n        characterReference: onenterdata,\n        codeFenced: opener(codeFlow),\n        codeFencedFenceInfo: buffer,\n        codeFencedFenceMeta: buffer,\n        codeIndented: opener(codeFlow, buffer),\n        codeText: opener(codeText, buffer),\n        codeTextData: onenterdata,\n        data: onenterdata,\n        codeFlowValue: onenterdata,\n        definition: opener(definition),\n        definitionDestinationString: buffer,\n        definitionLabelString: buffer,\n        definitionTitleString: buffer,\n        emphasis: opener(emphasis),\n        hardBreakEscape: opener(hardBreak),\n        hardBreakTrailing: opener(hardBreak),\n        htmlFlow: opener(html, buffer),\n        htmlFlowData: onenterdata,\n        htmlText: opener(html, buffer),\n        htmlTextData: onenterdata,\n        image: opener(image),\n        label: buffer,\n        link: opener(link),\n        listItem: opener(listItem),\n        listItemValue: onenterlistitemvalue,\n        listOrdered: opener(list, onenterlistordered),\n        listUnordered: opener(list),\n        paragraph: opener(paragraph),\n        reference: onenterreference,\n        referenceString: buffer,\n        resourceDestinationString: buffer,\n        resourceTitleString: buffer,\n        setextHeading: opener(heading),\n        strong: opener(strong),\n        thematicBreak: opener(thematicBreak)\n      },\n\n      exit: {\n        atxHeading: closer(),\n        atxHeadingSequence: onexitatxheadingsequence,\n        autolink: closer(),\n        autolinkEmail: onexitautolinkemail,\n        autolinkProtocol: onexitautolinkprotocol,\n        blockQuote: closer(),\n        characterEscapeValue: onexitdata,\n        characterReferenceMarkerHexadecimal: onexitcharacterreferencemarker,\n        characterReferenceMarkerNumeric: onexitcharacterreferencemarker,\n        characterReferenceValue: onexitcharacterreferencevalue,\n        codeFenced: closer(onexitcodefenced),\n        codeFencedFence: onexitcodefencedfence,\n        codeFencedFenceInfo: onexitcodefencedfenceinfo,\n        codeFencedFenceMeta: onexitcodefencedfencemeta,\n        codeFlowValue: onexitdata,\n        codeIndented: closer(onexitcodeindented),\n        codeText: closer(onexitcodetext),\n        codeTextData: onexitdata,\n        data: onexitdata,\n        definition: closer(),\n        definitionDestinationString: onexitdefinitiondestinationstring,\n        definitionLabelString: onexitdefinitionlabelstring,\n        definitionTitleString: onexitdefinitiontitlestring,\n        emphasis: closer(),\n        hardBreakEscape: closer(onexithardbreak),\n        hardBreakTrailing: closer(onexithardbreak),\n        htmlFlow: closer(onexithtmlflow),\n        htmlFlowData: onexitdata,\n        htmlText: closer(onexithtmltext),\n        htmlTextData: onexitdata,\n        image: closer(onexitimage),\n        label: onexitlabel,\n        labelText: onexitlabeltext,\n        lineEnding: onexitlineending,\n        link: closer(onexitlink),\n        listItem: closer(),\n        listOrdered: closer(),\n        listUnordered: closer(),\n        paragraph: closer(),\n        referenceString: onexitreferencestring,\n        resourceDestinationString: onexitresourcedestinationstring,\n        resourceTitleString: onexitresourcetitlestring,\n        resource: onexitresource,\n        setextHeading: closer(onexitsetextheading),\n        setextHeadingLineSequence: onexitsetextheadinglinesequence,\n        setextHeadingText: onexitsetextheadingtext,\n        strong: closer(),\n        thematicBreak: closer()\n      }\n    },\n\n    settings.mdastExtensions || []\n  )\n\n  var data = {}\n\n  return compile\n\n  function compile(events) {\n    var tree = {type: 'root', children: []}\n    var stack = [tree]\n    var tokenStack = []\n    var listStack = []\n    var index = -1\n    var handler\n    var listStart\n\n    var context = {\n      stack: stack,\n      tokenStack: tokenStack,\n      config: config,\n      enter: enter,\n      exit: exit,\n      buffer: buffer,\n      resume: resume,\n      setData: setData,\n      getData: getData\n    }\n\n    while (++index < events.length) {\n      // We preprocess lists to add `listItem` tokens, and to infer whether\n      // items the list itself are spread out.\n      if (\n        events[index][1].type === 'listOrdered' ||\n        events[index][1].type === 'listUnordered'\n      ) {\n        if (events[index][0] === 'enter') {\n          listStack.push(index)\n        } else {\n          listStart = listStack.pop(index)\n          index = prepareList(events, listStart, index)\n        }\n      }\n    }\n\n    index = -1\n\n    while (++index < events.length) {\n      handler = config[events[index][0]]\n\n      if (own.call(handler, events[index][1].type)) {\n        handler[events[index][1].type].call(\n          assign({sliceSerialize: events[index][2].sliceSerialize}, context),\n          events[index][1]\n        )\n      }\n    }\n\n    if (tokenStack.length) {\n      throw new Error(\n        'Cannot close document, a token (`' +\n          tokenStack[tokenStack.length - 1].type +\n          '`, ' +\n          stringifyPosition({\n            start: tokenStack[tokenStack.length - 1].start,\n            end: tokenStack[tokenStack.length - 1].end\n          }) +\n          ') is still open'\n      )\n    }\n\n    // Figure out `root` position.\n    tree.position = {\n      start: point(\n        events.length ? events[0][1].start : {line: 1, column: 1, offset: 0}\n      ),\n\n      end: point(\n        events.length\n          ? events[events.length - 2][1].end\n          : {line: 1, column: 1, offset: 0}\n      )\n    }\n\n    index = -1\n    while (++index < config.transforms.length) {\n      tree = config.transforms[index](tree) || tree\n    }\n\n    return tree\n  }\n\n  function prepareList(events, start, length) {\n    var index = start - 1\n    var containerBalance = -1\n    var listSpread = false\n    var listItem\n    var tailIndex\n    var lineIndex\n    var tailEvent\n    var event\n    var firstBlankLineIndex\n    var atMarker\n\n    while (++index <= length) {\n      event = events[index]\n\n      if (\n        event[1].type === 'listUnordered' ||\n        event[1].type === 'listOrdered' ||\n        event[1].type === 'blockQuote'\n      ) {\n        if (event[0] === 'enter') {\n          containerBalance++\n        } else {\n          containerBalance--\n        }\n\n        atMarker = undefined\n      } else if (event[1].type === 'lineEndingBlank') {\n        if (event[0] === 'enter') {\n          if (\n            listItem &&\n            !atMarker &&\n            !containerBalance &&\n            !firstBlankLineIndex\n          ) {\n            firstBlankLineIndex = index\n          }\n\n          atMarker = undefined\n        }\n      } else if (\n        event[1].type === 'linePrefix' ||\n        event[1].type === 'listItemValue' ||\n        event[1].type === 'listItemMarker' ||\n        event[1].type === 'listItemPrefix' ||\n        event[1].type === 'listItemPrefixWhitespace'\n      ) {\n        // Empty.\n      } else {\n        atMarker = undefined\n      }\n\n      if (\n        (!containerBalance &&\n          event[0] === 'enter' &&\n          event[1].type === 'listItemPrefix') ||\n        (containerBalance === -1 &&\n          event[0] === 'exit' &&\n          (event[1].type === 'listUnordered' ||\n            event[1].type === 'listOrdered'))\n      ) {\n        if (listItem) {\n          tailIndex = index\n          lineIndex = undefined\n\n          while (tailIndex--) {\n            tailEvent = events[tailIndex]\n\n            if (\n              tailEvent[1].type === 'lineEnding' ||\n              tailEvent[1].type === 'lineEndingBlank'\n            ) {\n              if (tailEvent[0] === 'exit') continue\n\n              if (lineIndex) {\n                events[lineIndex][1].type = 'lineEndingBlank'\n                listSpread = true\n              }\n\n              tailEvent[1].type = 'lineEnding'\n              lineIndex = tailIndex\n            } else if (\n              tailEvent[1].type === 'linePrefix' ||\n              tailEvent[1].type === 'blockQuotePrefix' ||\n              tailEvent[1].type === 'blockQuotePrefixWhitespace' ||\n              tailEvent[1].type === 'blockQuoteMarker' ||\n              tailEvent[1].type === 'listItemIndent'\n            ) {\n              // Empty\n            } else {\n              break\n            }\n          }\n\n          if (\n            firstBlankLineIndex &&\n            (!lineIndex || firstBlankLineIndex < lineIndex)\n          ) {\n            listItem._spread = true\n          }\n\n          // Fix position.\n          listItem.end = point(\n            lineIndex ? events[lineIndex][1].start : event[1].end\n          )\n\n          events.splice(lineIndex || index, 0, ['exit', listItem, event[2]])\n          index++\n          length++\n        }\n\n        // Create a new list item.\n        if (event[1].type === 'listItemPrefix') {\n          listItem = {\n            type: 'listItem',\n            _spread: false,\n            start: point(event[1].start)\n          }\n\n          events.splice(index, 0, ['enter', listItem, event[2]])\n          index++\n          length++\n          firstBlankLineIndex = undefined\n          atMarker = true\n        }\n      }\n    }\n\n    events[start][1]._spread = listSpread\n    return length\n  }\n\n  function setData(key, value) {\n    data[key] = value\n  }\n\n  function getData(key) {\n    return data[key]\n  }\n\n  function point(d) {\n    return {line: d.line, column: d.column, offset: d.offset}\n  }\n\n  function opener(create, and) {\n    return open\n\n    function open(token) {\n      enter.call(this, create(token), token)\n      if (and) and.call(this, token)\n    }\n  }\n\n  function buffer() {\n    this.stack.push({type: 'fragment', children: []})\n  }\n\n  function enter(node, token) {\n    this.stack[this.stack.length - 1].children.push(node)\n    this.stack.push(node)\n    this.tokenStack.push(token)\n    node.position = {start: point(token.start)}\n    return node\n  }\n\n  function closer(and) {\n    return close\n\n    function close(token) {\n      if (and) and.call(this, token)\n      exit.call(this, token)\n    }\n  }\n\n  function exit(token) {\n    var node = this.stack.pop()\n    var open = this.tokenStack.pop()\n\n    if (!open) {\n      throw new Error(\n        'Cannot close `' +\n          token.type +\n          '` (' +\n          stringifyPosition({start: token.start, end: token.end}) +\n          '): its not open'\n      )\n    } else if (open.type !== token.type) {\n      throw new Error(\n        'Cannot close `' +\n          token.type +\n          '` (' +\n          stringifyPosition({start: token.start, end: token.end}) +\n          '): a different token (`' +\n          open.type +\n          '`, ' +\n          stringifyPosition({start: open.start, end: open.end}) +\n          ') is open'\n      )\n    }\n\n    node.position.end = point(token.end)\n    return node\n  }\n\n  function resume() {\n    return toString(this.stack.pop())\n  }\n\n  //\n  // Handlers.\n  //\n\n  function onenterlistordered() {\n    setData('expectingFirstListItemValue', true)\n  }\n\n  function onenterlistitemvalue(token) {\n    if (getData('expectingFirstListItemValue')) {\n      this.stack[this.stack.length - 2].start = parseInt(\n        this.sliceSerialize(token),\n        10\n      )\n\n      setData('expectingFirstListItemValue')\n    }\n  }\n\n  function onexitcodefencedfenceinfo() {\n    var data = this.resume()\n    this.stack[this.stack.length - 1].lang = data\n  }\n\n  function onexitcodefencedfencemeta() {\n    var data = this.resume()\n    this.stack[this.stack.length - 1].meta = data\n  }\n\n  function onexitcodefencedfence() {\n    // Exit if this is the closing fence.\n    if (getData('flowCodeInside')) return\n    this.buffer()\n    setData('flowCodeInside', true)\n  }\n\n  function onexitcodefenced() {\n    var data = this.resume()\n    this.stack[this.stack.length - 1].value = data.replace(\n      /^(\\r?\\n|\\r)|(\\r?\\n|\\r)$/g,\n      ''\n    )\n\n    setData('flowCodeInside')\n  }\n\n  function onexitcodeindented() {\n    var data = this.resume()\n    this.stack[this.stack.length - 1].value = data\n  }\n\n  function onexitdefinitionlabelstring(token) {\n    // Discard label, use the source content instead.\n    var label = this.resume()\n    this.stack[this.stack.length - 1].label = label\n    this.stack[this.stack.length - 1].identifier = normalizeIdentifier(\n      this.sliceSerialize(token)\n    ).toLowerCase()\n  }\n\n  function onexitdefinitiontitlestring() {\n    var data = this.resume()\n    this.stack[this.stack.length - 1].title = data\n  }\n\n  function onexitdefinitiondestinationstring() {\n    var data = this.resume()\n    this.stack[this.stack.length - 1].url = data\n  }\n\n  function onexitatxheadingsequence(token) {\n    if (!this.stack[this.stack.length - 1].depth) {\n      this.stack[this.stack.length - 1].depth = this.sliceSerialize(\n        token\n      ).length\n    }\n  }\n\n  function onexitsetextheadingtext() {\n    setData('setextHeadingSlurpLineEnding', true)\n  }\n\n  function onexitsetextheadinglinesequence(token) {\n    this.stack[this.stack.length - 1].depth =\n      this.sliceSerialize(token).charCodeAt(0) === 61 ? 1 : 2\n  }\n\n  function onexitsetextheading() {\n    setData('setextHeadingSlurpLineEnding')\n  }\n\n  function onenterdata(token) {\n    var siblings = this.stack[this.stack.length - 1].children\n    var tail = siblings[siblings.length - 1]\n\n    if (!tail || tail.type !== 'text') {\n      // Add a new text node.\n      tail = text()\n      tail.position = {start: point(token.start)}\n      this.stack[this.stack.length - 1].children.push(tail)\n    }\n\n    this.stack.push(tail)\n  }\n\n  function onexitdata(token) {\n    var tail = this.stack.pop()\n    tail.value += this.sliceSerialize(token)\n    tail.position.end = point(token.end)\n  }\n\n  function onexitlineending(token) {\n    var context = this.stack[this.stack.length - 1]\n\n    // If were at a hard break, include the line ending in there.\n    if (getData('atHardBreak')) {\n      context.children[context.children.length - 1].position.end = point(\n        token.end\n      )\n\n      setData('atHardBreak')\n      return\n    }\n\n    if (\n      !getData('setextHeadingSlurpLineEnding') &&\n      config.canContainEols.indexOf(context.type) > -1\n    ) {\n      onenterdata.call(this, token)\n      onexitdata.call(this, token)\n    }\n  }\n\n  function onexithardbreak() {\n    setData('atHardBreak', true)\n  }\n\n  function onexithtmlflow() {\n    var data = this.resume()\n    this.stack[this.stack.length - 1].value = data\n  }\n\n  function onexithtmltext() {\n    var data = this.resume()\n    this.stack[this.stack.length - 1].value = data\n  }\n\n  function onexitcodetext() {\n    var data = this.resume()\n    this.stack[this.stack.length - 1].value = data\n  }\n\n  function onexitlink() {\n    var context = this.stack[this.stack.length - 1]\n\n    // To do: clean.\n    if (getData('inReference')) {\n      context.type += 'Reference'\n      context.referenceType = getData('referenceType') || 'shortcut'\n      delete context.url\n      delete context.title\n    } else {\n      delete context.identifier\n      delete context.label\n      delete context.referenceType\n    }\n\n    setData('referenceType')\n  }\n\n  function onexitimage() {\n    var context = this.stack[this.stack.length - 1]\n\n    // To do: clean.\n    if (getData('inReference')) {\n      context.type += 'Reference'\n      context.referenceType = getData('referenceType') || 'shortcut'\n      delete context.url\n      delete context.title\n    } else {\n      delete context.identifier\n      delete context.label\n      delete context.referenceType\n    }\n\n    setData('referenceType')\n  }\n\n  function onexitlabeltext(token) {\n    this.stack[this.stack.length - 2].identifier = normalizeIdentifier(\n      this.sliceSerialize(token)\n    ).toLowerCase()\n  }\n\n  function onexitlabel() {\n    var fragment = this.stack[this.stack.length - 1]\n    var value = this.resume()\n\n    this.stack[this.stack.length - 1].label = value\n\n    // Assume a reference.\n    setData('inReference', true)\n\n    if (this.stack[this.stack.length - 1].type === 'link') {\n      this.stack[this.stack.length - 1].children = fragment.children\n    } else {\n      this.stack[this.stack.length - 1].alt = value\n    }\n  }\n\n  function onexitresourcedestinationstring() {\n    var data = this.resume()\n    this.stack[this.stack.length - 1].url = data\n  }\n\n  function onexitresourcetitlestring() {\n    var data = this.resume()\n    this.stack[this.stack.length - 1].title = data\n  }\n\n  function onexitresource() {\n    setData('inReference')\n  }\n\n  function onenterreference() {\n    setData('referenceType', 'collapsed')\n  }\n\n  function onexitreferencestring(token) {\n    var label = this.resume()\n    this.stack[this.stack.length - 1].label = label\n    this.stack[this.stack.length - 1].identifier = normalizeIdentifier(\n      this.sliceSerialize(token)\n    ).toLowerCase()\n    setData('referenceType', 'full')\n  }\n\n  function onexitcharacterreferencemarker(token) {\n    setData('characterReferenceType', token.type)\n  }\n\n  function onexitcharacterreferencevalue(token) {\n    var data = this.sliceSerialize(token)\n    var type = getData('characterReferenceType')\n    var value\n    var tail\n\n    if (type) {\n      value = safeFromInt(\n        data,\n        type === 'characterReferenceMarkerNumeric' ? 10 : 16\n      )\n\n      setData('characterReferenceType')\n    } else {\n      value = decode(data)\n    }\n\n    tail = this.stack.pop()\n    tail.value += value\n    tail.position.end = point(token.end)\n  }\n\n  function onexitautolinkprotocol(token) {\n    onexitdata.call(this, token)\n    this.stack[this.stack.length - 1].url = this.sliceSerialize(token)\n  }\n\n  function onexitautolinkemail(token) {\n    onexitdata.call(this, token)\n    this.stack[this.stack.length - 1].url =\n      'mailto:' + this.sliceSerialize(token)\n  }\n\n  //\n  // Creaters.\n  //\n\n  function blockQuote() {\n    return {type: 'blockquote', children: []}\n  }\n\n  function codeFlow() {\n    return {type: 'code', lang: null, meta: null, value: ''}\n  }\n\n  function codeText() {\n    return {type: 'inlineCode', value: ''}\n  }\n\n  function definition() {\n    return {\n      type: 'definition',\n      identifier: '',\n      label: null,\n      title: null,\n      url: ''\n    }\n  }\n\n  function emphasis() {\n    return {type: 'emphasis', children: []}\n  }\n\n  function heading() {\n    return {type: 'heading', depth: undefined, children: []}\n  }\n\n  function hardBreak() {\n    return {type: 'break'}\n  }\n\n  function html() {\n    return {type: 'html', value: ''}\n  }\n\n  function image() {\n    return {type: 'image', title: null, url: '', alt: null}\n  }\n\n  function link() {\n    return {type: 'link', title: null, url: '', children: []}\n  }\n\n  function list(token) {\n    return {\n      type: 'list',\n      ordered: token.type === 'listOrdered',\n      start: null,\n      spread: token._spread,\n      children: []\n    }\n  }\n\n  function listItem(token) {\n    return {\n      type: 'listItem',\n      spread: token._spread,\n      checked: null,\n      children: []\n    }\n  }\n\n  function paragraph() {\n    return {type: 'paragraph', children: []}\n  }\n\n  function strong() {\n    return {type: 'strong', children: []}\n  }\n\n  function text() {\n    return {type: 'text', value: ''}\n  }\n\n  function thematicBreak() {\n    return {type: 'thematicBreak'}\n  }\n}\n\nfunction configure(config, extensions) {\n  var index = -1\n\n  while (++index < extensions.length) {\n    extension(config, extensions[index])\n  }\n\n  return config\n}\n\nfunction extension(config, extension) {\n  var key\n  var left\n\n  for (key in extension) {\n    left = own.call(config, key) ? config[key] : (config[key] = {})\n\n    if (key === 'canContainEols' || key === 'transforms') {\n      config[key] = [].concat(left, extension[key])\n    } else {\n      Object.assign(left, extension[key])\n    }\n  }\n}\n","'use strict'\n\nmodule.exports = require('./dist')\n","module.exports = createFromMarkdown\n\nvar matters = require('micromark-extension-frontmatter/lib/matters')\n\nfunction createFromMarkdown(options) {\n  var settings = matters(options)\n  var length = settings.length\n  var index = -1\n  var enter = {}\n  var exit = {}\n  var matter\n\n  while (++index < length) {\n    matter = settings[index]\n    enter[matter.type] = opener(matter)\n    exit[matter.type] = close\n    exit[matter.type + 'Value'] = value\n  }\n\n  return {enter: enter, exit: exit}\n}\n\nfunction opener(matter) {\n  return open\n  function open(token) {\n    this.enter({type: matter.type, value: ''}, token)\n    this.buffer()\n  }\n}\n\nfunction close(token) {\n  var data = this.resume()\n  // Remove the initial and final eol.\n  this.exit(token).value = data.replace(/^(\\r?\\n|\\r)|(\\r?\\n|\\r)$/g, '')\n}\n\nfunction value(token) {\n  this.config.enter.data.call(this, token)\n  this.config.exit.data.call(this, token)\n}\n","module.exports = createToMarkdown\n\nvar matters = require('micromark-extension-frontmatter/lib/matters')\n\nfunction createToMarkdown(options) {\n  var unsafe = []\n  var handlers = {}\n  var settings = matters(options)\n  var length = settings.length\n  var index = -1\n  var matter\n\n  while (++index < length) {\n    matter = settings[index]\n    handlers[matter.type] = handler(matter)\n    unsafe.push({atBreak: true, character: fence(matter, 'open').charAt(0)})\n  }\n\n  return {unsafe: unsafe, handlers: handlers}\n}\n\nfunction handler(matter) {\n  var open = fence(matter, 'open')\n  var close = fence(matter, 'close')\n\n  return handle\n\n  function handle(node) {\n    return open + (node.value ? '\\n' + node.value : '') + '\\n' + close\n  }\n}\n\nfunction fence(matter, prop) {\n  var marker\n\n  if (matter.marker) {\n    marker = pick(matter.marker, prop)\n    return marker + marker + marker\n  }\n\n  return pick(matter.fence, prop)\n}\n\nfunction pick(schema, prop) {\n  return typeof schema === 'string' ? schema : schema[prop]\n}\n","module.exports = require('./lib')\n","module.exports = configure\n\nfunction configure(base, extension) {\n  var index = -1\n  var key\n\n  // First do subextensions.\n  if (extension.extensions) {\n    while (++index < extension.extensions.length) {\n      configure(base, extension.extensions[index])\n    }\n  }\n\n  for (key in extension) {\n    if (key === 'extensions') {\n      // Empty.\n    } else if (key === 'unsafe' || key === 'join') {\n      base[key] = base[key].concat(extension[key] || [])\n    } else if (key === 'handlers') {\n      base[key] = Object.assign(base[key], extension[key] || {})\n    } else {\n      base.options[key] = extension[key]\n    }\n  }\n\n  return base\n}\n","module.exports = blockquote\n\nvar flow = require('../util/container-flow')\nvar indentLines = require('../util/indent-lines')\n\nfunction blockquote(node, _, context) {\n  var exit = context.enter('blockquote')\n  var value = indentLines(flow(node, context), map)\n  exit()\n  return value\n}\n\nfunction map(line, index, blank) {\n  return '>' + (blank ? '' : ' ') + line\n}\n","module.exports = hardBreak\n\nvar patternInScope = require('../util/pattern-in-scope')\n\nfunction hardBreak(node, _, context, safe) {\n  var index = -1\n\n  while (++index < context.unsafe.length) {\n    // If we cant put eols in this construct (setext headings, tables), use a\n    // space instead.\n    if (\n      context.unsafe[index].character === '\\n' &&\n      patternInScope(context.stack, context.unsafe[index])\n    ) {\n      return /[ \\t]/.test(safe.before) ? '' : ' '\n    }\n  }\n\n  return '\\\\\\n'\n}\n","module.exports = code\n\nvar repeat = require('repeat-string')\nvar streak = require('longest-streak')\nvar formatCodeAsIndented = require('../util/format-code-as-indented')\nvar checkFence = require('../util/check-fence')\nvar indentLines = require('../util/indent-lines')\nvar safe = require('../util/safe')\n\nfunction code(node, _, context) {\n  var marker = checkFence(context)\n  var raw = node.value || ''\n  var suffix = marker === '`' ? 'GraveAccent' : 'Tilde'\n  var value\n  var sequence\n  var exit\n  var subexit\n\n  if (formatCodeAsIndented(node, context)) {\n    exit = context.enter('codeIndented')\n    value = indentLines(raw, map)\n  } else {\n    sequence = repeat(marker, Math.max(streak(raw, marker) + 1, 3))\n    exit = context.enter('codeFenced')\n    value = sequence\n\n    if (node.lang) {\n      subexit = context.enter('codeFencedLang' + suffix)\n      value += safe(context, node.lang, {\n        before: '`',\n        after: ' ',\n        encode: ['`']\n      })\n      subexit()\n    }\n\n    if (node.lang && node.meta) {\n      subexit = context.enter('codeFencedMeta' + suffix)\n      value +=\n        ' ' +\n        safe(context, node.meta, {\n          before: ' ',\n          after: '\\n',\n          encode: ['`']\n        })\n      subexit()\n    }\n\n    value += '\\n'\n\n    if (raw) {\n      value += raw + '\\n'\n    }\n\n    value += sequence\n  }\n\n  exit()\n  return value\n}\n\nfunction map(line, _, blank) {\n  return (blank ? '' : '    ') + line\n}\n","module.exports = definition\n\nvar association = require('../util/association')\nvar checkQuote = require('../util/check-quote')\nvar safe = require('../util/safe')\n\nfunction definition(node, _, context) {\n  var marker = checkQuote(context)\n  var suffix = marker === '\"' ? 'Quote' : 'Apostrophe'\n  var exit = context.enter('definition')\n  var subexit = context.enter('label')\n  var value =\n    '[' + safe(context, association(node), {before: '[', after: ']'}) + ']: '\n\n  subexit()\n\n  if (\n    // If theres no url, or\n    !node.url ||\n    // If theres whitespace, enclosed is prettier.\n    /[ \\t\\r\\n]/.test(node.url)\n  ) {\n    subexit = context.enter('destinationLiteral')\n    value += '<' + safe(context, node.url, {before: '<', after: '>'}) + '>'\n  } else {\n    // No whitespace, raw is prettier.\n    subexit = context.enter('destinationRaw')\n    value += safe(context, node.url, {before: ' ', after: ' '})\n  }\n\n  subexit()\n\n  if (node.title) {\n    subexit = context.enter('title' + suffix)\n    value +=\n      ' ' +\n      marker +\n      safe(context, node.title, {before: marker, after: marker}) +\n      marker\n    subexit()\n  }\n\n  exit()\n\n  return value\n}\n","module.exports = emphasis\nemphasis.peek = emphasisPeek\n\nvar checkEmphasis = require('../util/check-emphasis')\nvar phrasing = require('../util/container-phrasing')\n\n// To do: there are cases where emphasis cannot form depending on the\n// previous or next character of sequences.\n// Theres no way around that though, except for injecting zero-width stuff.\n// Do we need to safeguard against that?\nfunction emphasis(node, _, context) {\n  var marker = checkEmphasis(context)\n  var exit = context.enter('emphasis')\n  var value = phrasing(node, context, {before: marker, after: marker})\n  exit()\n  return marker + value + marker\n}\n\nfunction emphasisPeek(node, _, context) {\n  return context.options.emphasis || '*'\n}\n","module.exports = heading\n\nvar repeat = require('repeat-string')\nvar formatHeadingAsSetext = require('../util/format-heading-as-setext')\nvar phrasing = require('../util/container-phrasing')\n\nfunction heading(node, _, context) {\n  var rank = Math.max(Math.min(6, node.depth || 1), 1)\n  var exit\n  var subexit\n  var value\n  var sequence\n\n  if (formatHeadingAsSetext(node, context)) {\n    exit = context.enter('headingSetext')\n    subexit = context.enter('phrasing')\n    value = phrasing(node, context, {before: '\\n', after: '\\n'})\n    subexit()\n    exit()\n\n    return (\n      value +\n      '\\n' +\n      repeat(\n        rank === 1 ? '=' : '-',\n        // The whole size\n        value.length -\n          // Minus the position of the character after the last EOL (or\n          // 0 if there is none)\n          (Math.max(value.lastIndexOf('\\r'), value.lastIndexOf('\\n')) + 1)\n      )\n    )\n  }\n\n  sequence = repeat('#', rank)\n  exit = context.enter('headingAtx')\n  subexit = context.enter('phrasing')\n  value = phrasing(node, context, {before: '# ', after: '\\n'})\n  value = value ? sequence + ' ' + value : sequence\n  if (context.options.closeAtx) {\n    value += ' ' + sequence\n  }\n\n  subexit()\n  exit()\n\n  return value\n}\n","module.exports = html\nhtml.peek = htmlPeek\n\nfunction html(node) {\n  return node.value || ''\n}\n\nfunction htmlPeek() {\n  return '<'\n}\n","module.exports = imageReference\nimageReference.peek = imageReferencePeek\n\nvar association = require('../util/association')\nvar safe = require('../util/safe')\n\nfunction imageReference(node, _, context) {\n  var type = node.referenceType\n  var exit = context.enter('imageReference')\n  var subexit = context.enter('label')\n  var alt = safe(context, node.alt, {before: '[', after: ']'})\n  var value = '![' + alt + ']'\n  var reference\n  var stack\n\n  subexit()\n  // Hide the fact that were in phrasing, because escapes dont work.\n  stack = context.stack\n  context.stack = []\n  subexit = context.enter('reference')\n  reference = safe(context, association(node), {before: '[', after: ']'})\n  subexit()\n  context.stack = stack\n  exit()\n\n  if (type === 'full' || !alt || alt !== reference) {\n    value += '[' + reference + ']'\n  } else if (type !== 'shortcut') {\n    value += '[]'\n  }\n\n  return value\n}\n\nfunction imageReferencePeek() {\n  return '!'\n}\n","module.exports = image\nimage.peek = imagePeek\n\nvar checkQuote = require('../util/check-quote')\nvar safe = require('../util/safe')\n\nfunction image(node, _, context) {\n  var quote = checkQuote(context)\n  var suffix = quote === '\"' ? 'Quote' : 'Apostrophe'\n  var exit = context.enter('image')\n  var subexit = context.enter('label')\n  var value = '![' + safe(context, node.alt, {before: '[', after: ']'}) + ']('\n\n  subexit()\n\n  if (\n    // If theres no url but there is a title\n    (!node.url && node.title) ||\n    // Or if theres markdown whitespace or an eol, enclose.\n    /[ \\t\\r\\n]/.test(node.url)\n  ) {\n    subexit = context.enter('destinationLiteral')\n    value += '<' + safe(context, node.url, {before: '<', after: '>'}) + '>'\n  } else {\n    // No whitespace, raw is prettier.\n    subexit = context.enter('destinationRaw')\n    value += safe(context, node.url, {\n      before: '(',\n      after: node.title ? ' ' : ')'\n    })\n  }\n\n  subexit()\n\n  if (node.title) {\n    subexit = context.enter('title' + suffix)\n    value +=\n      ' ' +\n      quote +\n      safe(context, node.title, {before: quote, after: quote}) +\n      quote\n    subexit()\n  }\n\n  value += ')'\n  exit()\n\n  return value\n}\n\nfunction imagePeek() {\n  return '!'\n}\n","exports.blockquote = require('./blockquote')\nexports.break = require('./break')\nexports.code = require('./code')\nexports.definition = require('./definition')\nexports.emphasis = require('./emphasis')\nexports.hardBreak = require('./break')\nexports.heading = require('./heading')\nexports.html = require('./html')\nexports.image = require('./image')\nexports.imageReference = require('./image-reference')\nexports.inlineCode = require('./inline-code')\nexports.link = require('./link')\nexports.linkReference = require('./link-reference')\nexports.list = require('./list')\nexports.listItem = require('./list-item')\nexports.paragraph = require('./paragraph')\nexports.root = require('./root')\nexports.strong = require('./strong')\nexports.text = require('./text')\nexports.thematicBreak = require('./thematic-break')\n","module.exports = inlineCode\ninlineCode.peek = inlineCodePeek\n\nvar patternCompile = require('../util/pattern-compile')\n\nfunction inlineCode(node, parent, context) {\n  var value = node.value || ''\n  var sequence = '`'\n  var index = -1\n  var pattern\n  var expression\n  var match\n  var position\n\n  // If there is a single grave accent on its own in the code, use a fence of\n  // two.\n  // If there are two in a row, use one.\n  while (new RegExp('(^|[^`])' + sequence + '([^`]|$)').test(value)) {\n    sequence += '`'\n  }\n\n  // If this is not just spaces or eols (tabs dont count), and either the\n  // first or last character are a space, eol, or tick, then pad with spaces.\n  if (\n    /[^ \\r\\n]/.test(value) &&\n    (/[ \\r\\n`]/.test(value.charAt(0)) ||\n      /[ \\r\\n`]/.test(value.charAt(value.length - 1)))\n  ) {\n    value = ' ' + value + ' '\n  }\n\n  // We have a potential problem: certain characters after eols could result in\n  // blocks being seen.\n  // For example, if someone injected the string `'\\n# b'`, then that would\n  // result in an ATX heading.\n  // We cant escape characters in `inlineCode`, but because eols are\n  // transformed to spaces when going from markdown to HTML anyway, we can swap\n  // them out.\n  while (++index < context.unsafe.length) {\n    pattern = context.unsafe[index]\n\n    // Only look for `atBreak`s.\n    // Btw: note that `atBreak` patterns will always start the regex at LF or\n    // CR.\n    if (!pattern.atBreak) continue\n\n    expression = patternCompile(pattern)\n\n    while ((match = expression.exec(value))) {\n      position = match.index\n\n      // Support CRLF (patterns only look for one of the characters).\n      if (\n        value.charCodeAt(position) === 10 /* `\\n` */ &&\n        value.charCodeAt(position - 1) === 13 /* `\\r` */\n      ) {\n        position--\n      }\n\n      value = value.slice(0, position) + ' ' + value.slice(match.index + 1)\n    }\n  }\n\n  return sequence + value + sequence\n}\n\nfunction inlineCodePeek() {\n  return '`'\n}\n","module.exports = linkReference\nlinkReference.peek = linkReferencePeek\n\nvar association = require('../util/association')\nvar phrasing = require('../util/container-phrasing')\nvar safe = require('../util/safe')\n\nfunction linkReference(node, _, context) {\n  var type = node.referenceType\n  var exit = context.enter('linkReference')\n  var subexit = context.enter('label')\n  var text = phrasing(node, context, {before: '[', after: ']'})\n  var value = '[' + text + ']'\n  var reference\n  var stack\n\n  subexit()\n  // Hide the fact that were in phrasing, because escapes dont work.\n  stack = context.stack\n  context.stack = []\n  subexit = context.enter('reference')\n  reference = safe(context, association(node), {before: '[', after: ']'})\n  subexit()\n  context.stack = stack\n  exit()\n\n  if (type === 'full' || !text || text !== reference) {\n    value += '[' + reference + ']'\n  } else if (type !== 'shortcut') {\n    value += '[]'\n  }\n\n  return value\n}\n\nfunction linkReferencePeek() {\n  return '['\n}\n","module.exports = link\nlink.peek = linkPeek\n\nvar checkQuote = require('../util/check-quote')\nvar formatLinkAsAutolink = require('../util/format-link-as-autolink')\nvar phrasing = require('../util/container-phrasing')\nvar safe = require('../util/safe')\n\nfunction link(node, _, context) {\n  var quote = checkQuote(context)\n  var suffix = quote === '\"' ? 'Quote' : 'Apostrophe'\n  var exit\n  var subexit\n  var value\n  var stack\n\n  if (formatLinkAsAutolink(node, context)) {\n    // Hide the fact that were in phrasing, because escapes dont work.\n    stack = context.stack\n    context.stack = []\n    exit = context.enter('autolink')\n    value = '<' + phrasing(node, context, {before: '<', after: '>'}) + '>'\n    exit()\n    context.stack = stack\n    return value\n  }\n\n  exit = context.enter('link')\n  subexit = context.enter('label')\n  value = '[' + phrasing(node, context, {before: '[', after: ']'}) + ']('\n  subexit()\n\n  if (\n    // If theres no url but there is a title\n    (!node.url && node.title) ||\n    // Or if theres markdown whitespace or an eol, enclose.\n    /[ \\t\\r\\n]/.test(node.url)\n  ) {\n    subexit = context.enter('destinationLiteral')\n    value += '<' + safe(context, node.url, {before: '<', after: '>'}) + '>'\n  } else {\n    // No whitespace, raw is prettier.\n    subexit = context.enter('destinationRaw')\n    value += safe(context, node.url, {\n      before: '(',\n      after: node.title ? ' ' : ')'\n    })\n  }\n\n  subexit()\n\n  if (node.title) {\n    subexit = context.enter('title' + suffix)\n    value +=\n      ' ' +\n      quote +\n      safe(context, node.title, {before: quote, after: quote}) +\n      quote\n    subexit()\n  }\n\n  value += ')'\n\n  exit()\n  return value\n}\n\nfunction linkPeek(node, _, context) {\n  return formatLinkAsAutolink(node, context) ? '<' : '['\n}\n","module.exports = listItem\n\nvar repeat = require('repeat-string')\nvar checkBullet = require('../util/check-bullet')\nvar checkListItemIndent = require('../util/check-list-item-indent')\nvar flow = require('../util/container-flow')\nvar indentLines = require('../util/indent-lines')\n\nfunction listItem(node, parent, context) {\n  var bullet = checkBullet(context)\n  var listItemIndent = checkListItemIndent(context)\n  var size\n  var value\n  var exit\n\n  if (parent && parent.ordered) {\n    bullet =\n      (parent.start > -1 ? parent.start : 1) +\n      (context.options.incrementListMarker === false\n        ? 0\n        : parent.children.indexOf(node)) +\n      '.'\n  }\n\n  size = bullet.length + 1\n\n  if (\n    listItemIndent === 'tab' ||\n    (listItemIndent === 'mixed' && ((parent && parent.spread) || node.spread))\n  ) {\n    size = Math.ceil(size / 4) * 4\n  }\n\n  exit = context.enter('listItem')\n  value = indentLines(flow(node, context), map)\n  exit()\n\n  return value\n\n  function map(line, index, blank) {\n    if (index) {\n      return (blank ? '' : repeat(' ', size)) + line\n    }\n\n    return (blank ? bullet : bullet + repeat(' ', size - bullet.length)) + line\n  }\n}\n","module.exports = list\n\nvar flow = require('../util/container-flow')\n\nfunction list(node, _, context) {\n  var exit = context.enter('list')\n  var value = flow(node, context)\n  exit()\n  return value\n}\n","module.exports = paragraph\n\nvar phrasing = require('../util/container-phrasing')\n\nfunction paragraph(node, _, context) {\n  var exit = context.enter('paragraph')\n  var subexit = context.enter('phrasing')\n  var value = phrasing(node, context, {before: '\\n', after: '\\n'})\n  subexit()\n  exit()\n  return value\n}\n","module.exports = root\n\nvar flow = require('../util/container-flow')\n\nfunction root(node, _, context) {\n  return flow(node, context)\n}\n","module.exports = strong\nstrong.peek = strongPeek\n\nvar checkStrong = require('../util/check-strong')\nvar phrasing = require('../util/container-phrasing')\n\n// To do: there are cases where emphasis cannot form depending on the\n// previous or next character of sequences.\n// Theres no way around that though, except for injecting zero-width stuff.\n// Do we need to safeguard against that?\nfunction strong(node, _, context) {\n  var marker = checkStrong(context)\n  var exit = context.enter('strong')\n  var value = phrasing(node, context, {before: marker, after: marker})\n  exit()\n  return marker + marker + value + marker + marker\n}\n\nfunction strongPeek(node, _, context) {\n  return context.options.strong || '*'\n}\n","module.exports = text\n\nvar safe = require('../util/safe')\n\nfunction text(node, parent, context, safeOptions) {\n  return safe(context, node.value, safeOptions)\n}\n","module.exports = thematicBreak\n\nvar repeat = require('repeat-string')\nvar checkRepeat = require('../util/check-rule-repeat')\nvar checkRule = require('../util/check-rule')\n\nfunction thematicBreak(node, parent, context) {\n  var value = repeat(\n    checkRule(context) + (context.options.ruleSpaces ? ' ' : ''),\n    checkRepeat(context)\n  )\n\n  return context.options.ruleSpaces ? value.slice(0, -1) : value\n}\n","module.exports = toMarkdown\n\nvar zwitch = require('zwitch')\nvar configure = require('./configure')\nvar defaultHandlers = require('./handle')\nvar defaultJoin = require('./join')\nvar defaultUnsafe = require('./unsafe')\n\nfunction toMarkdown(tree, options) {\n  var settings = options || {}\n  var context = {\n    enter: enter,\n    stack: [],\n    unsafe: [],\n    join: [],\n    handlers: {},\n    options: {}\n  }\n  var result\n\n  configure(context, {\n    unsafe: defaultUnsafe,\n    join: defaultJoin,\n    handlers: defaultHandlers\n  })\n  configure(context, settings)\n\n  if (context.options.tightDefinitions) {\n    context.join = [joinDefinition].concat(context.join)\n  }\n\n  context.handle = zwitch('type', {\n    invalid: invalid,\n    unknown: unknown,\n    handlers: context.handlers\n  })\n\n  result = context.handle(tree, null, context, {before: '\\n', after: '\\n'})\n\n  if (\n    result &&\n    result.charCodeAt(result.length - 1) !== 10 &&\n    result.charCodeAt(result.length - 1) !== 13\n  ) {\n    result += '\\n'\n  }\n\n  return result\n\n  function enter(name) {\n    context.stack.push(name)\n    return exit\n\n    function exit() {\n      context.stack.pop()\n    }\n  }\n}\n\nfunction invalid(value) {\n  throw new Error('Cannot handle value `' + value + '`, expected node')\n}\n\nfunction unknown(node) {\n  throw new Error('Cannot handle unknown node `' + node.type + '`')\n}\n\nfunction joinDefinition(left, right) {\n  // No blank line between adjacent definitions.\n  if (left.type === 'definition' && left.type === right.type) {\n    return 0\n  }\n}\n","module.exports = [joinDefaults]\n\nvar formatCodeAsIndented = require('./util/format-code-as-indented')\nvar formatHeadingAsSetext = require('./util/format-heading-as-setext')\n\nfunction joinDefaults(left, right, parent, context) {\n  if (\n    // Two lists with the same marker.\n    (right.type === 'list' &&\n      right.type === left.type &&\n      Boolean(left.ordered) === Boolean(right.ordered)) ||\n    // Indented code after list or another indented code.\n    (right.type === 'code' &&\n      formatCodeAsIndented(right, context) &&\n      (left.type === 'list' ||\n        (left.type === right.type && formatCodeAsIndented(left, context))))\n  ) {\n    return false\n  }\n\n  // Join children of a list or an item.\n  // In which case, `parent` has a `spread` field.\n  if (typeof parent.spread === 'boolean') {\n    if (\n      left.type === 'paragraph' &&\n      // Two paragraphs.\n      (left.type === right.type ||\n        right.type === 'definition' ||\n        // Paragraph followed by a setext heading.\n        (right.type === 'heading' && formatHeadingAsSetext(right, context)))\n    ) {\n      return\n    }\n\n    return parent.spread ? 1 : 0\n  }\n}\n","module.exports = [\n  {\n    character: '\\t',\n    inConstruct: ['codeFencedLangGraveAccent', 'codeFencedLangTilde']\n  },\n  {\n    character: '\\r',\n    inConstruct: [\n      'codeFencedLangGraveAccent',\n      'codeFencedLangTilde',\n      'codeFencedMetaGraveAccent',\n      'codeFencedMetaTilde',\n      'destinationLiteral',\n      'headingAtx'\n    ]\n  },\n  {\n    character: '\\n',\n    inConstruct: [\n      'codeFencedLangGraveAccent',\n      'codeFencedLangTilde',\n      'codeFencedMetaGraveAccent',\n      'codeFencedMetaTilde',\n      'destinationLiteral',\n      'headingAtx'\n    ]\n  },\n  {\n    character: ' ',\n    inConstruct: ['codeFencedLangGraveAccent', 'codeFencedLangTilde']\n  },\n  // An exclamation mark can start an image, if it is followed by a link or\n  // a link reference.\n  {character: '!', after: '\\\\[', inConstruct: 'phrasing'},\n  // A quote can break out of a title.\n  {character: '\"', inConstruct: 'titleQuote'},\n  // A number sign could start an ATX heading if it starts a line.\n  {atBreak: true, character: '#'},\n  {character: '#', inConstruct: 'headingAtx', after: '(?:[\\r\\n]|$)'},\n  // Dollar sign and percentage are not used in markdown.\n  // An ampersand could start a character reference.\n  {character: '&', after: '[#A-Za-z]', inConstruct: 'phrasing'},\n  // An apostrophe can break out of a title.\n  {character: \"'\", inConstruct: 'titleApostrophe'},\n  // A left paren could break out of a destination raw.\n  {character: '(', inConstruct: 'destinationRaw'},\n  {before: '\\\\]', character: '(', inConstruct: 'phrasing'},\n  // A right paren could start a list item or break out of a destination\n  // raw.\n  {atBreak: true, before: '\\\\d+', character: ')'},\n  {character: ')', inConstruct: 'destinationRaw'},\n  // An asterisk can start thematic breaks, list items, emphasis, strong.\n  {atBreak: true, character: '*'},\n  {character: '*', inConstruct: 'phrasing'},\n  // A plus sign could start a list item.\n  {atBreak: true, character: '+'},\n  // A dash can start thematic breaks, list items, and setext heading\n  // underlines.\n  {atBreak: true, character: '-'},\n  // A dot could start a list item.\n  {atBreak: true, before: '\\\\d+', character: '.', after: '(?:[ \\t\\r\\n]|$)'},\n  // Slash, colon, and semicolon are not used in markdown for constructs.\n  // A less than can start html (flow or text) or an autolink.\n  // HTML could start with an exclamation mark (declaration, cdata, comment),\n  // slash (closing tag), question mark (instruction), or a letter (tag).\n  // An autolink also starts with a letter.\n  // Finally, it could break out of a destination literal.\n  {atBreak: true, character: '<', after: '[!/?A-Za-z]'},\n  {character: '<', after: '[!/?A-Za-z]', inConstruct: 'phrasing'},\n  {character: '<', inConstruct: 'destinationLiteral'},\n  // An equals to can start setext heading underlines.\n  {atBreak: true, character: '='},\n  // A greater than can start block quotes and it can break out of a\n  // destination literal.\n  {atBreak: true, character: '>'},\n  {character: '>', inConstruct: 'destinationLiteral'},\n  // Question mark and at sign are not used in markdown for constructs.\n  // A left bracket can start definitions, references, labels,\n  {atBreak: true, character: '['},\n  {character: '[', inConstruct: ['phrasing', 'label', 'reference']},\n  // A backslash can start an escape (when followed by punctuation) or a\n  // hard break (when followed by an eol).\n  // Note: typical escapes are handled in `safe`!\n  {character: '\\\\', after: '[\\\\r\\\\n]', inConstruct: 'phrasing'},\n  // A right bracket can exit labels.\n  {\n    character: ']',\n    inConstruct: ['label', 'reference']\n  },\n  // Caret is not used in markdown for constructs.\n  // An underscore can start emphasis, strong, or a thematic break.\n  {atBreak: true, character: '_'},\n  {before: '[^A-Za-z]', character: '_', inConstruct: 'phrasing'},\n  {character: '_', after: '[^A-Za-z]', inConstruct: 'phrasing'},\n  // A grave accent can start code (fenced or text), or it can break out of\n  // a grave accent code fence.\n  {atBreak: true, character: '`'},\n  {\n    character: '`',\n    inConstruct: [\n      'codeFencedLangGraveAccent',\n      'codeFencedMetaGraveAccent',\n      'phrasing'\n    ]\n  },\n  // Left brace, vertical bar, right brace are not used in markdown for\n  // constructs.\n  // A tilde can start code (fenced).\n  {atBreak: true, character: '~'}\n]\n","module.exports = association\n\nvar decode = require('parse-entities/decode-entity')\n\nvar characterEscape = /\\\\([!-/:-@[-`{-~])/g\nvar characterReference = /&(#(\\d{1,7}|x[\\da-f]{1,6})|[\\da-z]{1,31});/gi\n\n// The `label` of an association is the string value: character escapes and\n// references work, and casing is intact.\n// The `identifier` is used to match one association to another: controversially,\n// character escapes and references dont work in this matching: `&copy;` does\n// not match ``, and `\\+` does not match `+`.\n// But casing is ignored (and whitespace) is trimmed and collapsed: ` A\\nb`\n// matches `a b`.\n// So, we do prefer the label when figuring out how were going to serialize:\n// it has whitespace, casing, and we can ignore most useless character escapes\n// and all character references.\nfunction association(node) {\n  if (node.label || !node.identifier) {\n    return node.label || ''\n  }\n\n  return node.identifier\n    .replace(characterEscape, '$1')\n    .replace(characterReference, decodeIfPossible)\n}\n\nfunction decodeIfPossible($0, $1) {\n  return decode($1) || $0\n}\n","module.exports = checkBullet\n\nfunction checkBullet(context) {\n  var marker = context.options.bullet || '*'\n\n  if (marker !== '*' && marker !== '+' && marker !== '-') {\n    throw new Error(\n      'Cannot serialize items with `' +\n        marker +\n        '` for `options.bullet`, expected `*`, `+`, or `-`'\n    )\n  }\n\n  return marker\n}\n","module.exports = checkEmphasis\n\nfunction checkEmphasis(context) {\n  var marker = context.options.emphasis || '*'\n\n  if (marker !== '*' && marker !== '_') {\n    throw new Error(\n      'Cannot serialize emphasis with `' +\n        marker +\n        '` for `options.emphasis`, expected `*`, or `_`'\n    )\n  }\n\n  return marker\n}\n","module.exports = checkFence\n\nfunction checkFence(context) {\n  var marker = context.options.fence || '`'\n\n  if (marker !== '`' && marker !== '~') {\n    throw new Error(\n      'Cannot serialize code with `' +\n        marker +\n        '` for `options.fence`, expected `` ` `` or `~`'\n    )\n  }\n\n  return marker\n}\n","module.exports = checkListItemIndent\n\nfunction checkListItemIndent(context) {\n  var style = context.options.listItemIndent || 'tab'\n\n  if (style === 1 || style === '1') {\n    return 'one'\n  }\n\n  if (style !== 'tab' && style !== 'one' && style !== 'mixed') {\n    throw new Error(\n      'Cannot serialize items with `' +\n        style +\n        '` for `options.listItemIndent`, expected `tab`, `one`, or `mixed`'\n    )\n  }\n\n  return style\n}\n","module.exports = checkQuote\n\nfunction checkQuote(context) {\n  var marker = context.options.quote || '\"'\n\n  if (marker !== '\"' && marker !== \"'\") {\n    throw new Error(\n      'Cannot serialize title with `' +\n        marker +\n        '` for `options.quote`, expected `\"`, or `\\'`'\n    )\n  }\n\n  return marker\n}\n","module.exports = checkRule\n\nfunction checkRule(context) {\n  var repetition = context.options.ruleRepetition || 3\n\n  if (repetition < 3) {\n    throw new Error(\n      'Cannot serialize rules with repetition `' +\n        repetition +\n        '` for `options.ruleRepetition`, expected `3` or more'\n    )\n  }\n\n  return repetition\n}\n","module.exports = checkRule\n\nfunction checkRule(context) {\n  var marker = context.options.rule || '*'\n\n  if (marker !== '*' && marker !== '-' && marker !== '_') {\n    throw new Error(\n      'Cannot serialize rules with `' +\n        marker +\n        '` for `options.rule`, expected `*`, `-`, or `_`'\n    )\n  }\n\n  return marker\n}\n","module.exports = checkStrong\n\nfunction checkStrong(context) {\n  var marker = context.options.strong || '*'\n\n  if (marker !== '*' && marker !== '_') {\n    throw new Error(\n      'Cannot serialize strong with `' +\n        marker +\n        '` for `options.strong`, expected `*`, or `_`'\n    )\n  }\n\n  return marker\n}\n","module.exports = flow\n\nvar repeat = require('repeat-string')\n\nfunction flow(parent, context) {\n  var children = parent.children || []\n  var results = []\n  var index = -1\n  var child\n\n  while (++index < children.length) {\n    child = children[index]\n\n    results.push(\n      context.handle(child, parent, context, {before: '\\n', after: '\\n'})\n    )\n\n    if (index + 1 < children.length) {\n      results.push(between(child, children[index + 1]))\n    }\n  }\n\n  return results.join('')\n\n  function between(left, right) {\n    var index = -1\n    var result\n\n    while (++index < context.join.length) {\n      result = context.join[index](left, right, parent, context)\n\n      if (result === true || result === 1) {\n        break\n      }\n\n      if (typeof result === 'number') {\n        return repeat('\\n', 1 + Number(result))\n      }\n\n      if (result === false) {\n        return '\\n\\n<!---->\\n\\n'\n      }\n    }\n\n    return '\\n\\n'\n  }\n}\n","module.exports = phrasing\n\nfunction phrasing(parent, context, safeOptions) {\n  var children = parent.children || []\n  var results = []\n  var index = -1\n  var before = safeOptions.before\n  var after\n  var handle\n  var child\n\n  while (++index < children.length) {\n    child = children[index]\n\n    if (index + 1 < children.length) {\n      handle = context.handle.handlers[children[index + 1].type]\n      if (handle && handle.peek) handle = handle.peek\n      after = handle\n        ? handle(children[index + 1], parent, context, {\n            before: '',\n            after: ''\n          }).charAt(0)\n        : ''\n    } else {\n      after = safeOptions.after\n    }\n\n    // In some cases, html (text) can be found in phrasing right after an eol.\n    // When wed serialize that, in most cases that would be seen as html\n    // (flow).\n    // As we cant escape or so to prevent it from happening, we take a somewhat\n    // reasonable approach: replace that eol with a space.\n    // See: <https://github.com/syntax-tree/mdast-util-to-markdown/issues/15>\n    if (\n      results.length > 0 &&\n      (before === '\\r' || before === '\\n') &&\n      child.type === 'html'\n    ) {\n      results[results.length - 1] = results[results.length - 1].replace(\n        /(\\r?\\n|\\r)$/,\n        ' '\n      )\n      before = ' '\n    }\n\n    results.push(\n      context.handle(child, parent, context, {\n        before: before,\n        after: after\n      })\n    )\n\n    before = results[results.length - 1].slice(-1)\n  }\n\n  return results.join('')\n}\n","module.exports = formatCodeAsIndented\n\nfunction formatCodeAsIndented(node, context) {\n  return (\n    !context.options.fences &&\n    node.value &&\n    // If theres no info\n    !node.lang &&\n    // And theres a non-whitespace character\n    /[^ \\r\\n]/.test(node.value) &&\n    // And the value doesnt start or end in a blank\n    !/^[\\t ]*(?:[\\r\\n]|$)|(?:^|[\\r\\n])[\\t ]*$/.test(node.value)\n  )\n}\n","module.exports = formatHeadingAsSetext\n\nvar toString = require('mdast-util-to-string')\n\nfunction formatHeadingAsSetext(node, context) {\n  return (\n    context.options.setext && (!node.depth || node.depth < 3) && toString(node)\n  )\n}\n","module.exports = formatLinkAsAutolink\n\nvar toString = require('mdast-util-to-string')\n\nfunction formatLinkAsAutolink(node, context) {\n  var raw = toString(node)\n\n  return (\n    !context.options.resourceLink &&\n    // If theres a url\n    node.url &&\n    // And theres a no title\n    !node.title &&\n    // And the content of `node` is a single text node\n    node.children &&\n    node.children.length === 1 &&\n    node.children[0].type === 'text' &&\n    // And if the url is the same as the content\n    (raw === node.url || 'mailto:' + raw === node.url) &&\n    // And that starts w/ a protocol\n    /^[a-z][a-z+.-]+:/i.test(node.url) &&\n    // And that doesnt contain ASCII control codes (character escapes and\n    // references dont work) or angle brackets\n    !/[\\0- <>\\u007F]/.test(node.url)\n  )\n}\n","module.exports = indentLines\n\nvar eol = /\\r?\\n|\\r/g\n\nfunction indentLines(value, map) {\n  var result = []\n  var start = 0\n  var line = 0\n  var match\n\n  while ((match = eol.exec(value))) {\n    one(value.slice(start, match.index))\n    result.push(match[0])\n    start = match.index + match[0].length\n    line++\n  }\n\n  one(value.slice(start))\n\n  return result.join('')\n\n  function one(value) {\n    result.push(map(value, line, !value))\n  }\n}\n","module.exports = patternCompile\n\nfunction patternCompile(pattern) {\n  var before\n  var after\n\n  if (!pattern._compiled) {\n    before = pattern.before ? '(?:' + pattern.before + ')' : ''\n    after = pattern.after ? '(?:' + pattern.after + ')' : ''\n\n    if (pattern.atBreak) {\n      before = '[\\\\r\\\\n][\\\\t ]*' + before\n    }\n\n    pattern._compiled = new RegExp(\n      (before ? '(' + before + ')' : '') +\n        (/[|\\\\{}()[\\]^$+*?.-]/.test(pattern.character) ? '\\\\' : '') +\n        pattern.character +\n        (after || ''),\n      'g'\n    )\n  }\n\n  return pattern._compiled\n}\n","module.exports = patternInScope\n\nfunction patternInScope(stack, pattern) {\n  return (\n    listInScope(stack, pattern.inConstruct, true) &&\n    !listInScope(stack, pattern.notInConstruct)\n  )\n}\n\nfunction listInScope(stack, list, none) {\n  var index\n\n  if (!list) {\n    return none\n  }\n\n  if (typeof list === 'string') {\n    list = [list]\n  }\n\n  index = -1\n\n  while (++index < list.length) {\n    if (stack.indexOf(list[index]) !== -1) {\n      return true\n    }\n  }\n\n  return false\n}\n","module.exports = safe\n\nvar patternCompile = require('./pattern-compile')\nvar patternInScope = require('./pattern-in-scope')\n\nfunction safe(context, input, config) {\n  var value = (config.before || '') + (input || '') + (config.after || '')\n  var positions = []\n  var result = []\n  var infos = {}\n  var index = -1\n  var before\n  var after\n  var position\n  var pattern\n  var expression\n  var match\n  var start\n  var end\n\n  while (++index < context.unsafe.length) {\n    pattern = context.unsafe[index]\n\n    if (!patternInScope(context.stack, pattern)) {\n      continue\n    }\n\n    expression = patternCompile(pattern)\n\n    while ((match = expression.exec(value))) {\n      before = 'before' in pattern || pattern.atBreak\n      after = 'after' in pattern\n\n      position = match.index + (before ? match[1].length : 0)\n\n      if (positions.indexOf(position) === -1) {\n        positions.push(position)\n        infos[position] = {before: before, after: after}\n      } else {\n        if (infos[position].before && !before) {\n          infos[position].before = false\n        }\n\n        if (infos[position].after && !after) {\n          infos[position].after = false\n        }\n      }\n    }\n  }\n\n  positions.sort(numerical)\n\n  start = config.before ? config.before.length : 0\n  end = value.length - (config.after ? config.after.length : 0)\n  index = -1\n\n  while (++index < positions.length) {\n    position = positions[index]\n\n    if (\n      // Character before or after matched:\n      position < start ||\n      position >= end\n    ) {\n      continue\n    }\n\n    // If this character is supposed to be escaped because it has a condition on\n    // the next character, and the next character is definitly being escaped,\n    // then skip this escape.\n    if (\n      position + 1 < end &&\n      positions[index + 1] === position + 1 &&\n      infos[position].after &&\n      !infos[position + 1].before &&\n      !infos[position + 1].after\n    ) {\n      continue\n    }\n\n    if (start !== position) {\n      // If we have to use a character reference, an ampersand would be more\n      // correct, but as backslashes only care about punctuation, either will\n      // do the trick\n      result.push(escapeBackslashes(value.slice(start, position), '\\\\'))\n    }\n\n    start = position\n\n    if (\n      /[!-/:-@[-`{-~]/.test(value.charAt(position)) &&\n      (!config.encode || config.encode.indexOf(value.charAt(position)) === -1)\n    ) {\n      // Character escape.\n      result.push('\\\\')\n    } else {\n      // Character reference.\n      result.push(\n        '&#x' + value.charCodeAt(position).toString(16).toUpperCase() + ';'\n      )\n      start++\n    }\n  }\n\n  result.push(escapeBackslashes(value.slice(start, end), config.after))\n\n  return result.join('')\n}\n\nfunction numerical(a, b) {\n  return a - b\n}\n\nfunction escapeBackslashes(value, after) {\n  var expression = /\\\\(?=[!-/:-@[-`{-~])/g\n  var positions = []\n  var results = []\n  var index = -1\n  var start = 0\n  var whole = value + after\n  var match\n\n  while ((match = expression.exec(whole))) {\n    positions.push(match.index)\n  }\n\n  while (++index < positions.length) {\n    if (start !== positions[index]) {\n      results.push(value.slice(start, positions[index]))\n    }\n\n    results.push('\\\\')\n    start = positions[index]\n  }\n\n  results.push(value.slice(start))\n\n  return results.join('')\n}\n","'use strict'\n\nmodule.exports = toString\n\n// Get the text content of a node.\n// Prefer the nodes plain-text fields, otherwise serialize its children,\n// and if the given value is an array, serialize the nodes in it.\nfunction toString(node) {\n  return (\n    (node &&\n      (node.value ||\n        node.alt ||\n        node.title ||\n        ('children' in node && all(node.children)) ||\n        ('length' in node && all(node)))) ||\n    ''\n  )\n}\n\nfunction all(values) {\n  var result = []\n  var index = -1\n\n  while (++index < values.length) {\n    result[index] = toString(values[index])\n  }\n\n  return result.join('')\n}\n","module.exports = require('./lib/syntax')\n","module.exports = matters\n\nvar fault = require('fault')\n\nvar own = {}.hasOwnProperty\n\nvar markers = {yaml: '-', toml: '+'}\n\nfunction matters(options) {\n  var settings = options || 'yaml'\n  var results = []\n  var index = -1\n  var length\n\n  // One preset or matter.\n  if (typeof settings === 'string' || !('length' in settings)) {\n    settings = [settings]\n  }\n\n  length = settings.length\n\n  while (++index < length) {\n    results[index] = matter(settings[index])\n  }\n\n  return results\n}\n\nfunction matter(option) {\n  var result = option\n\n  if (typeof result === 'string') {\n    if (!own.call(markers, result)) {\n      throw fault('Missing matter definition for `%s`', result)\n    }\n\n    result = {type: result, marker: markers[result]}\n  } else if (typeof result !== 'object') {\n    throw fault('Expected matter to be an object, not `%j`', result)\n  }\n\n  if (!own.call(result, 'type')) {\n    throw fault('Missing `type` in matter `%j`', result)\n  }\n\n  if (!own.call(result, 'fence') && !own.call(result, 'marker')) {\n    throw fault('Missing `marker` or `fence` in matter `%j`', result)\n  }\n\n  return result\n}\n","module.exports = create\n\nvar matters = require('./matters')\n\nfunction create(options) {\n  var settings = matters(options)\n  var length = settings.length\n  var index = -1\n  var flow = {}\n  var matter\n  var code\n\n  while (++index < length) {\n    matter = settings[index]\n    code = fence(matter, 'open').charCodeAt(0)\n    if (code in flow) {\n      flow[code].push(parse(matter))\n    } else {\n      flow[code] = [parse(matter)]\n    }\n  }\n\n  return {flow: flow}\n}\n\nfunction parse(matter) {\n  var name = matter.type\n  var anywhere = matter.anywhere\n  var valueType = name + 'Value'\n  var fenceType = name + 'Fence'\n  var sequenceType = fenceType + 'Sequence'\n  var fenceConstruct = {tokenize: tokenizeFence, partial: true}\n  var buffer\n\n  return {tokenize: tokenizeFrontmatter, concrete: true}\n\n  function tokenizeFrontmatter(effects, ok, nok) {\n    var self = this\n\n    return start\n\n    function start(code) {\n      var position = self.now()\n\n      if (position.column !== 1 || (!anywhere && position.line !== 1)) {\n        return nok(code)\n      }\n\n      effects.enter(name)\n      buffer = fence(matter, 'open')\n      return effects.attempt(fenceConstruct, afterOpeningFence, nok)(code)\n    }\n\n    function afterOpeningFence(code) {\n      buffer = fence(matter, 'close')\n      return lineEnd(code)\n    }\n\n    function lineStart(code) {\n      if (code === -5 || code === -4 || code === -3 || code === null) {\n        return lineEnd(code)\n      }\n\n      effects.enter(valueType)\n      return lineData(code)\n    }\n\n    function lineData(code) {\n      if (code === -5 || code === -4 || code === -3 || code === null) {\n        effects.exit(valueType)\n        return lineEnd(code)\n      }\n\n      effects.consume(code)\n      return lineData\n    }\n\n    function lineEnd(code) {\n      // Require a closing fence.\n      if (code === null) {\n        return nok(code)\n      }\n\n      // Can only be an eol.\n      effects.enter('lineEnding')\n      effects.consume(code)\n      effects.exit('lineEnding')\n      return effects.attempt(fenceConstruct, after, lineStart)\n    }\n\n    function after(code) {\n      effects.exit(name)\n      return ok(code)\n    }\n  }\n\n  function tokenizeFence(effects, ok, nok) {\n    var bufferIndex = 0\n\n    return start\n\n    function start(code) {\n      if (code === buffer.charCodeAt(bufferIndex)) {\n        effects.enter(fenceType)\n        effects.enter(sequenceType)\n        return insideSequence(code)\n      }\n\n      return nok(code)\n    }\n\n    function insideSequence(code) {\n      if (bufferIndex === buffer.length) {\n        effects.exit(sequenceType)\n\n        if (code === -2 || code === -1 || code === 32) {\n          effects.enter('whitespace')\n          return insideWhitespace(code)\n        }\n\n        return fenceEnd(code)\n      }\n\n      if (code === buffer.charCodeAt(bufferIndex)) {\n        effects.consume(code)\n        bufferIndex++\n        return insideSequence\n      }\n\n      return nok(code)\n    }\n\n    function insideWhitespace(code) {\n      if (code === -2 || code === -1 || code === 32) {\n        effects.consume(code)\n        return insideWhitespace\n      }\n\n      effects.exit('whitespace')\n      return fenceEnd(code)\n    }\n\n    function fenceEnd(code) {\n      if (code === -5 || code === -4 || code === -3 || code === null) {\n        effects.exit(fenceType)\n        return ok(code)\n      }\n\n      return nok(code)\n    }\n  }\n}\n\nfunction fence(matter, prop) {\n  var marker\n\n  if (matter.marker) {\n    marker = pick(matter.marker, prop)\n    return marker + marker + marker\n  }\n\n  return pick(matter.fence, prop)\n}\n\nfunction pick(schema, prop) {\n  return typeof schema === 'string' ? schema : schema[prop]\n}\n","'use strict'\n\nvar regexCheck = require('../util/regex-check.js')\n\nvar asciiAlpha = regexCheck(/[A-Za-z]/)\n\nmodule.exports = asciiAlpha\n","'use strict'\n\nvar regexCheck = require('../util/regex-check.js')\n\nvar asciiAlphanumeric = regexCheck(/[\\dA-Za-z]/)\n\nmodule.exports = asciiAlphanumeric\n","'use strict'\n\nvar regexCheck = require('../util/regex-check.js')\n\nvar asciiAtext = regexCheck(/[#-'*+\\--9=?A-Z^-~]/)\n\nmodule.exports = asciiAtext\n","'use strict'\n\n// Note: EOF is seen as ASCII control here, because `null < 32 == true`.\nfunction asciiControl(code) {\n  return (\n    // Special whitespace codes (which have negative values), C0 and Control\n    // character DEL\n    code < 32 || code === 127\n  )\n}\n\nmodule.exports = asciiControl\n","'use strict'\n\nvar regexCheck = require('../util/regex-check.js')\n\nvar asciiDigit = regexCheck(/\\d/)\n\nmodule.exports = asciiDigit\n","'use strict'\n\nvar regexCheck = require('../util/regex-check.js')\n\nvar asciiHexDigit = regexCheck(/[\\dA-Fa-f]/)\n\nmodule.exports = asciiHexDigit\n","'use strict'\n\nvar regexCheck = require('../util/regex-check.js')\n\nvar asciiPunctuation = regexCheck(/[!-/:-@[-`{-~]/)\n\nmodule.exports = asciiPunctuation\n","'use strict'\n\nfunction markdownLineEndingOrSpace(code) {\n  return code < 0 || code === 32\n}\n\nmodule.exports = markdownLineEndingOrSpace\n","'use strict'\n\nfunction markdownLineEnding(code) {\n  return code < -2\n}\n\nmodule.exports = markdownLineEnding\n","'use strict'\n\nfunction markdownSpace(code) {\n  return code === -2 || code === -1 || code === 32\n}\n\nmodule.exports = markdownSpace\n","'use strict'\n\nvar unicodePunctuationRegex = require('../constant/unicode-punctuation-regex.js')\nvar regexCheck = require('../util/regex-check.js')\n\n// In fact adds to the bundle size.\n\nvar unicodePunctuation = regexCheck(unicodePunctuationRegex)\n\nmodule.exports = unicodePunctuation\n","'use strict'\n\nvar regexCheck = require('../util/regex-check.js')\n\nvar unicodeWhitespace = regexCheck(/\\s/)\n\nmodule.exports = unicodeWhitespace\n","'use strict'\n\nvar assign = Object.assign\n\nmodule.exports = assign\n","'use strict'\n\nvar fromCharCode = String.fromCharCode\n\nmodule.exports = fromCharCode\n","'use strict'\n\nvar own = {}.hasOwnProperty\n\nmodule.exports = own\n","'use strict'\n\n// This module is copied from <https://spec.commonmark.org/0.29/#html-blocks>.\nvar basics = [\n  'address',\n  'article',\n  'aside',\n  'base',\n  'basefont',\n  'blockquote',\n  'body',\n  'caption',\n  'center',\n  'col',\n  'colgroup',\n  'dd',\n  'details',\n  'dialog',\n  'dir',\n  'div',\n  'dl',\n  'dt',\n  'fieldset',\n  'figcaption',\n  'figure',\n  'footer',\n  'form',\n  'frame',\n  'frameset',\n  'h1',\n  'h2',\n  'h3',\n  'h4',\n  'h5',\n  'h6',\n  'head',\n  'header',\n  'hr',\n  'html',\n  'iframe',\n  'legend',\n  'li',\n  'link',\n  'main',\n  'menu',\n  'menuitem',\n  'nav',\n  'noframes',\n  'ol',\n  'optgroup',\n  'option',\n  'p',\n  'param',\n  'section',\n  'source',\n  'summary',\n  'table',\n  'tbody',\n  'td',\n  'tfoot',\n  'th',\n  'thead',\n  'title',\n  'tr',\n  'track',\n  'ul'\n]\n\nmodule.exports = basics\n","'use strict'\n\n// This module is copied from <https://spec.commonmark.org/0.29/#html-blocks>.\nvar raws = ['pre', 'script', 'style', 'textarea']\n\nmodule.exports = raws\n","'use strict'\n\nvar splice = [].splice\n\nmodule.exports = splice\n","'use strict'\n\n// This module is generated by `script/`.\n//\n// CommonMark handles attention (emphasis, strong) markers based on what comes\n// before or after them.\n// One such difference is if those characters are Unicode punctuation.\n// This script is generated from the Unicode data.\nvar unicodePunctuation = /[!-\\/:-@\\[-`\\{-~\\xA1\\xA7\\xAB\\xB6\\xB7\\xBB\\xBF\\u037E\\u0387\\u055A-\\u055F\\u0589\\u058A\\u05BE\\u05C0\\u05C3\\u05C6\\u05F3\\u05F4\\u0609\\u060A\\u060C\\u060D\\u061B\\u061E\\u061F\\u066A-\\u066D\\u06D4\\u0700-\\u070D\\u07F7-\\u07F9\\u0830-\\u083E\\u085E\\u0964\\u0965\\u0970\\u09FD\\u0A76\\u0AF0\\u0C77\\u0C84\\u0DF4\\u0E4F\\u0E5A\\u0E5B\\u0F04-\\u0F12\\u0F14\\u0F3A-\\u0F3D\\u0F85\\u0FD0-\\u0FD4\\u0FD9\\u0FDA\\u104A-\\u104F\\u10FB\\u1360-\\u1368\\u1400\\u166E\\u169B\\u169C\\u16EB-\\u16ED\\u1735\\u1736\\u17D4-\\u17D6\\u17D8-\\u17DA\\u1800-\\u180A\\u1944\\u1945\\u1A1E\\u1A1F\\u1AA0-\\u1AA6\\u1AA8-\\u1AAD\\u1B5A-\\u1B60\\u1BFC-\\u1BFF\\u1C3B-\\u1C3F\\u1C7E\\u1C7F\\u1CC0-\\u1CC7\\u1CD3\\u2010-\\u2027\\u2030-\\u2043\\u2045-\\u2051\\u2053-\\u205E\\u207D\\u207E\\u208D\\u208E\\u2308-\\u230B\\u2329\\u232A\\u2768-\\u2775\\u27C5\\u27C6\\u27E6-\\u27EF\\u2983-\\u2998\\u29D8-\\u29DB\\u29FC\\u29FD\\u2CF9-\\u2CFC\\u2CFE\\u2CFF\\u2D70\\u2E00-\\u2E2E\\u2E30-\\u2E4F\\u2E52\\u3001-\\u3003\\u3008-\\u3011\\u3014-\\u301F\\u3030\\u303D\\u30A0\\u30FB\\uA4FE\\uA4FF\\uA60D-\\uA60F\\uA673\\uA67E\\uA6F2-\\uA6F7\\uA874-\\uA877\\uA8CE\\uA8CF\\uA8F8-\\uA8FA\\uA8FC\\uA92E\\uA92F\\uA95F\\uA9C1-\\uA9CD\\uA9DE\\uA9DF\\uAA5C-\\uAA5F\\uAADE\\uAADF\\uAAF0\\uAAF1\\uABEB\\uFD3E\\uFD3F\\uFE10-\\uFE19\\uFE30-\\uFE52\\uFE54-\\uFE61\\uFE63\\uFE68\\uFE6A\\uFE6B\\uFF01-\\uFF03\\uFF05-\\uFF0A\\uFF0C-\\uFF0F\\uFF1A\\uFF1B\\uFF1F\\uFF20\\uFF3B-\\uFF3D\\uFF3F\\uFF5B\\uFF5D\\uFF5F-\\uFF65]/\n\nmodule.exports = unicodePunctuation\n","'use strict'\n\nObject.defineProperty(exports, '__esModule', {value: true})\n\nvar text$1 = require('./initialize/text.js')\nvar attention = require('./tokenize/attention.js')\nvar autolink = require('./tokenize/autolink.js')\nvar blockQuote = require('./tokenize/block-quote.js')\nvar characterEscape = require('./tokenize/character-escape.js')\nvar characterReference = require('./tokenize/character-reference.js')\nvar codeFenced = require('./tokenize/code-fenced.js')\nvar codeIndented = require('./tokenize/code-indented.js')\nvar codeText = require('./tokenize/code-text.js')\nvar definition = require('./tokenize/definition.js')\nvar hardBreakEscape = require('./tokenize/hard-break-escape.js')\nvar headingAtx = require('./tokenize/heading-atx.js')\nvar htmlFlow = require('./tokenize/html-flow.js')\nvar htmlText = require('./tokenize/html-text.js')\nvar labelEnd = require('./tokenize/label-end.js')\nvar labelStartImage = require('./tokenize/label-start-image.js')\nvar labelStartLink = require('./tokenize/label-start-link.js')\nvar lineEnding = require('./tokenize/line-ending.js')\nvar list = require('./tokenize/list.js')\nvar setextUnderline = require('./tokenize/setext-underline.js')\nvar thematicBreak = require('./tokenize/thematic-break.js')\n\nvar document = {\n  42: list,\n  // Asterisk\n  43: list,\n  // Plus sign\n  45: list,\n  // Dash\n  48: list,\n  // 0\n  49: list,\n  // 1\n  50: list,\n  // 2\n  51: list,\n  // 3\n  52: list,\n  // 4\n  53: list,\n  // 5\n  54: list,\n  // 6\n  55: list,\n  // 7\n  56: list,\n  // 8\n  57: list,\n  // 9\n  62: blockQuote // Greater than\n}\nvar contentInitial = {\n  91: definition // Left square bracket\n}\nvar flowInitial = {\n  '-2': codeIndented,\n  // Horizontal tab\n  '-1': codeIndented,\n  // Virtual space\n  32: codeIndented // Space\n}\nvar flow = {\n  35: headingAtx,\n  // Number sign\n  42: thematicBreak,\n  // Asterisk\n  45: [setextUnderline, thematicBreak],\n  // Dash\n  60: htmlFlow,\n  // Less than\n  61: setextUnderline,\n  // Equals to\n  95: thematicBreak,\n  // Underscore\n  96: codeFenced,\n  // Grave accent\n  126: codeFenced // Tilde\n}\nvar string = {\n  38: characterReference,\n  // Ampersand\n  92: characterEscape // Backslash\n}\nvar text = {\n  '-5': lineEnding,\n  // Carriage return\n  '-4': lineEnding,\n  // Line feed\n  '-3': lineEnding,\n  // Carriage return + line feed\n  33: labelStartImage,\n  // Exclamation mark\n  38: characterReference,\n  // Ampersand\n  42: attention,\n  // Asterisk\n  60: [autolink, htmlText],\n  // Less than\n  91: labelStartLink,\n  // Left square bracket\n  92: [hardBreakEscape, characterEscape],\n  // Backslash\n  93: labelEnd,\n  // Right square bracket\n  95: attention,\n  // Underscore\n  96: codeText // Grave accent\n}\nvar insideSpan = {\n  null: [attention, text$1.resolver]\n}\nvar disable = {\n  null: []\n}\n\nexports.contentInitial = contentInitial\nexports.disable = disable\nexports.document = document\nexports.flow = flow\nexports.flowInitial = flowInitial\nexports.insideSpan = insideSpan\nexports.string = string\nexports.text = text\n","'use strict'\n\nObject.defineProperty(exports, '__esModule', {value: true})\n\nvar markdownLineEnding = require('../character/markdown-line-ending.js')\nvar factorySpace = require('../tokenize/factory-space.js')\n\nvar tokenize = initializeContent\n\nfunction initializeContent(effects) {\n  var contentStart = effects.attempt(\n    this.parser.constructs.contentInitial,\n    afterContentStartConstruct,\n    paragraphInitial\n  )\n  var previous\n  return contentStart\n\n  function afterContentStartConstruct(code) {\n    if (code === null) {\n      effects.consume(code)\n      return\n    }\n\n    effects.enter('lineEnding')\n    effects.consume(code)\n    effects.exit('lineEnding')\n    return factorySpace(effects, contentStart, 'linePrefix')\n  }\n\n  function paragraphInitial(code) {\n    effects.enter('paragraph')\n    return lineStart(code)\n  }\n\n  function lineStart(code) {\n    var token = effects.enter('chunkText', {\n      contentType: 'text',\n      previous: previous\n    })\n\n    if (previous) {\n      previous.next = token\n    }\n\n    previous = token\n    return data(code)\n  }\n\n  function data(code) {\n    if (code === null) {\n      effects.exit('chunkText')\n      effects.exit('paragraph')\n      effects.consume(code)\n      return\n    }\n\n    if (markdownLineEnding(code)) {\n      effects.consume(code)\n      effects.exit('chunkText')\n      return lineStart\n    } // Data.\n\n    effects.consume(code)\n    return data\n  }\n}\n\nexports.tokenize = tokenize\n","'use strict'\n\nObject.defineProperty(exports, '__esModule', {value: true})\n\nvar markdownLineEnding = require('../character/markdown-line-ending.js')\nvar factorySpace = require('../tokenize/factory-space.js')\nvar partialBlankLine = require('../tokenize/partial-blank-line.js')\n\nvar tokenize = initializeDocument\nvar containerConstruct = {\n  tokenize: tokenizeContainer\n}\nvar lazyFlowConstruct = {\n  tokenize: tokenizeLazyFlow\n}\n\nfunction initializeDocument(effects) {\n  var self = this\n  var stack = []\n  var continued = 0\n  var inspectConstruct = {\n    tokenize: tokenizeInspect,\n    partial: true\n  }\n  var inspectResult\n  var childFlow\n  var childToken\n  return start\n\n  function start(code) {\n    if (continued < stack.length) {\n      self.containerState = stack[continued][1]\n      return effects.attempt(\n        stack[continued][0].continuation,\n        documentContinue,\n        documentContinued\n      )(code)\n    }\n\n    return documentContinued(code)\n  }\n\n  function documentContinue(code) {\n    continued++\n    return start(code)\n  }\n\n  function documentContinued(code) {\n    // If were in a concrete construct (such as when expecting another line of\n    // HTML, or we resulted in lazy content), we can immediately start flow.\n    if (inspectResult && inspectResult.flowContinue) {\n      return flowStart(code)\n    }\n\n    self.interrupt =\n      childFlow &&\n      childFlow.currentConstruct &&\n      childFlow.currentConstruct.interruptible\n    self.containerState = {}\n    return effects.attempt(\n      containerConstruct,\n      containerContinue,\n      flowStart\n    )(code)\n  }\n\n  function containerContinue(code) {\n    stack.push([self.currentConstruct, self.containerState])\n    self.containerState = undefined\n    return documentContinued(code)\n  }\n\n  function flowStart(code) {\n    if (code === null) {\n      exitContainers(0, true)\n      effects.consume(code)\n      return\n    }\n\n    childFlow = childFlow || self.parser.flow(self.now())\n    effects.enter('chunkFlow', {\n      contentType: 'flow',\n      previous: childToken,\n      _tokenizer: childFlow\n    })\n    return flowContinue(code)\n  }\n\n  function flowContinue(code) {\n    if (code === null) {\n      continueFlow(effects.exit('chunkFlow'))\n      return flowStart(code)\n    }\n\n    if (markdownLineEnding(code)) {\n      effects.consume(code)\n      continueFlow(effects.exit('chunkFlow'))\n      return effects.check(inspectConstruct, documentAfterPeek)\n    }\n\n    effects.consume(code)\n    return flowContinue\n  }\n\n  function documentAfterPeek(code) {\n    exitContainers(\n      inspectResult.continued,\n      inspectResult && inspectResult.flowEnd\n    )\n    continued = 0\n    return start(code)\n  }\n\n  function continueFlow(token) {\n    if (childToken) childToken.next = token\n    childToken = token\n    childFlow.lazy = inspectResult && inspectResult.lazy\n    childFlow.defineSkip(token.start)\n    childFlow.write(self.sliceStream(token))\n  }\n\n  function exitContainers(size, end) {\n    var index = stack.length // Close the flow.\n\n    if (childFlow && end) {\n      childFlow.write([null])\n      childToken = childFlow = undefined\n    } // Exit open containers.\n\n    while (index-- > size) {\n      self.containerState = stack[index][1]\n      stack[index][0].exit.call(self, effects)\n    }\n\n    stack.length = size\n  }\n\n  function tokenizeInspect(effects, ok) {\n    var subcontinued = 0\n    inspectResult = {}\n    return inspectStart\n\n    function inspectStart(code) {\n      if (subcontinued < stack.length) {\n        self.containerState = stack[subcontinued][1]\n        return effects.attempt(\n          stack[subcontinued][0].continuation,\n          inspectContinue,\n          inspectLess\n        )(code)\n      } // If were continued but in a concrete flow, we cant have more\n      // containers.\n\n      if (childFlow.currentConstruct && childFlow.currentConstruct.concrete) {\n        inspectResult.flowContinue = true\n        return inspectDone(code)\n      }\n\n      self.interrupt =\n        childFlow.currentConstruct && childFlow.currentConstruct.interruptible\n      self.containerState = {}\n      return effects.attempt(\n        containerConstruct,\n        inspectFlowEnd,\n        inspectDone\n      )(code)\n    }\n\n    function inspectContinue(code) {\n      subcontinued++\n      return self.containerState._closeFlow\n        ? inspectFlowEnd(code)\n        : inspectStart(code)\n    }\n\n    function inspectLess(code) {\n      if (childFlow.currentConstruct && childFlow.currentConstruct.lazy) {\n        // Maybe another container?\n        self.containerState = {}\n        return effects.attempt(\n          containerConstruct,\n          inspectFlowEnd, // Maybe flow, or a blank line?\n          effects.attempt(\n            lazyFlowConstruct,\n            inspectFlowEnd,\n            effects.check(partialBlankLine, inspectFlowEnd, inspectLazy)\n          )\n        )(code)\n      } // Otherwise were interrupting.\n\n      return inspectFlowEnd(code)\n    }\n\n    function inspectLazy(code) {\n      // Act as if all containers are continued.\n      subcontinued = stack.length\n      inspectResult.lazy = true\n      inspectResult.flowContinue = true\n      return inspectDone(code)\n    } // Were done with flow if we have more containers, or an interruption.\n\n    function inspectFlowEnd(code) {\n      inspectResult.flowEnd = true\n      return inspectDone(code)\n    }\n\n    function inspectDone(code) {\n      inspectResult.continued = subcontinued\n      self.interrupt = self.containerState = undefined\n      return ok(code)\n    }\n  }\n}\n\nfunction tokenizeContainer(effects, ok, nok) {\n  return factorySpace(\n    effects,\n    effects.attempt(this.parser.constructs.document, ok, nok),\n    'linePrefix',\n    this.parser.constructs.disable.null.indexOf('codeIndented') > -1\n      ? undefined\n      : 4\n  )\n}\n\nfunction tokenizeLazyFlow(effects, ok, nok) {\n  return factorySpace(\n    effects,\n    effects.lazy(this.parser.constructs.flow, ok, nok),\n    'linePrefix',\n    this.parser.constructs.disable.null.indexOf('codeIndented') > -1\n      ? undefined\n      : 4\n  )\n}\n\nexports.tokenize = tokenize\n","'use strict'\n\nObject.defineProperty(exports, '__esModule', {value: true})\n\nvar content = require('../tokenize/content.js')\nvar factorySpace = require('../tokenize/factory-space.js')\nvar partialBlankLine = require('../tokenize/partial-blank-line.js')\n\nvar tokenize = initializeFlow\n\nfunction initializeFlow(effects) {\n  var self = this\n  var initial = effects.attempt(\n    // Try to parse a blank line.\n    partialBlankLine,\n    atBlankEnding, // Try to parse initial flow (essentially, only code).\n    effects.attempt(\n      this.parser.constructs.flowInitial,\n      afterConstruct,\n      factorySpace(\n        effects,\n        effects.attempt(\n          this.parser.constructs.flow,\n          afterConstruct,\n          effects.attempt(content, afterConstruct)\n        ),\n        'linePrefix'\n      )\n    )\n  )\n  return initial\n\n  function atBlankEnding(code) {\n    if (code === null) {\n      effects.consume(code)\n      return\n    }\n\n    effects.enter('lineEndingBlank')\n    effects.consume(code)\n    effects.exit('lineEndingBlank')\n    self.currentConstruct = undefined\n    return initial\n  }\n\n  function afterConstruct(code) {\n    if (code === null) {\n      effects.consume(code)\n      return\n    }\n\n    effects.enter('lineEnding')\n    effects.consume(code)\n    effects.exit('lineEnding')\n    self.currentConstruct = undefined\n    return initial\n  }\n}\n\nexports.tokenize = tokenize\n","'use strict'\n\nObject.defineProperty(exports, '__esModule', {value: true})\n\nvar assign = require('../constant/assign.js')\nvar shallow = require('../util/shallow.js')\n\nvar text = initializeFactory('text')\nvar string = initializeFactory('string')\nvar resolver = {\n  resolveAll: createResolver()\n}\n\nfunction initializeFactory(field) {\n  return {\n    tokenize: initializeText,\n    resolveAll: createResolver(\n      field === 'text' ? resolveAllLineSuffixes : undefined\n    )\n  }\n\n  function initializeText(effects) {\n    var self = this\n    var constructs = this.parser.constructs[field]\n    var text = effects.attempt(constructs, start, notText)\n    return start\n\n    function start(code) {\n      return atBreak(code) ? text(code) : notText(code)\n    }\n\n    function notText(code) {\n      if (code === null) {\n        effects.consume(code)\n        return\n      }\n\n      effects.enter('data')\n      effects.consume(code)\n      return data\n    }\n\n    function data(code) {\n      if (atBreak(code)) {\n        effects.exit('data')\n        return text(code)\n      } // Data.\n\n      effects.consume(code)\n      return data\n    }\n\n    function atBreak(code) {\n      var list = constructs[code]\n      var index = -1\n\n      if (code === null) {\n        return true\n      }\n\n      if (list) {\n        while (++index < list.length) {\n          if (\n            !list[index].previous ||\n            list[index].previous.call(self, self.previous)\n          ) {\n            return true\n          }\n        }\n      }\n    }\n  }\n}\n\nfunction createResolver(extraResolver) {\n  return resolveAllText\n\n  function resolveAllText(events, context) {\n    var index = -1\n    var enter // A rather boring computation (to merge adjacent `data` events) which\n    // improves mm performance by 29%.\n\n    while (++index <= events.length) {\n      if (enter === undefined) {\n        if (events[index] && events[index][1].type === 'data') {\n          enter = index\n          index++\n        }\n      } else if (!events[index] || events[index][1].type !== 'data') {\n        // Dont do anything if there is one data token.\n        if (index !== enter + 2) {\n          events[enter][1].end = events[index - 1][1].end\n          events.splice(enter + 2, index - enter - 2)\n          index = enter + 2\n        }\n\n        enter = undefined\n      }\n    }\n\n    return extraResolver ? extraResolver(events, context) : events\n  }\n} // A rather ugly set of instructions which again looks at chunks in the input\n// stream.\n// The reason to do this here is that it is *much* faster to parse in reverse.\n// And that we cant hook into `null` to split the line suffix before an EOF.\n// To do: figure out if we can make this into a clean utility, or even in core.\n// As it will be useful for GFMs literal autolink extension (and maybe even\n// tables?)\n\nfunction resolveAllLineSuffixes(events, context) {\n  var eventIndex = -1\n  var chunks\n  var data\n  var chunk\n  var index\n  var bufferIndex\n  var size\n  var tabs\n  var token\n\n  while (++eventIndex <= events.length) {\n    if (\n      (eventIndex === events.length ||\n        events[eventIndex][1].type === 'lineEnding') &&\n      events[eventIndex - 1][1].type === 'data'\n    ) {\n      data = events[eventIndex - 1][1]\n      chunks = context.sliceStream(data)\n      index = chunks.length\n      bufferIndex = -1\n      size = 0\n      tabs = undefined\n\n      while (index--) {\n        chunk = chunks[index]\n\n        if (typeof chunk === 'string') {\n          bufferIndex = chunk.length\n\n          while (chunk.charCodeAt(bufferIndex - 1) === 32) {\n            size++\n            bufferIndex--\n          }\n\n          if (bufferIndex) break\n          bufferIndex = -1\n        } // Number\n        else if (chunk === -2) {\n          tabs = true\n          size++\n        } else if (chunk === -1);\n        else {\n          // Replacement character, exit.\n          index++\n          break\n        }\n      }\n\n      if (size) {\n        token = {\n          type:\n            eventIndex === events.length || tabs || size < 2\n              ? 'lineSuffix'\n              : 'hardBreakTrailing',\n          start: {\n            line: data.end.line,\n            column: data.end.column - size,\n            offset: data.end.offset - size,\n            _index: data.start._index + index,\n            _bufferIndex: index\n              ? bufferIndex\n              : data.start._bufferIndex + bufferIndex\n          },\n          end: shallow(data.end)\n        }\n        data.end = shallow(token.start)\n\n        if (data.start.offset === data.end.offset) {\n          assign(data, token)\n        } else {\n          events.splice(\n            eventIndex,\n            0,\n            ['enter', token, context],\n            ['exit', token, context]\n          )\n          eventIndex += 2\n        }\n      }\n\n      eventIndex++\n    }\n  }\n\n  return events\n}\n\nexports.resolver = resolver\nexports.string = string\nexports.text = text\n","'use strict'\n\nvar content = require('./initialize/content.js')\nvar document = require('./initialize/document.js')\nvar flow = require('./initialize/flow.js')\nvar text = require('./initialize/text.js')\nvar combineExtensions = require('./util/combine-extensions.js')\nvar createTokenizer = require('./util/create-tokenizer.js')\nvar miniflat = require('./util/miniflat.js')\nvar constructs = require('./constructs.js')\n\nfunction parse(options) {\n  var settings = options || {}\n  var parser = {\n    defined: [],\n    constructs: combineExtensions(\n      [constructs].concat(miniflat(settings.extensions))\n    ),\n    content: create(content),\n    document: create(document),\n    flow: create(flow),\n    string: create(text.string),\n    text: create(text.text)\n  }\n  return parser\n\n  function create(initializer) {\n    return creator\n\n    function creator(from) {\n      return createTokenizer(parser, initializer, from)\n    }\n  }\n}\n\nmodule.exports = parse\n","'use strict'\n\nvar subtokenize = require('./util/subtokenize.js')\n\nfunction postprocess(events) {\n  while (!subtokenize(events)) {\n    // Empty\n  }\n\n  return events\n}\n\nmodule.exports = postprocess\n","'use strict'\n\nvar search = /[\\0\\t\\n\\r]/g\n\nfunction preprocess() {\n  var start = true\n  var column = 1\n  var buffer = ''\n  var atCarriageReturn\n  return preprocessor\n\n  function preprocessor(value, encoding, end) {\n    var chunks = []\n    var match\n    var next\n    var startPosition\n    var endPosition\n    var code\n    value = buffer + value.toString(encoding)\n    startPosition = 0\n    buffer = ''\n\n    if (start) {\n      if (value.charCodeAt(0) === 65279) {\n        startPosition++\n      }\n\n      start = undefined\n    }\n\n    while (startPosition < value.length) {\n      search.lastIndex = startPosition\n      match = search.exec(value)\n      endPosition = match ? match.index : value.length\n      code = value.charCodeAt(endPosition)\n\n      if (!match) {\n        buffer = value.slice(startPosition)\n        break\n      }\n\n      if (code === 10 && startPosition === endPosition && atCarriageReturn) {\n        chunks.push(-3)\n        atCarriageReturn = undefined\n      } else {\n        if (atCarriageReturn) {\n          chunks.push(-5)\n          atCarriageReturn = undefined\n        }\n\n        if (startPosition < endPosition) {\n          chunks.push(value.slice(startPosition, endPosition))\n          column += endPosition - startPosition\n        }\n\n        if (code === 0) {\n          chunks.push(65533)\n          column++\n        } else if (code === 9) {\n          next = Math.ceil(column / 4) * 4\n          chunks.push(-2)\n\n          while (column++ < next) chunks.push(-1)\n        } else if (code === 10) {\n          chunks.push(-4)\n          column = 1\n        } // Must be carriage return.\n        else {\n          atCarriageReturn = true\n          column = 1\n        }\n      }\n\n      startPosition = endPosition + 1\n    }\n\n    if (end) {\n      if (atCarriageReturn) chunks.push(-5)\n      if (buffer) chunks.push(buffer)\n      chunks.push(null)\n    }\n\n    return chunks\n  }\n}\n\nmodule.exports = preprocess\n","'use strict'\n\nvar chunkedPush = require('../util/chunked-push.js')\nvar chunkedSplice = require('../util/chunked-splice.js')\nvar classifyCharacter = require('../util/classify-character.js')\nvar movePoint = require('../util/move-point.js')\nvar resolveAll = require('../util/resolve-all.js')\nvar shallow = require('../util/shallow.js')\n\nvar attention = {\n  name: 'attention',\n  tokenize: tokenizeAttention,\n  resolveAll: resolveAllAttention\n}\n\nfunction resolveAllAttention(events, context) {\n  var index = -1\n  var open\n  var group\n  var text\n  var openingSequence\n  var closingSequence\n  var use\n  var nextEvents\n  var offset // Walk through all events.\n  //\n  // Note: performance of this is fine on an mb of normal markdown, but its\n  // a bottleneck for malicious stuff.\n\n  while (++index < events.length) {\n    // Find a token that can close.\n    if (\n      events[index][0] === 'enter' &&\n      events[index][1].type === 'attentionSequence' &&\n      events[index][1]._close\n    ) {\n      open = index // Now walk back to find an opener.\n\n      while (open--) {\n        // Find a token that can open the closer.\n        if (\n          events[open][0] === 'exit' &&\n          events[open][1].type === 'attentionSequence' &&\n          events[open][1]._open && // If the markers are the same:\n          context.sliceSerialize(events[open][1]).charCodeAt(0) ===\n            context.sliceSerialize(events[index][1]).charCodeAt(0)\n        ) {\n          // If the opening can close or the closing can open,\n          // and the close size *is not* a multiple of three,\n          // but the sum of the opening and closing size *is* multiple of three,\n          // then dont match.\n          if (\n            (events[open][1]._close || events[index][1]._open) &&\n            (events[index][1].end.offset - events[index][1].start.offset) % 3 &&\n            !(\n              (events[open][1].end.offset -\n                events[open][1].start.offset +\n                events[index][1].end.offset -\n                events[index][1].start.offset) %\n              3\n            )\n          ) {\n            continue\n          } // Number of markers to use from the sequence.\n\n          use =\n            events[open][1].end.offset - events[open][1].start.offset > 1 &&\n            events[index][1].end.offset - events[index][1].start.offset > 1\n              ? 2\n              : 1\n          openingSequence = {\n            type: use > 1 ? 'strongSequence' : 'emphasisSequence',\n            start: movePoint(shallow(events[open][1].end), -use),\n            end: shallow(events[open][1].end)\n          }\n          closingSequence = {\n            type: use > 1 ? 'strongSequence' : 'emphasisSequence',\n            start: shallow(events[index][1].start),\n            end: movePoint(shallow(events[index][1].start), use)\n          }\n          text = {\n            type: use > 1 ? 'strongText' : 'emphasisText',\n            start: shallow(events[open][1].end),\n            end: shallow(events[index][1].start)\n          }\n          group = {\n            type: use > 1 ? 'strong' : 'emphasis',\n            start: shallow(openingSequence.start),\n            end: shallow(closingSequence.end)\n          }\n          events[open][1].end = shallow(openingSequence.start)\n          events[index][1].start = shallow(closingSequence.end)\n          nextEvents = [] // If there are more markers in the opening, add them before.\n\n          if (events[open][1].end.offset - events[open][1].start.offset) {\n            nextEvents = chunkedPush(nextEvents, [\n              ['enter', events[open][1], context],\n              ['exit', events[open][1], context]\n            ])\n          } // Opening.\n\n          nextEvents = chunkedPush(nextEvents, [\n            ['enter', group, context],\n            ['enter', openingSequence, context],\n            ['exit', openingSequence, context],\n            ['enter', text, context]\n          ]) // Between.\n\n          nextEvents = chunkedPush(\n            nextEvents,\n            resolveAll(\n              context.parser.constructs.insideSpan.null,\n              events.slice(open + 1, index),\n              context\n            )\n          ) // Closing.\n\n          nextEvents = chunkedPush(nextEvents, [\n            ['exit', text, context],\n            ['enter', closingSequence, context],\n            ['exit', closingSequence, context],\n            ['exit', group, context]\n          ]) // If there are more markers in the closing, add them after.\n\n          if (events[index][1].end.offset - events[index][1].start.offset) {\n            offset = 2\n            nextEvents = chunkedPush(nextEvents, [\n              ['enter', events[index][1], context],\n              ['exit', events[index][1], context]\n            ])\n          } else {\n            offset = 0\n          }\n\n          chunkedSplice(events, open - 1, index - open + 3, nextEvents)\n          index = open + nextEvents.length - offset - 2\n          break\n        }\n      }\n    }\n  } // Remove remaining sequences.\n\n  index = -1\n\n  while (++index < events.length) {\n    if (events[index][1].type === 'attentionSequence') {\n      events[index][1].type = 'data'\n    }\n  }\n\n  return events\n}\n\nfunction tokenizeAttention(effects, ok) {\n  var before = classifyCharacter(this.previous)\n  var marker\n  return start\n\n  function start(code) {\n    effects.enter('attentionSequence')\n    marker = code\n    return sequence(code)\n  }\n\n  function sequence(code) {\n    var token\n    var after\n    var open\n    var close\n\n    if (code === marker) {\n      effects.consume(code)\n      return sequence\n    }\n\n    token = effects.exit('attentionSequence')\n    after = classifyCharacter(code)\n    open = !after || (after === 2 && before)\n    close = !before || (before === 2 && after)\n    token._open = marker === 42 ? open : open && (before || !close)\n    token._close = marker === 42 ? close : close && (after || !open)\n    return ok(code)\n  }\n}\n\nmodule.exports = attention\n","'use strict'\n\nvar asciiAlpha = require('../character/ascii-alpha.js')\nvar asciiAlphanumeric = require('../character/ascii-alphanumeric.js')\nvar asciiAtext = require('../character/ascii-atext.js')\nvar asciiControl = require('../character/ascii-control.js')\n\nvar autolink = {\n  name: 'autolink',\n  tokenize: tokenizeAutolink\n}\n\nfunction tokenizeAutolink(effects, ok, nok) {\n  var size = 1\n  return start\n\n  function start(code) {\n    effects.enter('autolink')\n    effects.enter('autolinkMarker')\n    effects.consume(code)\n    effects.exit('autolinkMarker')\n    effects.enter('autolinkProtocol')\n    return open\n  }\n\n  function open(code) {\n    if (asciiAlpha(code)) {\n      effects.consume(code)\n      return schemeOrEmailAtext\n    }\n\n    return asciiAtext(code) ? emailAtext(code) : nok(code)\n  }\n\n  function schemeOrEmailAtext(code) {\n    return code === 43 || code === 45 || code === 46 || asciiAlphanumeric(code)\n      ? schemeInsideOrEmailAtext(code)\n      : emailAtext(code)\n  }\n\n  function schemeInsideOrEmailAtext(code) {\n    if (code === 58) {\n      effects.consume(code)\n      return urlInside\n    }\n\n    if (\n      (code === 43 || code === 45 || code === 46 || asciiAlphanumeric(code)) &&\n      size++ < 32\n    ) {\n      effects.consume(code)\n      return schemeInsideOrEmailAtext\n    }\n\n    return emailAtext(code)\n  }\n\n  function urlInside(code) {\n    if (code === 62) {\n      effects.exit('autolinkProtocol')\n      return end(code)\n    }\n\n    if (code === 32 || code === 60 || asciiControl(code)) {\n      return nok(code)\n    }\n\n    effects.consume(code)\n    return urlInside\n  }\n\n  function emailAtext(code) {\n    if (code === 64) {\n      effects.consume(code)\n      size = 0\n      return emailAtSignOrDot\n    }\n\n    if (asciiAtext(code)) {\n      effects.consume(code)\n      return emailAtext\n    }\n\n    return nok(code)\n  }\n\n  function emailAtSignOrDot(code) {\n    return asciiAlphanumeric(code) ? emailLabel(code) : nok(code)\n  }\n\n  function emailLabel(code) {\n    if (code === 46) {\n      effects.consume(code)\n      size = 0\n      return emailAtSignOrDot\n    }\n\n    if (code === 62) {\n      // Exit, then change the type.\n      effects.exit('autolinkProtocol').type = 'autolinkEmail'\n      return end(code)\n    }\n\n    return emailValue(code)\n  }\n\n  function emailValue(code) {\n    if ((code === 45 || asciiAlphanumeric(code)) && size++ < 63) {\n      effects.consume(code)\n      return code === 45 ? emailValue : emailLabel\n    }\n\n    return nok(code)\n  }\n\n  function end(code) {\n    effects.enter('autolinkMarker')\n    effects.consume(code)\n    effects.exit('autolinkMarker')\n    effects.exit('autolink')\n    return ok\n  }\n}\n\nmodule.exports = autolink\n","'use strict'\n\nvar markdownSpace = require('../character/markdown-space.js')\nvar factorySpace = require('./factory-space.js')\n\nvar blockQuote = {\n  name: 'blockQuote',\n  tokenize: tokenizeBlockQuoteStart,\n  continuation: {\n    tokenize: tokenizeBlockQuoteContinuation\n  },\n  exit: exit\n}\n\nfunction tokenizeBlockQuoteStart(effects, ok, nok) {\n  var self = this\n  return start\n\n  function start(code) {\n    if (code === 62) {\n      if (!self.containerState.open) {\n        effects.enter('blockQuote', {\n          _container: true\n        })\n        self.containerState.open = true\n      }\n\n      effects.enter('blockQuotePrefix')\n      effects.enter('blockQuoteMarker')\n      effects.consume(code)\n      effects.exit('blockQuoteMarker')\n      return after\n    }\n\n    return nok(code)\n  }\n\n  function after(code) {\n    if (markdownSpace(code)) {\n      effects.enter('blockQuotePrefixWhitespace')\n      effects.consume(code)\n      effects.exit('blockQuotePrefixWhitespace')\n      effects.exit('blockQuotePrefix')\n      return ok\n    }\n\n    effects.exit('blockQuotePrefix')\n    return ok(code)\n  }\n}\n\nfunction tokenizeBlockQuoteContinuation(effects, ok, nok) {\n  return factorySpace(\n    effects,\n    effects.attempt(blockQuote, ok, nok),\n    'linePrefix',\n    this.parser.constructs.disable.null.indexOf('codeIndented') > -1\n      ? undefined\n      : 4\n  )\n}\n\nfunction exit(effects) {\n  effects.exit('blockQuote')\n}\n\nmodule.exports = blockQuote\n","'use strict'\n\nvar asciiPunctuation = require('../character/ascii-punctuation.js')\n\nvar characterEscape = {\n  name: 'characterEscape',\n  tokenize: tokenizeCharacterEscape\n}\n\nfunction tokenizeCharacterEscape(effects, ok, nok) {\n  return start\n\n  function start(code) {\n    effects.enter('characterEscape')\n    effects.enter('escapeMarker')\n    effects.consume(code)\n    effects.exit('escapeMarker')\n    return open\n  }\n\n  function open(code) {\n    if (asciiPunctuation(code)) {\n      effects.enter('characterEscapeValue')\n      effects.consume(code)\n      effects.exit('characterEscapeValue')\n      effects.exit('characterEscape')\n      return ok\n    }\n\n    return nok(code)\n  }\n}\n\nmodule.exports = characterEscape\n","'use strict'\n\nvar decodeEntity = require('parse-entities/decode-entity.js')\nvar asciiAlphanumeric = require('../character/ascii-alphanumeric.js')\nvar asciiDigit = require('../character/ascii-digit.js')\nvar asciiHexDigit = require('../character/ascii-hex-digit.js')\n\nfunction _interopDefaultLegacy(e) {\n  return e && typeof e === 'object' && 'default' in e ? e : {default: e}\n}\n\nvar decodeEntity__default = /*#__PURE__*/ _interopDefaultLegacy(decodeEntity)\n\nvar characterReference = {\n  name: 'characterReference',\n  tokenize: tokenizeCharacterReference\n}\n\nfunction tokenizeCharacterReference(effects, ok, nok) {\n  var self = this\n  var size = 0\n  var max\n  var test\n  return start\n\n  function start(code) {\n    effects.enter('characterReference')\n    effects.enter('characterReferenceMarker')\n    effects.consume(code)\n    effects.exit('characterReferenceMarker')\n    return open\n  }\n\n  function open(code) {\n    if (code === 35) {\n      effects.enter('characterReferenceMarkerNumeric')\n      effects.consume(code)\n      effects.exit('characterReferenceMarkerNumeric')\n      return numeric\n    }\n\n    effects.enter('characterReferenceValue')\n    max = 31\n    test = asciiAlphanumeric\n    return value(code)\n  }\n\n  function numeric(code) {\n    if (code === 88 || code === 120) {\n      effects.enter('characterReferenceMarkerHexadecimal')\n      effects.consume(code)\n      effects.exit('characterReferenceMarkerHexadecimal')\n      effects.enter('characterReferenceValue')\n      max = 6\n      test = asciiHexDigit\n      return value\n    }\n\n    effects.enter('characterReferenceValue')\n    max = 7\n    test = asciiDigit\n    return value(code)\n  }\n\n  function value(code) {\n    var token\n\n    if (code === 59 && size) {\n      token = effects.exit('characterReferenceValue')\n\n      if (\n        test === asciiAlphanumeric &&\n        !decodeEntity__default['default'](self.sliceSerialize(token))\n      ) {\n        return nok(code)\n      }\n\n      effects.enter('characterReferenceMarker')\n      effects.consume(code)\n      effects.exit('characterReferenceMarker')\n      effects.exit('characterReference')\n      return ok\n    }\n\n    if (test(code) && size++ < max) {\n      effects.consume(code)\n      return value\n    }\n\n    return nok(code)\n  }\n}\n\nmodule.exports = characterReference\n","'use strict'\n\nvar markdownLineEnding = require('../character/markdown-line-ending.js')\nvar markdownLineEndingOrSpace = require('../character/markdown-line-ending-or-space.js')\nvar prefixSize = require('../util/prefix-size.js')\nvar factorySpace = require('./factory-space.js')\n\nvar codeFenced = {\n  name: 'codeFenced',\n  tokenize: tokenizeCodeFenced,\n  concrete: true\n}\n\nfunction tokenizeCodeFenced(effects, ok, nok) {\n  var self = this\n  var closingFenceConstruct = {\n    tokenize: tokenizeClosingFence,\n    partial: true\n  }\n  var initialPrefix = prefixSize(this.events, 'linePrefix')\n  var sizeOpen = 0\n  var marker\n  return start\n\n  function start(code) {\n    effects.enter('codeFenced')\n    effects.enter('codeFencedFence')\n    effects.enter('codeFencedFenceSequence')\n    marker = code\n    return sequenceOpen(code)\n  }\n\n  function sequenceOpen(code) {\n    if (code === marker) {\n      effects.consume(code)\n      sizeOpen++\n      return sequenceOpen\n    }\n\n    effects.exit('codeFencedFenceSequence')\n    return sizeOpen < 3\n      ? nok(code)\n      : factorySpace(effects, infoOpen, 'whitespace')(code)\n  }\n\n  function infoOpen(code) {\n    if (code === null || markdownLineEnding(code)) {\n      return openAfter(code)\n    }\n\n    effects.enter('codeFencedFenceInfo')\n    effects.enter('chunkString', {\n      contentType: 'string'\n    })\n    return info(code)\n  }\n\n  function info(code) {\n    if (code === null || markdownLineEndingOrSpace(code)) {\n      effects.exit('chunkString')\n      effects.exit('codeFencedFenceInfo')\n      return factorySpace(effects, infoAfter, 'whitespace')(code)\n    }\n\n    if (code === 96 && code === marker) return nok(code)\n    effects.consume(code)\n    return info\n  }\n\n  function infoAfter(code) {\n    if (code === null || markdownLineEnding(code)) {\n      return openAfter(code)\n    }\n\n    effects.enter('codeFencedFenceMeta')\n    effects.enter('chunkString', {\n      contentType: 'string'\n    })\n    return meta(code)\n  }\n\n  function meta(code) {\n    if (code === null || markdownLineEnding(code)) {\n      effects.exit('chunkString')\n      effects.exit('codeFencedFenceMeta')\n      return openAfter(code)\n    }\n\n    if (code === 96 && code === marker) return nok(code)\n    effects.consume(code)\n    return meta\n  }\n\n  function openAfter(code) {\n    effects.exit('codeFencedFence')\n    return self.interrupt ? ok(code) : content(code)\n  }\n\n  function content(code) {\n    if (code === null) {\n      return after(code)\n    }\n\n    if (markdownLineEnding(code)) {\n      effects.enter('lineEnding')\n      effects.consume(code)\n      effects.exit('lineEnding')\n      return effects.attempt(\n        closingFenceConstruct,\n        after,\n        initialPrefix\n          ? factorySpace(effects, content, 'linePrefix', initialPrefix + 1)\n          : content\n      )\n    }\n\n    effects.enter('codeFlowValue')\n    return contentContinue(code)\n  }\n\n  function contentContinue(code) {\n    if (code === null || markdownLineEnding(code)) {\n      effects.exit('codeFlowValue')\n      return content(code)\n    }\n\n    effects.consume(code)\n    return contentContinue\n  }\n\n  function after(code) {\n    effects.exit('codeFenced')\n    return ok(code)\n  }\n\n  function tokenizeClosingFence(effects, ok, nok) {\n    var size = 0\n    return factorySpace(\n      effects,\n      closingSequenceStart,\n      'linePrefix',\n      this.parser.constructs.disable.null.indexOf('codeIndented') > -1\n        ? undefined\n        : 4\n    )\n\n    function closingSequenceStart(code) {\n      effects.enter('codeFencedFence')\n      effects.enter('codeFencedFenceSequence')\n      return closingSequence(code)\n    }\n\n    function closingSequence(code) {\n      if (code === marker) {\n        effects.consume(code)\n        size++\n        return closingSequence\n      }\n\n      if (size < sizeOpen) return nok(code)\n      effects.exit('codeFencedFenceSequence')\n      return factorySpace(effects, closingSequenceEnd, 'whitespace')(code)\n    }\n\n    function closingSequenceEnd(code) {\n      if (code === null || markdownLineEnding(code)) {\n        effects.exit('codeFencedFence')\n        return ok(code)\n      }\n\n      return nok(code)\n    }\n  }\n}\n\nmodule.exports = codeFenced\n","'use strict'\n\nvar markdownLineEnding = require('../character/markdown-line-ending.js')\nvar chunkedSplice = require('../util/chunked-splice.js')\nvar prefixSize = require('../util/prefix-size.js')\nvar factorySpace = require('./factory-space.js')\n\nvar codeIndented = {\n  name: 'codeIndented',\n  tokenize: tokenizeCodeIndented,\n  resolve: resolveCodeIndented\n}\nvar indentedContentConstruct = {\n  tokenize: tokenizeIndentedContent,\n  partial: true\n}\n\nfunction resolveCodeIndented(events, context) {\n  var code = {\n    type: 'codeIndented',\n    start: events[0][1].start,\n    end: events[events.length - 1][1].end\n  }\n  chunkedSplice(events, 0, 0, [['enter', code, context]])\n  chunkedSplice(events, events.length, 0, [['exit', code, context]])\n  return events\n}\n\nfunction tokenizeCodeIndented(effects, ok, nok) {\n  return effects.attempt(indentedContentConstruct, afterPrefix, nok)\n\n  function afterPrefix(code) {\n    if (code === null) {\n      return ok(code)\n    }\n\n    if (markdownLineEnding(code)) {\n      return effects.attempt(indentedContentConstruct, afterPrefix, ok)(code)\n    }\n\n    effects.enter('codeFlowValue')\n    return content(code)\n  }\n\n  function content(code) {\n    if (code === null || markdownLineEnding(code)) {\n      effects.exit('codeFlowValue')\n      return afterPrefix(code)\n    }\n\n    effects.consume(code)\n    return content\n  }\n}\n\nfunction tokenizeIndentedContent(effects, ok, nok) {\n  var self = this\n  return factorySpace(effects, afterPrefix, 'linePrefix', 4 + 1)\n\n  function afterPrefix(code) {\n    if (markdownLineEnding(code)) {\n      effects.enter('lineEnding')\n      effects.consume(code)\n      effects.exit('lineEnding')\n      return factorySpace(effects, afterPrefix, 'linePrefix', 4 + 1)\n    }\n\n    return prefixSize(self.events, 'linePrefix') < 4 ? nok(code) : ok(code)\n  }\n}\n\nmodule.exports = codeIndented\n","'use strict'\n\nvar markdownLineEnding = require('../character/markdown-line-ending.js')\n\nvar codeText = {\n  name: 'codeText',\n  tokenize: tokenizeCodeText,\n  resolve: resolveCodeText,\n  previous: previous\n}\n\nfunction resolveCodeText(events) {\n  var tailExitIndex = events.length - 4\n  var headEnterIndex = 3\n  var index\n  var enter // If we start and end with an EOL or a space.\n\n  if (\n    (events[headEnterIndex][1].type === 'lineEnding' ||\n      events[headEnterIndex][1].type === 'space') &&\n    (events[tailExitIndex][1].type === 'lineEnding' ||\n      events[tailExitIndex][1].type === 'space')\n  ) {\n    index = headEnterIndex // And we have data.\n\n    while (++index < tailExitIndex) {\n      if (events[index][1].type === 'codeTextData') {\n        // Then we have padding.\n        events[tailExitIndex][1].type = events[headEnterIndex][1].type =\n          'codeTextPadding'\n        headEnterIndex += 2\n        tailExitIndex -= 2\n        break\n      }\n    }\n  } // Merge adjacent spaces and data.\n\n  index = headEnterIndex - 1\n  tailExitIndex++\n\n  while (++index <= tailExitIndex) {\n    if (enter === undefined) {\n      if (index !== tailExitIndex && events[index][1].type !== 'lineEnding') {\n        enter = index\n      }\n    } else if (\n      index === tailExitIndex ||\n      events[index][1].type === 'lineEnding'\n    ) {\n      events[enter][1].type = 'codeTextData'\n\n      if (index !== enter + 2) {\n        events[enter][1].end = events[index - 1][1].end\n        events.splice(enter + 2, index - enter - 2)\n        tailExitIndex -= index - enter - 2\n        index = enter + 2\n      }\n\n      enter = undefined\n    }\n  }\n\n  return events\n}\n\nfunction previous(code) {\n  // If there is a previous code, there will always be a tail.\n  return (\n    code !== 96 ||\n    this.events[this.events.length - 1][1].type === 'characterEscape'\n  )\n}\n\nfunction tokenizeCodeText(effects, ok, nok) {\n  var sizeOpen = 0\n  var size\n  var token\n  return start\n\n  function start(code) {\n    effects.enter('codeText')\n    effects.enter('codeTextSequence')\n    return openingSequence(code)\n  }\n\n  function openingSequence(code) {\n    if (code === 96) {\n      effects.consume(code)\n      sizeOpen++\n      return openingSequence\n    }\n\n    effects.exit('codeTextSequence')\n    return gap(code)\n  }\n\n  function gap(code) {\n    // EOF.\n    if (code === null) {\n      return nok(code)\n    } // Closing fence?\n    // Could also be data.\n\n    if (code === 96) {\n      token = effects.enter('codeTextSequence')\n      size = 0\n      return closingSequence(code)\n    } // Tabs dont work, and virtual spaces dont make sense.\n\n    if (code === 32) {\n      effects.enter('space')\n      effects.consume(code)\n      effects.exit('space')\n      return gap\n    }\n\n    if (markdownLineEnding(code)) {\n      effects.enter('lineEnding')\n      effects.consume(code)\n      effects.exit('lineEnding')\n      return gap\n    } // Data.\n\n    effects.enter('codeTextData')\n    return data(code)\n  } // In code.\n\n  function data(code) {\n    if (\n      code === null ||\n      code === 32 ||\n      code === 96 ||\n      markdownLineEnding(code)\n    ) {\n      effects.exit('codeTextData')\n      return gap(code)\n    }\n\n    effects.consume(code)\n    return data\n  } // Closing fence.\n\n  function closingSequence(code) {\n    // More.\n    if (code === 96) {\n      effects.consume(code)\n      size++\n      return closingSequence\n    } // Done!\n\n    if (size === sizeOpen) {\n      effects.exit('codeTextSequence')\n      effects.exit('codeText')\n      return ok(code)\n    } // More or less accents: mark as data.\n\n    token.type = 'codeTextData'\n    return data(code)\n  }\n}\n\nmodule.exports = codeText\n","'use strict'\n\nvar markdownLineEnding = require('../character/markdown-line-ending.js')\nvar prefixSize = require('../util/prefix-size.js')\nvar subtokenize = require('../util/subtokenize.js')\nvar factorySpace = require('./factory-space.js')\n\n// No name because it must not be turned off.\nvar content = {\n  tokenize: tokenizeContent,\n  resolve: resolveContent,\n  interruptible: true,\n  lazy: true\n}\nvar continuationConstruct = {\n  tokenize: tokenizeContinuation,\n  partial: true\n} // Content is transparent: its parsed right now. That way, definitions are also\n// parsed right now: before text in paragraphs (specifically, media) are parsed.\n\nfunction resolveContent(events) {\n  subtokenize(events)\n  return events\n}\n\nfunction tokenizeContent(effects, ok) {\n  var previous\n  return start\n\n  function start(code) {\n    effects.enter('content')\n    previous = effects.enter('chunkContent', {\n      contentType: 'content'\n    })\n    return data(code)\n  }\n\n  function data(code) {\n    if (code === null) {\n      return contentEnd(code)\n    }\n\n    if (markdownLineEnding(code)) {\n      return effects.check(\n        continuationConstruct,\n        contentContinue,\n        contentEnd\n      )(code)\n    } // Data.\n\n    effects.consume(code)\n    return data\n  }\n\n  function contentEnd(code) {\n    effects.exit('chunkContent')\n    effects.exit('content')\n    return ok(code)\n  }\n\n  function contentContinue(code) {\n    effects.consume(code)\n    effects.exit('chunkContent')\n    previous = previous.next = effects.enter('chunkContent', {\n      contentType: 'content',\n      previous: previous\n    })\n    return data\n  }\n}\n\nfunction tokenizeContinuation(effects, ok, nok) {\n  var self = this\n  return startLookahead\n\n  function startLookahead(code) {\n    effects.enter('lineEnding')\n    effects.consume(code)\n    effects.exit('lineEnding')\n    return factorySpace(effects, prefixed, 'linePrefix')\n  }\n\n  function prefixed(code) {\n    if (code === null || markdownLineEnding(code)) {\n      return nok(code)\n    }\n\n    if (\n      self.parser.constructs.disable.null.indexOf('codeIndented') > -1 ||\n      prefixSize(self.events, 'linePrefix') < 4\n    ) {\n      return effects.interrupt(self.parser.constructs.flow, nok, ok)(code)\n    }\n\n    return ok(code)\n  }\n}\n\nmodule.exports = content\n","'use strict'\n\nvar markdownLineEnding = require('../character/markdown-line-ending.js')\nvar markdownLineEndingOrSpace = require('../character/markdown-line-ending-or-space.js')\nvar normalizeIdentifier = require('../util/normalize-identifier.js')\nvar factoryDestination = require('./factory-destination.js')\nvar factoryLabel = require('./factory-label.js')\nvar factorySpace = require('./factory-space.js')\nvar factoryWhitespace = require('./factory-whitespace.js')\nvar factoryTitle = require('./factory-title.js')\n\nvar definition = {\n  name: 'definition',\n  tokenize: tokenizeDefinition\n}\nvar titleConstruct = {\n  tokenize: tokenizeTitle,\n  partial: true\n}\n\nfunction tokenizeDefinition(effects, ok, nok) {\n  var self = this\n  var identifier\n  return start\n\n  function start(code) {\n    effects.enter('definition')\n    return factoryLabel.call(\n      self,\n      effects,\n      labelAfter,\n      nok,\n      'definitionLabel',\n      'definitionLabelMarker',\n      'definitionLabelString'\n    )(code)\n  }\n\n  function labelAfter(code) {\n    identifier = normalizeIdentifier(\n      self.sliceSerialize(self.events[self.events.length - 1][1]).slice(1, -1)\n    )\n\n    if (code === 58) {\n      effects.enter('definitionMarker')\n      effects.consume(code)\n      effects.exit('definitionMarker') // Note: blank lines cant exist in content.\n\n      return factoryWhitespace(\n        effects,\n        factoryDestination(\n          effects,\n          effects.attempt(\n            titleConstruct,\n            factorySpace(effects, after, 'whitespace'),\n            factorySpace(effects, after, 'whitespace')\n          ),\n          nok,\n          'definitionDestination',\n          'definitionDestinationLiteral',\n          'definitionDestinationLiteralMarker',\n          'definitionDestinationRaw',\n          'definitionDestinationString'\n        )\n      )\n    }\n\n    return nok(code)\n  }\n\n  function after(code) {\n    if (code === null || markdownLineEnding(code)) {\n      effects.exit('definition')\n\n      if (self.parser.defined.indexOf(identifier) < 0) {\n        self.parser.defined.push(identifier)\n      }\n\n      return ok(code)\n    }\n\n    return nok(code)\n  }\n}\n\nfunction tokenizeTitle(effects, ok, nok) {\n  return start\n\n  function start(code) {\n    return markdownLineEndingOrSpace(code)\n      ? factoryWhitespace(effects, before)(code)\n      : nok(code)\n  }\n\n  function before(code) {\n    if (code === 34 || code === 39 || code === 40) {\n      return factoryTitle(\n        effects,\n        factorySpace(effects, after, 'whitespace'),\n        nok,\n        'definitionTitle',\n        'definitionTitleMarker',\n        'definitionTitleString'\n      )(code)\n    }\n\n    return nok(code)\n  }\n\n  function after(code) {\n    return code === null || markdownLineEnding(code) ? ok(code) : nok(code)\n  }\n}\n\nmodule.exports = definition\n","'use strict'\n\nvar asciiControl = require('../character/ascii-control.js')\nvar markdownLineEndingOrSpace = require('../character/markdown-line-ending-or-space.js')\nvar markdownLineEnding = require('../character/markdown-line-ending.js')\n\n// eslint-disable-next-line max-params\nfunction destinationFactory(\n  effects,\n  ok,\n  nok,\n  type,\n  literalType,\n  literalMarkerType,\n  rawType,\n  stringType,\n  max\n) {\n  var limit = max || Infinity\n  var balance = 0\n  return start\n\n  function start(code) {\n    if (code === 60) {\n      effects.enter(type)\n      effects.enter(literalType)\n      effects.enter(literalMarkerType)\n      effects.consume(code)\n      effects.exit(literalMarkerType)\n      return destinationEnclosedBefore\n    }\n\n    if (asciiControl(code) || code === 41) {\n      return nok(code)\n    }\n\n    effects.enter(type)\n    effects.enter(rawType)\n    effects.enter(stringType)\n    effects.enter('chunkString', {\n      contentType: 'string'\n    })\n    return destinationRaw(code)\n  }\n\n  function destinationEnclosedBefore(code) {\n    if (code === 62) {\n      effects.enter(literalMarkerType)\n      effects.consume(code)\n      effects.exit(literalMarkerType)\n      effects.exit(literalType)\n      effects.exit(type)\n      return ok\n    }\n\n    effects.enter(stringType)\n    effects.enter('chunkString', {\n      contentType: 'string'\n    })\n    return destinationEnclosed(code)\n  }\n\n  function destinationEnclosed(code) {\n    if (code === 62) {\n      effects.exit('chunkString')\n      effects.exit(stringType)\n      return destinationEnclosedBefore(code)\n    }\n\n    if (code === null || code === 60 || markdownLineEnding(code)) {\n      return nok(code)\n    }\n\n    effects.consume(code)\n    return code === 92 ? destinationEnclosedEscape : destinationEnclosed\n  }\n\n  function destinationEnclosedEscape(code) {\n    if (code === 60 || code === 62 || code === 92) {\n      effects.consume(code)\n      return destinationEnclosed\n    }\n\n    return destinationEnclosed(code)\n  }\n\n  function destinationRaw(code) {\n    if (code === 40) {\n      if (++balance > limit) return nok(code)\n      effects.consume(code)\n      return destinationRaw\n    }\n\n    if (code === 41) {\n      if (!balance--) {\n        effects.exit('chunkString')\n        effects.exit(stringType)\n        effects.exit(rawType)\n        effects.exit(type)\n        return ok(code)\n      }\n\n      effects.consume(code)\n      return destinationRaw\n    }\n\n    if (code === null || markdownLineEndingOrSpace(code)) {\n      if (balance) return nok(code)\n      effects.exit('chunkString')\n      effects.exit(stringType)\n      effects.exit(rawType)\n      effects.exit(type)\n      return ok(code)\n    }\n\n    if (asciiControl(code)) return nok(code)\n    effects.consume(code)\n    return code === 92 ? destinationRawEscape : destinationRaw\n  }\n\n  function destinationRawEscape(code) {\n    if (code === 40 || code === 41 || code === 92) {\n      effects.consume(code)\n      return destinationRaw\n    }\n\n    return destinationRaw(code)\n  }\n}\n\nmodule.exports = destinationFactory\n","'use strict'\n\nvar markdownLineEnding = require('../character/markdown-line-ending.js')\nvar markdownSpace = require('../character/markdown-space.js')\n\n// eslint-disable-next-line max-params\nfunction labelFactory(effects, ok, nok, type, markerType, stringType) {\n  var self = this\n  var size = 0\n  var data\n  return start\n\n  function start(code) {\n    effects.enter(type)\n    effects.enter(markerType)\n    effects.consume(code)\n    effects.exit(markerType)\n    effects.enter(stringType)\n    return atBreak\n  }\n\n  function atBreak(code) {\n    if (\n      code === null ||\n      code === 91 ||\n      (code === 93 && !data) ||\n      /* c8 ignore next */\n      (code === 94 &&\n        /* c8 ignore next */\n        !size &&\n        /* c8 ignore next */\n        '_hiddenFootnoteSupport' in self.parser.constructs) ||\n      size > 999\n    ) {\n      return nok(code)\n    }\n\n    if (code === 93) {\n      effects.exit(stringType)\n      effects.enter(markerType)\n      effects.consume(code)\n      effects.exit(markerType)\n      effects.exit(type)\n      return ok\n    }\n\n    if (markdownLineEnding(code)) {\n      effects.enter('lineEnding')\n      effects.consume(code)\n      effects.exit('lineEnding')\n      return atBreak\n    }\n\n    effects.enter('chunkString', {\n      contentType: 'string'\n    })\n    return label(code)\n  }\n\n  function label(code) {\n    if (\n      code === null ||\n      code === 91 ||\n      code === 93 ||\n      markdownLineEnding(code) ||\n      size++ > 999\n    ) {\n      effects.exit('chunkString')\n      return atBreak(code)\n    }\n\n    effects.consume(code)\n    data = data || !markdownSpace(code)\n    return code === 92 ? labelEscape : label\n  }\n\n  function labelEscape(code) {\n    if (code === 91 || code === 92 || code === 93) {\n      effects.consume(code)\n      size++\n      return label\n    }\n\n    return label(code)\n  }\n}\n\nmodule.exports = labelFactory\n","'use strict'\n\nvar markdownSpace = require('../character/markdown-space.js')\n\nfunction spaceFactory(effects, ok, type, max) {\n  var limit = max ? max - 1 : Infinity\n  var size = 0\n  return start\n\n  function start(code) {\n    if (markdownSpace(code)) {\n      effects.enter(type)\n      return prefix(code)\n    }\n\n    return ok(code)\n  }\n\n  function prefix(code) {\n    if (markdownSpace(code) && size++ < limit) {\n      effects.consume(code)\n      return prefix\n    }\n\n    effects.exit(type)\n    return ok(code)\n  }\n}\n\nmodule.exports = spaceFactory\n","'use strict'\n\nvar markdownLineEnding = require('../character/markdown-line-ending.js')\nvar factorySpace = require('./factory-space.js')\n\nfunction titleFactory(effects, ok, nok, type, markerType, stringType) {\n  var marker\n  return start\n\n  function start(code) {\n    effects.enter(type)\n    effects.enter(markerType)\n    effects.consume(code)\n    effects.exit(markerType)\n    marker = code === 40 ? 41 : code\n    return atFirstTitleBreak\n  }\n\n  function atFirstTitleBreak(code) {\n    if (code === marker) {\n      effects.enter(markerType)\n      effects.consume(code)\n      effects.exit(markerType)\n      effects.exit(type)\n      return ok\n    }\n\n    effects.enter(stringType)\n    return atTitleBreak(code)\n  }\n\n  function atTitleBreak(code) {\n    if (code === marker) {\n      effects.exit(stringType)\n      return atFirstTitleBreak(marker)\n    }\n\n    if (code === null) {\n      return nok(code)\n    } // Note: blank lines cant exist in content.\n\n    if (markdownLineEnding(code)) {\n      effects.enter('lineEnding')\n      effects.consume(code)\n      effects.exit('lineEnding')\n      return factorySpace(effects, atTitleBreak, 'linePrefix')\n    }\n\n    effects.enter('chunkString', {\n      contentType: 'string'\n    })\n    return title(code)\n  }\n\n  function title(code) {\n    if (code === marker || code === null || markdownLineEnding(code)) {\n      effects.exit('chunkString')\n      return atTitleBreak(code)\n    }\n\n    effects.consume(code)\n    return code === 92 ? titleEscape : title\n  }\n\n  function titleEscape(code) {\n    if (code === marker || code === 92) {\n      effects.consume(code)\n      return title\n    }\n\n    return title(code)\n  }\n}\n\nmodule.exports = titleFactory\n","'use strict'\n\nvar markdownLineEnding = require('../character/markdown-line-ending.js')\nvar markdownSpace = require('../character/markdown-space.js')\nvar factorySpace = require('./factory-space.js')\n\nfunction whitespaceFactory(effects, ok) {\n  var seen\n  return start\n\n  function start(code) {\n    if (markdownLineEnding(code)) {\n      effects.enter('lineEnding')\n      effects.consume(code)\n      effects.exit('lineEnding')\n      seen = true\n      return start\n    }\n\n    if (markdownSpace(code)) {\n      return factorySpace(\n        effects,\n        start,\n        seen ? 'linePrefix' : 'lineSuffix'\n      )(code)\n    }\n\n    return ok(code)\n  }\n}\n\nmodule.exports = whitespaceFactory\n","'use strict'\n\nvar markdownLineEnding = require('../character/markdown-line-ending.js')\n\nvar hardBreakEscape = {\n  name: 'hardBreakEscape',\n  tokenize: tokenizeHardBreakEscape\n}\n\nfunction tokenizeHardBreakEscape(effects, ok, nok) {\n  return start\n\n  function start(code) {\n    effects.enter('hardBreakEscape')\n    effects.enter('escapeMarker')\n    effects.consume(code)\n    return open\n  }\n\n  function open(code) {\n    if (markdownLineEnding(code)) {\n      effects.exit('escapeMarker')\n      effects.exit('hardBreakEscape')\n      return ok(code)\n    }\n\n    return nok(code)\n  }\n}\n\nmodule.exports = hardBreakEscape\n","'use strict'\n\nvar markdownLineEnding = require('../character/markdown-line-ending.js')\nvar markdownLineEndingOrSpace = require('../character/markdown-line-ending-or-space.js')\nvar markdownSpace = require('../character/markdown-space.js')\nvar chunkedSplice = require('../util/chunked-splice.js')\nvar factorySpace = require('./factory-space.js')\n\nvar headingAtx = {\n  name: 'headingAtx',\n  tokenize: tokenizeHeadingAtx,\n  resolve: resolveHeadingAtx\n}\n\nfunction resolveHeadingAtx(events, context) {\n  var contentEnd = events.length - 2\n  var contentStart = 3\n  var content\n  var text // Prefix whitespace, part of the opening.\n\n  if (events[contentStart][1].type === 'whitespace') {\n    contentStart += 2\n  } // Suffix whitespace, part of the closing.\n\n  if (\n    contentEnd - 2 > contentStart &&\n    events[contentEnd][1].type === 'whitespace'\n  ) {\n    contentEnd -= 2\n  }\n\n  if (\n    events[contentEnd][1].type === 'atxHeadingSequence' &&\n    (contentStart === contentEnd - 1 ||\n      (contentEnd - 4 > contentStart &&\n        events[contentEnd - 2][1].type === 'whitespace'))\n  ) {\n    contentEnd -= contentStart + 1 === contentEnd ? 2 : 4\n  }\n\n  if (contentEnd > contentStart) {\n    content = {\n      type: 'atxHeadingText',\n      start: events[contentStart][1].start,\n      end: events[contentEnd][1].end\n    }\n    text = {\n      type: 'chunkText',\n      start: events[contentStart][1].start,\n      end: events[contentEnd][1].end,\n      contentType: 'text'\n    }\n    chunkedSplice(events, contentStart, contentEnd - contentStart + 1, [\n      ['enter', content, context],\n      ['enter', text, context],\n      ['exit', text, context],\n      ['exit', content, context]\n    ])\n  }\n\n  return events\n}\n\nfunction tokenizeHeadingAtx(effects, ok, nok) {\n  var self = this\n  var size = 0\n  return start\n\n  function start(code) {\n    effects.enter('atxHeading')\n    effects.enter('atxHeadingSequence')\n    return fenceOpenInside(code)\n  }\n\n  function fenceOpenInside(code) {\n    if (code === 35 && size++ < 6) {\n      effects.consume(code)\n      return fenceOpenInside\n    }\n\n    if (code === null || markdownLineEndingOrSpace(code)) {\n      effects.exit('atxHeadingSequence')\n      return self.interrupt ? ok(code) : headingBreak(code)\n    }\n\n    return nok(code)\n  }\n\n  function headingBreak(code) {\n    if (code === 35) {\n      effects.enter('atxHeadingSequence')\n      return sequence(code)\n    }\n\n    if (code === null || markdownLineEnding(code)) {\n      effects.exit('atxHeading')\n      return ok(code)\n    }\n\n    if (markdownSpace(code)) {\n      return factorySpace(effects, headingBreak, 'whitespace')(code)\n    }\n\n    effects.enter('atxHeadingText')\n    return data(code)\n  }\n\n  function sequence(code) {\n    if (code === 35) {\n      effects.consume(code)\n      return sequence\n    }\n\n    effects.exit('atxHeadingSequence')\n    return headingBreak(code)\n  }\n\n  function data(code) {\n    if (code === null || code === 35 || markdownLineEndingOrSpace(code)) {\n      effects.exit('atxHeadingText')\n      return headingBreak(code)\n    }\n\n    effects.consume(code)\n    return data\n  }\n}\n\nmodule.exports = headingAtx\n","'use strict'\n\nvar asciiAlpha = require('../character/ascii-alpha.js')\nvar asciiAlphanumeric = require('../character/ascii-alphanumeric.js')\nvar markdownLineEnding = require('../character/markdown-line-ending.js')\nvar markdownLineEndingOrSpace = require('../character/markdown-line-ending-or-space.js')\nvar markdownSpace = require('../character/markdown-space.js')\nvar fromCharCode = require('../constant/from-char-code.js')\nvar htmlBlockNames = require('../constant/html-block-names.js')\nvar htmlRawNames = require('../constant/html-raw-names.js')\nvar partialBlankLine = require('./partial-blank-line.js')\n\nvar htmlFlow = {\n  name: 'htmlFlow',\n  tokenize: tokenizeHtmlFlow,\n  resolveTo: resolveToHtmlFlow,\n  concrete: true\n}\nvar nextBlankConstruct = {\n  tokenize: tokenizeNextBlank,\n  partial: true\n}\n\nfunction resolveToHtmlFlow(events) {\n  var index = events.length\n\n  while (index--) {\n    if (events[index][0] === 'enter' && events[index][1].type === 'htmlFlow') {\n      break\n    }\n  }\n\n  if (index > 1 && events[index - 2][1].type === 'linePrefix') {\n    // Add the prefix start to the HTML token.\n    events[index][1].start = events[index - 2][1].start // Add the prefix start to the HTML line token.\n\n    events[index + 1][1].start = events[index - 2][1].start // Remove the line prefix.\n\n    events.splice(index - 2, 2)\n  }\n\n  return events\n}\n\nfunction tokenizeHtmlFlow(effects, ok, nok) {\n  var self = this\n  var kind\n  var startTag\n  var buffer\n  var index\n  var marker\n  return start\n\n  function start(code) {\n    effects.enter('htmlFlow')\n    effects.enter('htmlFlowData')\n    effects.consume(code)\n    return open\n  }\n\n  function open(code) {\n    if (code === 33) {\n      effects.consume(code)\n      return declarationStart\n    }\n\n    if (code === 47) {\n      effects.consume(code)\n      return tagCloseStart\n    }\n\n    if (code === 63) {\n      effects.consume(code)\n      kind = 3 // While were in an instruction instead of a declaration, were on a `?`\n      // right now, so we do need to search for `>`, similar to declarations.\n\n      return self.interrupt ? ok : continuationDeclarationInside\n    }\n\n    if (asciiAlpha(code)) {\n      effects.consume(code)\n      buffer = fromCharCode(code)\n      startTag = true\n      return tagName\n    }\n\n    return nok(code)\n  }\n\n  function declarationStart(code) {\n    if (code === 45) {\n      effects.consume(code)\n      kind = 2\n      return commentOpenInside\n    }\n\n    if (code === 91) {\n      effects.consume(code)\n      kind = 5\n      buffer = 'CDATA['\n      index = 0\n      return cdataOpenInside\n    }\n\n    if (asciiAlpha(code)) {\n      effects.consume(code)\n      kind = 4\n      return self.interrupt ? ok : continuationDeclarationInside\n    }\n\n    return nok(code)\n  }\n\n  function commentOpenInside(code) {\n    if (code === 45) {\n      effects.consume(code)\n      return self.interrupt ? ok : continuationDeclarationInside\n    }\n\n    return nok(code)\n  }\n\n  function cdataOpenInside(code) {\n    if (code === buffer.charCodeAt(index++)) {\n      effects.consume(code)\n      return index === buffer.length\n        ? self.interrupt\n          ? ok\n          : continuation\n        : cdataOpenInside\n    }\n\n    return nok(code)\n  }\n\n  function tagCloseStart(code) {\n    if (asciiAlpha(code)) {\n      effects.consume(code)\n      buffer = fromCharCode(code)\n      return tagName\n    }\n\n    return nok(code)\n  }\n\n  function tagName(code) {\n    if (\n      code === null ||\n      code === 47 ||\n      code === 62 ||\n      markdownLineEndingOrSpace(code)\n    ) {\n      if (\n        code !== 47 &&\n        startTag &&\n        htmlRawNames.indexOf(buffer.toLowerCase()) > -1\n      ) {\n        kind = 1\n        return self.interrupt ? ok(code) : continuation(code)\n      }\n\n      if (htmlBlockNames.indexOf(buffer.toLowerCase()) > -1) {\n        kind = 6\n\n        if (code === 47) {\n          effects.consume(code)\n          return basicSelfClosing\n        }\n\n        return self.interrupt ? ok(code) : continuation(code)\n      }\n\n      kind = 7 // Do not support complete HTML when interrupting.\n\n      return self.interrupt\n        ? nok(code)\n        : startTag\n        ? completeAttributeNameBefore(code)\n        : completeClosingTagAfter(code)\n    }\n\n    if (code === 45 || asciiAlphanumeric(code)) {\n      effects.consume(code)\n      buffer += fromCharCode(code)\n      return tagName\n    }\n\n    return nok(code)\n  }\n\n  function basicSelfClosing(code) {\n    if (code === 62) {\n      effects.consume(code)\n      return self.interrupt ? ok : continuation\n    }\n\n    return nok(code)\n  }\n\n  function completeClosingTagAfter(code) {\n    if (markdownSpace(code)) {\n      effects.consume(code)\n      return completeClosingTagAfter\n    }\n\n    return completeEnd(code)\n  }\n\n  function completeAttributeNameBefore(code) {\n    if (code === 47) {\n      effects.consume(code)\n      return completeEnd\n    }\n\n    if (code === 58 || code === 95 || asciiAlpha(code)) {\n      effects.consume(code)\n      return completeAttributeName\n    }\n\n    if (markdownSpace(code)) {\n      effects.consume(code)\n      return completeAttributeNameBefore\n    }\n\n    return completeEnd(code)\n  }\n\n  function completeAttributeName(code) {\n    if (\n      code === 45 ||\n      code === 46 ||\n      code === 58 ||\n      code === 95 ||\n      asciiAlphanumeric(code)\n    ) {\n      effects.consume(code)\n      return completeAttributeName\n    }\n\n    return completeAttributeNameAfter(code)\n  }\n\n  function completeAttributeNameAfter(code) {\n    if (code === 61) {\n      effects.consume(code)\n      return completeAttributeValueBefore\n    }\n\n    if (markdownSpace(code)) {\n      effects.consume(code)\n      return completeAttributeNameAfter\n    }\n\n    return completeAttributeNameBefore(code)\n  }\n\n  function completeAttributeValueBefore(code) {\n    if (\n      code === null ||\n      code === 60 ||\n      code === 61 ||\n      code === 62 ||\n      code === 96\n    ) {\n      return nok(code)\n    }\n\n    if (code === 34 || code === 39) {\n      effects.consume(code)\n      marker = code\n      return completeAttributeValueQuoted\n    }\n\n    if (markdownSpace(code)) {\n      effects.consume(code)\n      return completeAttributeValueBefore\n    }\n\n    marker = undefined\n    return completeAttributeValueUnquoted(code)\n  }\n\n  function completeAttributeValueQuoted(code) {\n    if (code === marker) {\n      effects.consume(code)\n      return completeAttributeValueQuotedAfter\n    }\n\n    if (code === null || markdownLineEnding(code)) {\n      return nok(code)\n    }\n\n    effects.consume(code)\n    return completeAttributeValueQuoted\n  }\n\n  function completeAttributeValueUnquoted(code) {\n    if (\n      code === null ||\n      code === 34 ||\n      code === 39 ||\n      code === 60 ||\n      code === 61 ||\n      code === 62 ||\n      code === 96 ||\n      markdownLineEndingOrSpace(code)\n    ) {\n      return completeAttributeNameAfter(code)\n    }\n\n    effects.consume(code)\n    return completeAttributeValueUnquoted\n  }\n\n  function completeAttributeValueQuotedAfter(code) {\n    if (code === 47 || code === 62 || markdownSpace(code)) {\n      return completeAttributeNameBefore(code)\n    }\n\n    return nok(code)\n  }\n\n  function completeEnd(code) {\n    if (code === 62) {\n      effects.consume(code)\n      return completeAfter\n    }\n\n    return nok(code)\n  }\n\n  function completeAfter(code) {\n    if (markdownSpace(code)) {\n      effects.consume(code)\n      return completeAfter\n    }\n\n    return code === null || markdownLineEnding(code)\n      ? continuation(code)\n      : nok(code)\n  }\n\n  function continuation(code) {\n    if (code === 45 && kind === 2) {\n      effects.consume(code)\n      return continuationCommentInside\n    }\n\n    if (code === 60 && kind === 1) {\n      effects.consume(code)\n      return continuationRawTagOpen\n    }\n\n    if (code === 62 && kind === 4) {\n      effects.consume(code)\n      return continuationClose\n    }\n\n    if (code === 63 && kind === 3) {\n      effects.consume(code)\n      return continuationDeclarationInside\n    }\n\n    if (code === 93 && kind === 5) {\n      effects.consume(code)\n      return continuationCharacterDataInside\n    }\n\n    if (markdownLineEnding(code) && (kind === 6 || kind === 7)) {\n      return effects.check(\n        nextBlankConstruct,\n        continuationClose,\n        continuationAtLineEnding\n      )(code)\n    }\n\n    if (code === null || markdownLineEnding(code)) {\n      return continuationAtLineEnding(code)\n    }\n\n    effects.consume(code)\n    return continuation\n  }\n\n  function continuationAtLineEnding(code) {\n    effects.exit('htmlFlowData')\n    return htmlContinueStart(code)\n  }\n\n  function htmlContinueStart(code) {\n    if (code === null) {\n      return done(code)\n    }\n\n    if (markdownLineEnding(code)) {\n      effects.enter('lineEnding')\n      effects.consume(code)\n      effects.exit('lineEnding')\n      return htmlContinueStart\n    }\n\n    effects.enter('htmlFlowData')\n    return continuation(code)\n  }\n\n  function continuationCommentInside(code) {\n    if (code === 45) {\n      effects.consume(code)\n      return continuationDeclarationInside\n    }\n\n    return continuation(code)\n  }\n\n  function continuationRawTagOpen(code) {\n    if (code === 47) {\n      effects.consume(code)\n      buffer = ''\n      return continuationRawEndTag\n    }\n\n    return continuation(code)\n  }\n\n  function continuationRawEndTag(code) {\n    if (code === 62 && htmlRawNames.indexOf(buffer.toLowerCase()) > -1) {\n      effects.consume(code)\n      return continuationClose\n    }\n\n    if (asciiAlpha(code) && buffer.length < 8) {\n      effects.consume(code)\n      buffer += fromCharCode(code)\n      return continuationRawEndTag\n    }\n\n    return continuation(code)\n  }\n\n  function continuationCharacterDataInside(code) {\n    if (code === 93) {\n      effects.consume(code)\n      return continuationDeclarationInside\n    }\n\n    return continuation(code)\n  }\n\n  function continuationDeclarationInside(code) {\n    if (code === 62) {\n      effects.consume(code)\n      return continuationClose\n    }\n\n    return continuation(code)\n  }\n\n  function continuationClose(code) {\n    if (code === null || markdownLineEnding(code)) {\n      effects.exit('htmlFlowData')\n      return done(code)\n    }\n\n    effects.consume(code)\n    return continuationClose\n  }\n\n  function done(code) {\n    effects.exit('htmlFlow')\n    return ok(code)\n  }\n}\n\nfunction tokenizeNextBlank(effects, ok, nok) {\n  return start\n\n  function start(code) {\n    effects.exit('htmlFlowData')\n    effects.enter('lineEndingBlank')\n    effects.consume(code)\n    effects.exit('lineEndingBlank')\n    return effects.attempt(partialBlankLine, ok, nok)\n  }\n}\n\nmodule.exports = htmlFlow\n","'use strict'\n\nvar asciiAlpha = require('../character/ascii-alpha.js')\nvar asciiAlphanumeric = require('../character/ascii-alphanumeric.js')\nvar markdownLineEnding = require('../character/markdown-line-ending.js')\nvar markdownLineEndingOrSpace = require('../character/markdown-line-ending-or-space.js')\nvar markdownSpace = require('../character/markdown-space.js')\nvar factorySpace = require('./factory-space.js')\n\nvar htmlText = {\n  name: 'htmlText',\n  tokenize: tokenizeHtmlText\n}\n\nfunction tokenizeHtmlText(effects, ok, nok) {\n  var self = this\n  var marker\n  var buffer\n  var index\n  var returnState\n  return start\n\n  function start(code) {\n    effects.enter('htmlText')\n    effects.enter('htmlTextData')\n    effects.consume(code)\n    return open\n  }\n\n  function open(code) {\n    if (code === 33) {\n      effects.consume(code)\n      return declarationOpen\n    }\n\n    if (code === 47) {\n      effects.consume(code)\n      return tagCloseStart\n    }\n\n    if (code === 63) {\n      effects.consume(code)\n      return instruction\n    }\n\n    if (asciiAlpha(code)) {\n      effects.consume(code)\n      return tagOpen\n    }\n\n    return nok(code)\n  }\n\n  function declarationOpen(code) {\n    if (code === 45) {\n      effects.consume(code)\n      return commentOpen\n    }\n\n    if (code === 91) {\n      effects.consume(code)\n      buffer = 'CDATA['\n      index = 0\n      return cdataOpen\n    }\n\n    if (asciiAlpha(code)) {\n      effects.consume(code)\n      return declaration\n    }\n\n    return nok(code)\n  }\n\n  function commentOpen(code) {\n    if (code === 45) {\n      effects.consume(code)\n      return commentStart\n    }\n\n    return nok(code)\n  }\n\n  function commentStart(code) {\n    if (code === null || code === 62) {\n      return nok(code)\n    }\n\n    if (code === 45) {\n      effects.consume(code)\n      return commentStartDash\n    }\n\n    return comment(code)\n  }\n\n  function commentStartDash(code) {\n    if (code === null || code === 62) {\n      return nok(code)\n    }\n\n    return comment(code)\n  }\n\n  function comment(code) {\n    if (code === null) {\n      return nok(code)\n    }\n\n    if (code === 45) {\n      effects.consume(code)\n      return commentClose\n    }\n\n    if (markdownLineEnding(code)) {\n      returnState = comment\n      return atLineEnding(code)\n    }\n\n    effects.consume(code)\n    return comment\n  }\n\n  function commentClose(code) {\n    if (code === 45) {\n      effects.consume(code)\n      return end\n    }\n\n    return comment(code)\n  }\n\n  function cdataOpen(code) {\n    if (code === buffer.charCodeAt(index++)) {\n      effects.consume(code)\n      return index === buffer.length ? cdata : cdataOpen\n    }\n\n    return nok(code)\n  }\n\n  function cdata(code) {\n    if (code === null) {\n      return nok(code)\n    }\n\n    if (code === 93) {\n      effects.consume(code)\n      return cdataClose\n    }\n\n    if (markdownLineEnding(code)) {\n      returnState = cdata\n      return atLineEnding(code)\n    }\n\n    effects.consume(code)\n    return cdata\n  }\n\n  function cdataClose(code) {\n    if (code === 93) {\n      effects.consume(code)\n      return cdataEnd\n    }\n\n    return cdata(code)\n  }\n\n  function cdataEnd(code) {\n    if (code === 62) {\n      return end(code)\n    }\n\n    if (code === 93) {\n      effects.consume(code)\n      return cdataEnd\n    }\n\n    return cdata(code)\n  }\n\n  function declaration(code) {\n    if (code === null || code === 62) {\n      return end(code)\n    }\n\n    if (markdownLineEnding(code)) {\n      returnState = declaration\n      return atLineEnding(code)\n    }\n\n    effects.consume(code)\n    return declaration\n  }\n\n  function instruction(code) {\n    if (code === null) {\n      return nok(code)\n    }\n\n    if (code === 63) {\n      effects.consume(code)\n      return instructionClose\n    }\n\n    if (markdownLineEnding(code)) {\n      returnState = instruction\n      return atLineEnding(code)\n    }\n\n    effects.consume(code)\n    return instruction\n  }\n\n  function instructionClose(code) {\n    return code === 62 ? end(code) : instruction(code)\n  }\n\n  function tagCloseStart(code) {\n    if (asciiAlpha(code)) {\n      effects.consume(code)\n      return tagClose\n    }\n\n    return nok(code)\n  }\n\n  function tagClose(code) {\n    if (code === 45 || asciiAlphanumeric(code)) {\n      effects.consume(code)\n      return tagClose\n    }\n\n    return tagCloseBetween(code)\n  }\n\n  function tagCloseBetween(code) {\n    if (markdownLineEnding(code)) {\n      returnState = tagCloseBetween\n      return atLineEnding(code)\n    }\n\n    if (markdownSpace(code)) {\n      effects.consume(code)\n      return tagCloseBetween\n    }\n\n    return end(code)\n  }\n\n  function tagOpen(code) {\n    if (code === 45 || asciiAlphanumeric(code)) {\n      effects.consume(code)\n      return tagOpen\n    }\n\n    if (code === 47 || code === 62 || markdownLineEndingOrSpace(code)) {\n      return tagOpenBetween(code)\n    }\n\n    return nok(code)\n  }\n\n  function tagOpenBetween(code) {\n    if (code === 47) {\n      effects.consume(code)\n      return end\n    }\n\n    if (code === 58 || code === 95 || asciiAlpha(code)) {\n      effects.consume(code)\n      return tagOpenAttributeName\n    }\n\n    if (markdownLineEnding(code)) {\n      returnState = tagOpenBetween\n      return atLineEnding(code)\n    }\n\n    if (markdownSpace(code)) {\n      effects.consume(code)\n      return tagOpenBetween\n    }\n\n    return end(code)\n  }\n\n  function tagOpenAttributeName(code) {\n    if (\n      code === 45 ||\n      code === 46 ||\n      code === 58 ||\n      code === 95 ||\n      asciiAlphanumeric(code)\n    ) {\n      effects.consume(code)\n      return tagOpenAttributeName\n    }\n\n    return tagOpenAttributeNameAfter(code)\n  }\n\n  function tagOpenAttributeNameAfter(code) {\n    if (code === 61) {\n      effects.consume(code)\n      return tagOpenAttributeValueBefore\n    }\n\n    if (markdownLineEnding(code)) {\n      returnState = tagOpenAttributeNameAfter\n      return atLineEnding(code)\n    }\n\n    if (markdownSpace(code)) {\n      effects.consume(code)\n      return tagOpenAttributeNameAfter\n    }\n\n    return tagOpenBetween(code)\n  }\n\n  function tagOpenAttributeValueBefore(code) {\n    if (\n      code === null ||\n      code === 60 ||\n      code === 61 ||\n      code === 62 ||\n      code === 96\n    ) {\n      return nok(code)\n    }\n\n    if (code === 34 || code === 39) {\n      effects.consume(code)\n      marker = code\n      return tagOpenAttributeValueQuoted\n    }\n\n    if (markdownLineEnding(code)) {\n      returnState = tagOpenAttributeValueBefore\n      return atLineEnding(code)\n    }\n\n    if (markdownSpace(code)) {\n      effects.consume(code)\n      return tagOpenAttributeValueBefore\n    }\n\n    effects.consume(code)\n    marker = undefined\n    return tagOpenAttributeValueUnquoted\n  }\n\n  function tagOpenAttributeValueQuoted(code) {\n    if (code === marker) {\n      effects.consume(code)\n      return tagOpenAttributeValueQuotedAfter\n    }\n\n    if (code === null) {\n      return nok(code)\n    }\n\n    if (markdownLineEnding(code)) {\n      returnState = tagOpenAttributeValueQuoted\n      return atLineEnding(code)\n    }\n\n    effects.consume(code)\n    return tagOpenAttributeValueQuoted\n  }\n\n  function tagOpenAttributeValueQuotedAfter(code) {\n    if (code === 62 || code === 47 || markdownLineEndingOrSpace(code)) {\n      return tagOpenBetween(code)\n    }\n\n    return nok(code)\n  }\n\n  function tagOpenAttributeValueUnquoted(code) {\n    if (\n      code === null ||\n      code === 34 ||\n      code === 39 ||\n      code === 60 ||\n      code === 61 ||\n      code === 96\n    ) {\n      return nok(code)\n    }\n\n    if (code === 62 || markdownLineEndingOrSpace(code)) {\n      return tagOpenBetween(code)\n    }\n\n    effects.consume(code)\n    return tagOpenAttributeValueUnquoted\n  } // We cant have blank lines in content, so no need to worry about empty\n  // tokens.\n\n  function atLineEnding(code) {\n    effects.exit('htmlTextData')\n    effects.enter('lineEnding')\n    effects.consume(code)\n    effects.exit('lineEnding')\n    return factorySpace(\n      effects,\n      afterPrefix,\n      'linePrefix',\n      self.parser.constructs.disable.null.indexOf('codeIndented') > -1\n        ? undefined\n        : 4\n    )\n  }\n\n  function afterPrefix(code) {\n    effects.enter('htmlTextData')\n    return returnState(code)\n  }\n\n  function end(code) {\n    if (code === 62) {\n      effects.consume(code)\n      effects.exit('htmlTextData')\n      effects.exit('htmlText')\n      return ok\n    }\n\n    return nok(code)\n  }\n}\n\nmodule.exports = htmlText\n","'use strict'\n\nvar markdownLineEndingOrSpace = require('../character/markdown-line-ending-or-space.js')\nvar chunkedPush = require('../util/chunked-push.js')\nvar chunkedSplice = require('../util/chunked-splice.js')\nvar normalizeIdentifier = require('../util/normalize-identifier.js')\nvar resolveAll = require('../util/resolve-all.js')\nvar shallow = require('../util/shallow.js')\nvar factoryDestination = require('./factory-destination.js')\nvar factoryLabel = require('./factory-label.js')\nvar factoryTitle = require('./factory-title.js')\nvar factoryWhitespace = require('./factory-whitespace.js')\n\nvar labelEnd = {\n  name: 'labelEnd',\n  tokenize: tokenizeLabelEnd,\n  resolveTo: resolveToLabelEnd,\n  resolveAll: resolveAllLabelEnd\n}\nvar resourceConstruct = {\n  tokenize: tokenizeResource\n}\nvar fullReferenceConstruct = {\n  tokenize: tokenizeFullReference\n}\nvar collapsedReferenceConstruct = {\n  tokenize: tokenizeCollapsedReference\n}\n\nfunction resolveAllLabelEnd(events) {\n  var index = -1\n  var token\n\n  while (++index < events.length) {\n    token = events[index][1]\n\n    if (\n      !token._used &&\n      (token.type === 'labelImage' ||\n        token.type === 'labelLink' ||\n        token.type === 'labelEnd')\n    ) {\n      // Remove the marker.\n      events.splice(index + 1, token.type === 'labelImage' ? 4 : 2)\n      token.type = 'data'\n      index++\n    }\n  }\n\n  return events\n}\n\nfunction resolveToLabelEnd(events, context) {\n  var index = events.length\n  var offset = 0\n  var group\n  var label\n  var text\n  var token\n  var open\n  var close\n  var media // Find an opening.\n\n  while (index--) {\n    token = events[index][1]\n\n    if (open) {\n      // If we see another link, or inactive link label, weve been here before.\n      if (\n        token.type === 'link' ||\n        (token.type === 'labelLink' && token._inactive)\n      ) {\n        break\n      } // Mark other link openings as inactive, as we cant have links in\n      // links.\n\n      if (events[index][0] === 'enter' && token.type === 'labelLink') {\n        token._inactive = true\n      }\n    } else if (close) {\n      if (\n        events[index][0] === 'enter' &&\n        (token.type === 'labelImage' || token.type === 'labelLink') &&\n        !token._balanced\n      ) {\n        open = index\n\n        if (token.type !== 'labelLink') {\n          offset = 2\n          break\n        }\n      }\n    } else if (token.type === 'labelEnd') {\n      close = index\n    }\n  }\n\n  group = {\n    type: events[open][1].type === 'labelLink' ? 'link' : 'image',\n    start: shallow(events[open][1].start),\n    end: shallow(events[events.length - 1][1].end)\n  }\n  label = {\n    type: 'label',\n    start: shallow(events[open][1].start),\n    end: shallow(events[close][1].end)\n  }\n  text = {\n    type: 'labelText',\n    start: shallow(events[open + offset + 2][1].end),\n    end: shallow(events[close - 2][1].start)\n  }\n  media = [\n    ['enter', group, context],\n    ['enter', label, context]\n  ] // Opening marker.\n\n  media = chunkedPush(media, events.slice(open + 1, open + offset + 3)) // Text open.\n\n  media = chunkedPush(media, [['enter', text, context]]) // Between.\n\n  media = chunkedPush(\n    media,\n    resolveAll(\n      context.parser.constructs.insideSpan.null,\n      events.slice(open + offset + 4, close - 3),\n      context\n    )\n  ) // Text close, marker close, label close.\n\n  media = chunkedPush(media, [\n    ['exit', text, context],\n    events[close - 2],\n    events[close - 1],\n    ['exit', label, context]\n  ]) // Reference, resource, or so.\n\n  media = chunkedPush(media, events.slice(close + 1)) // Media close.\n\n  media = chunkedPush(media, [['exit', group, context]])\n  chunkedSplice(events, open, events.length, media)\n  return events\n}\n\nfunction tokenizeLabelEnd(effects, ok, nok) {\n  var self = this\n  var index = self.events.length\n  var labelStart\n  var defined // Find an opening.\n\n  while (index--) {\n    if (\n      (self.events[index][1].type === 'labelImage' ||\n        self.events[index][1].type === 'labelLink') &&\n      !self.events[index][1]._balanced\n    ) {\n      labelStart = self.events[index][1]\n      break\n    }\n  }\n\n  return start\n\n  function start(code) {\n    if (!labelStart) {\n      return nok(code)\n    } // Its a balanced bracket, but contains a link.\n\n    if (labelStart._inactive) return balanced(code)\n    defined =\n      self.parser.defined.indexOf(\n        normalizeIdentifier(\n          self.sliceSerialize({\n            start: labelStart.end,\n            end: self.now()\n          })\n        )\n      ) > -1\n    effects.enter('labelEnd')\n    effects.enter('labelMarker')\n    effects.consume(code)\n    effects.exit('labelMarker')\n    effects.exit('labelEnd')\n    return afterLabelEnd\n  }\n\n  function afterLabelEnd(code) {\n    // Resource: `[asd](fgh)`.\n    if (code === 40) {\n      return effects.attempt(\n        resourceConstruct,\n        ok,\n        defined ? ok : balanced\n      )(code)\n    } // Collapsed (`[asd][]`) or full (`[asd][fgh]`) reference?\n\n    if (code === 91) {\n      return effects.attempt(\n        fullReferenceConstruct,\n        ok,\n        defined\n          ? effects.attempt(collapsedReferenceConstruct, ok, balanced)\n          : balanced\n      )(code)\n    } // Shortcut reference: `[asd]`?\n\n    return defined ? ok(code) : balanced(code)\n  }\n\n  function balanced(code) {\n    labelStart._balanced = true\n    return nok(code)\n  }\n}\n\nfunction tokenizeResource(effects, ok, nok) {\n  return start\n\n  function start(code) {\n    effects.enter('resource')\n    effects.enter('resourceMarker')\n    effects.consume(code)\n    effects.exit('resourceMarker')\n    return factoryWhitespace(effects, open)\n  }\n\n  function open(code) {\n    if (code === 41) {\n      return end(code)\n    }\n\n    return factoryDestination(\n      effects,\n      destinationAfter,\n      nok,\n      'resourceDestination',\n      'resourceDestinationLiteral',\n      'resourceDestinationLiteralMarker',\n      'resourceDestinationRaw',\n      'resourceDestinationString',\n      3\n    )(code)\n  }\n\n  function destinationAfter(code) {\n    return markdownLineEndingOrSpace(code)\n      ? factoryWhitespace(effects, between)(code)\n      : end(code)\n  }\n\n  function between(code) {\n    if (code === 34 || code === 39 || code === 40) {\n      return factoryTitle(\n        effects,\n        factoryWhitespace(effects, end),\n        nok,\n        'resourceTitle',\n        'resourceTitleMarker',\n        'resourceTitleString'\n      )(code)\n    }\n\n    return end(code)\n  }\n\n  function end(code) {\n    if (code === 41) {\n      effects.enter('resourceMarker')\n      effects.consume(code)\n      effects.exit('resourceMarker')\n      effects.exit('resource')\n      return ok\n    }\n\n    return nok(code)\n  }\n}\n\nfunction tokenizeFullReference(effects, ok, nok) {\n  var self = this\n  return start\n\n  function start(code) {\n    return factoryLabel.call(\n      self,\n      effects,\n      afterLabel,\n      nok,\n      'reference',\n      'referenceMarker',\n      'referenceString'\n    )(code)\n  }\n\n  function afterLabel(code) {\n    return self.parser.defined.indexOf(\n      normalizeIdentifier(\n        self.sliceSerialize(self.events[self.events.length - 1][1]).slice(1, -1)\n      )\n    ) < 0\n      ? nok(code)\n      : ok(code)\n  }\n}\n\nfunction tokenizeCollapsedReference(effects, ok, nok) {\n  return start\n\n  function start(code) {\n    effects.enter('reference')\n    effects.enter('referenceMarker')\n    effects.consume(code)\n    effects.exit('referenceMarker')\n    return open\n  }\n\n  function open(code) {\n    if (code === 93) {\n      effects.enter('referenceMarker')\n      effects.consume(code)\n      effects.exit('referenceMarker')\n      effects.exit('reference')\n      return ok\n    }\n\n    return nok(code)\n  }\n}\n\nmodule.exports = labelEnd\n","'use strict'\n\nvar labelEnd = require('./label-end.js')\n\nvar labelStartImage = {\n  name: 'labelStartImage',\n  tokenize: tokenizeLabelStartImage,\n  resolveAll: labelEnd.resolveAll\n}\n\nfunction tokenizeLabelStartImage(effects, ok, nok) {\n  var self = this\n  return start\n\n  function start(code) {\n    effects.enter('labelImage')\n    effects.enter('labelImageMarker')\n    effects.consume(code)\n    effects.exit('labelImageMarker')\n    return open\n  }\n\n  function open(code) {\n    if (code === 91) {\n      effects.enter('labelMarker')\n      effects.consume(code)\n      effects.exit('labelMarker')\n      effects.exit('labelImage')\n      return after\n    }\n\n    return nok(code)\n  }\n\n  function after(code) {\n    /* c8 ignore next */\n    return code === 94 &&\n      /* c8 ignore next */\n      '_hiddenFootnoteSupport' in self.parser.constructs\n      ? /* c8 ignore next */\n        nok(code)\n      : ok(code)\n  }\n}\n\nmodule.exports = labelStartImage\n","'use strict'\n\nvar labelEnd = require('./label-end.js')\n\nvar labelStartLink = {\n  name: 'labelStartLink',\n  tokenize: tokenizeLabelStartLink,\n  resolveAll: labelEnd.resolveAll\n}\n\nfunction tokenizeLabelStartLink(effects, ok, nok) {\n  var self = this\n  return start\n\n  function start(code) {\n    effects.enter('labelLink')\n    effects.enter('labelMarker')\n    effects.consume(code)\n    effects.exit('labelMarker')\n    effects.exit('labelLink')\n    return after\n  }\n\n  function after(code) {\n    /* c8 ignore next */\n    return code === 94 &&\n      /* c8 ignore next */\n      '_hiddenFootnoteSupport' in self.parser.constructs\n      ? /* c8 ignore next */\n        nok(code)\n      : ok(code)\n  }\n}\n\nmodule.exports = labelStartLink\n","'use strict'\n\nvar factorySpace = require('./factory-space.js')\n\nvar lineEnding = {\n  name: 'lineEnding',\n  tokenize: tokenizeLineEnding\n}\n\nfunction tokenizeLineEnding(effects, ok) {\n  return start\n\n  function start(code) {\n    effects.enter('lineEnding')\n    effects.consume(code)\n    effects.exit('lineEnding')\n    return factorySpace(effects, ok, 'linePrefix')\n  }\n}\n\nmodule.exports = lineEnding\n","'use strict'\n\nvar asciiDigit = require('../character/ascii-digit.js')\nvar markdownSpace = require('../character/markdown-space.js')\nvar prefixSize = require('../util/prefix-size.js')\nvar sizeChunks = require('../util/size-chunks.js')\nvar factorySpace = require('./factory-space.js')\nvar partialBlankLine = require('./partial-blank-line.js')\nvar thematicBreak = require('./thematic-break.js')\n\nvar list = {\n  name: 'list',\n  tokenize: tokenizeListStart,\n  continuation: {\n    tokenize: tokenizeListContinuation\n  },\n  exit: tokenizeListEnd\n}\nvar listItemPrefixWhitespaceConstruct = {\n  tokenize: tokenizeListItemPrefixWhitespace,\n  partial: true\n}\nvar indentConstruct = {\n  tokenize: tokenizeIndent,\n  partial: true\n}\n\nfunction tokenizeListStart(effects, ok, nok) {\n  var self = this\n  var initialSize = prefixSize(self.events, 'linePrefix')\n  var size = 0\n  return start\n\n  function start(code) {\n    var kind =\n      self.containerState.type ||\n      (code === 42 || code === 43 || code === 45\n        ? 'listUnordered'\n        : 'listOrdered')\n\n    if (\n      kind === 'listUnordered'\n        ? !self.containerState.marker || code === self.containerState.marker\n        : asciiDigit(code)\n    ) {\n      if (!self.containerState.type) {\n        self.containerState.type = kind\n        effects.enter(kind, {\n          _container: true\n        })\n      }\n\n      if (kind === 'listUnordered') {\n        effects.enter('listItemPrefix')\n        return code === 42 || code === 45\n          ? effects.check(thematicBreak, nok, atMarker)(code)\n          : atMarker(code)\n      }\n\n      if (!self.interrupt || code === 49) {\n        effects.enter('listItemPrefix')\n        effects.enter('listItemValue')\n        return inside(code)\n      }\n    }\n\n    return nok(code)\n  }\n\n  function inside(code) {\n    if (asciiDigit(code) && ++size < 10) {\n      effects.consume(code)\n      return inside\n    }\n\n    if (\n      (!self.interrupt || size < 2) &&\n      (self.containerState.marker\n        ? code === self.containerState.marker\n        : code === 41 || code === 46)\n    ) {\n      effects.exit('listItemValue')\n      return atMarker(code)\n    }\n\n    return nok(code)\n  }\n\n  function atMarker(code) {\n    effects.enter('listItemMarker')\n    effects.consume(code)\n    effects.exit('listItemMarker')\n    self.containerState.marker = self.containerState.marker || code\n    return effects.check(\n      partialBlankLine, // Cant be empty when interrupting.\n      self.interrupt ? nok : onBlank,\n      effects.attempt(\n        listItemPrefixWhitespaceConstruct,\n        endOfPrefix,\n        otherPrefix\n      )\n    )\n  }\n\n  function onBlank(code) {\n    self.containerState.initialBlankLine = true\n    initialSize++\n    return endOfPrefix(code)\n  }\n\n  function otherPrefix(code) {\n    if (markdownSpace(code)) {\n      effects.enter('listItemPrefixWhitespace')\n      effects.consume(code)\n      effects.exit('listItemPrefixWhitespace')\n      return endOfPrefix\n    }\n\n    return nok(code)\n  }\n\n  function endOfPrefix(code) {\n    self.containerState.size =\n      initialSize + sizeChunks(self.sliceStream(effects.exit('listItemPrefix')))\n    return ok(code)\n  }\n}\n\nfunction tokenizeListContinuation(effects, ok, nok) {\n  var self = this\n  self.containerState._closeFlow = undefined\n  return effects.check(partialBlankLine, onBlank, notBlank)\n\n  function onBlank(code) {\n    self.containerState.furtherBlankLines =\n      self.containerState.furtherBlankLines ||\n      self.containerState.initialBlankLine // We have a blank line.\n    // Still, try to consume at most the items size.\n\n    return factorySpace(\n      effects,\n      ok,\n      'listItemIndent',\n      self.containerState.size + 1\n    )(code)\n  }\n\n  function notBlank(code) {\n    if (self.containerState.furtherBlankLines || !markdownSpace(code)) {\n      self.containerState.furtherBlankLines = self.containerState.initialBlankLine = undefined\n      return notInCurrentItem(code)\n    }\n\n    self.containerState.furtherBlankLines = self.containerState.initialBlankLine = undefined\n    return effects.attempt(indentConstruct, ok, notInCurrentItem)(code)\n  }\n\n  function notInCurrentItem(code) {\n    // While we do continue, we signal that the flow should be closed.\n    self.containerState._closeFlow = true // As were closing flow, were no longer interrupting.\n\n    self.interrupt = undefined\n    return factorySpace(\n      effects,\n      effects.attempt(list, ok, nok),\n      'linePrefix',\n      self.parser.constructs.disable.null.indexOf('codeIndented') > -1\n        ? undefined\n        : 4\n    )(code)\n  }\n}\n\nfunction tokenizeIndent(effects, ok, nok) {\n  var self = this\n  return factorySpace(\n    effects,\n    afterPrefix,\n    'listItemIndent',\n    self.containerState.size + 1\n  )\n\n  function afterPrefix(code) {\n    return prefixSize(self.events, 'listItemIndent') ===\n      self.containerState.size\n      ? ok(code)\n      : nok(code)\n  }\n}\n\nfunction tokenizeListEnd(effects) {\n  effects.exit(this.containerState.type)\n}\n\nfunction tokenizeListItemPrefixWhitespace(effects, ok, nok) {\n  var self = this\n  return factorySpace(\n    effects,\n    afterPrefix,\n    'listItemPrefixWhitespace',\n    self.parser.constructs.disable.null.indexOf('codeIndented') > -1\n      ? undefined\n      : 4 + 1\n  )\n\n  function afterPrefix(code) {\n    return markdownSpace(code) ||\n      !prefixSize(self.events, 'listItemPrefixWhitespace')\n      ? nok(code)\n      : ok(code)\n  }\n}\n\nmodule.exports = list\n","'use strict'\n\nvar markdownLineEnding = require('../character/markdown-line-ending.js')\nvar factorySpace = require('./factory-space.js')\n\nvar partialBlankLine = {\n  tokenize: tokenizePartialBlankLine,\n  partial: true\n}\n\nfunction tokenizePartialBlankLine(effects, ok, nok) {\n  return factorySpace(effects, afterWhitespace, 'linePrefix')\n\n  function afterWhitespace(code) {\n    return code === null || markdownLineEnding(code) ? ok(code) : nok(code)\n  }\n}\n\nmodule.exports = partialBlankLine\n","'use strict'\n\nvar markdownLineEnding = require('../character/markdown-line-ending.js')\nvar shallow = require('../util/shallow.js')\nvar factorySpace = require('./factory-space.js')\n\nvar setextUnderline = {\n  name: 'setextUnderline',\n  tokenize: tokenizeSetextUnderline,\n  resolveTo: resolveToSetextUnderline\n}\n\nfunction resolveToSetextUnderline(events, context) {\n  var index = events.length\n  var content\n  var text\n  var definition\n  var heading // Find the opening of the content.\n  // Itll always exist: we dont tokenize if it isnt there.\n\n  while (index--) {\n    if (events[index][0] === 'enter') {\n      if (events[index][1].type === 'content') {\n        content = index\n        break\n      }\n\n      if (events[index][1].type === 'paragraph') {\n        text = index\n      }\n    } // Exit\n    else {\n      if (events[index][1].type === 'content') {\n        // Remove the content end (if needed well add it later)\n        events.splice(index, 1)\n      }\n\n      if (!definition && events[index][1].type === 'definition') {\n        definition = index\n      }\n    }\n  }\n\n  heading = {\n    type: 'setextHeading',\n    start: shallow(events[text][1].start),\n    end: shallow(events[events.length - 1][1].end)\n  } // Change the paragraph to setext heading text.\n\n  events[text][1].type = 'setextHeadingText' // If we have definitions in the content, well keep on having content,\n  // but we need move it.\n\n  if (definition) {\n    events.splice(text, 0, ['enter', heading, context])\n    events.splice(definition + 1, 0, ['exit', events[content][1], context])\n    events[content][1].end = shallow(events[definition][1].end)\n  } else {\n    events[content][1] = heading\n  } // Add the heading exit at the end.\n\n  events.push(['exit', heading, context])\n  return events\n}\n\nfunction tokenizeSetextUnderline(effects, ok, nok) {\n  var self = this\n  var index = self.events.length\n  var marker\n  var paragraph // Find an opening.\n\n  while (index--) {\n    // Skip enter/exit of line ending, line prefix, and content.\n    // We can now either have a definition or a paragraph.\n    if (\n      self.events[index][1].type !== 'lineEnding' &&\n      self.events[index][1].type !== 'linePrefix' &&\n      self.events[index][1].type !== 'content'\n    ) {\n      paragraph = self.events[index][1].type === 'paragraph'\n      break\n    }\n  }\n\n  return start\n\n  function start(code) {\n    if (!self.lazy && (self.interrupt || paragraph)) {\n      effects.enter('setextHeadingLine')\n      effects.enter('setextHeadingLineSequence')\n      marker = code\n      return closingSequence(code)\n    }\n\n    return nok(code)\n  }\n\n  function closingSequence(code) {\n    if (code === marker) {\n      effects.consume(code)\n      return closingSequence\n    }\n\n    effects.exit('setextHeadingLineSequence')\n    return factorySpace(effects, closingSequenceEnd, 'lineSuffix')(code)\n  }\n\n  function closingSequenceEnd(code) {\n    if (code === null || markdownLineEnding(code)) {\n      effects.exit('setextHeadingLine')\n      return ok(code)\n    }\n\n    return nok(code)\n  }\n}\n\nmodule.exports = setextUnderline\n","'use strict'\n\nvar markdownLineEnding = require('../character/markdown-line-ending.js')\nvar markdownSpace = require('../character/markdown-space.js')\nvar factorySpace = require('./factory-space.js')\n\nvar thematicBreak = {\n  name: 'thematicBreak',\n  tokenize: tokenizeThematicBreak\n}\n\nfunction tokenizeThematicBreak(effects, ok, nok) {\n  var size = 0\n  var marker\n  return start\n\n  function start(code) {\n    effects.enter('thematicBreak')\n    marker = code\n    return atBreak(code)\n  }\n\n  function atBreak(code) {\n    if (code === marker) {\n      effects.enter('thematicBreakSequence')\n      return sequence(code)\n    }\n\n    if (markdownSpace(code)) {\n      return factorySpace(effects, atBreak, 'whitespace')(code)\n    }\n\n    if (size < 3 || (code !== null && !markdownLineEnding(code))) {\n      return nok(code)\n    }\n\n    effects.exit('thematicBreak')\n    return ok(code)\n  }\n\n  function sequence(code) {\n    if (code === marker) {\n      effects.consume(code)\n      size++\n      return sequence\n    }\n\n    effects.exit('thematicBreakSequence')\n    return atBreak(code)\n  }\n}\n\nmodule.exports = thematicBreak\n","'use strict'\n\nvar chunkedSplice = require('./chunked-splice.js')\n\nfunction chunkedPush(list, items) {\n  if (list.length) {\n    chunkedSplice(list, list.length, 0, items)\n    return list\n  }\n\n  return items\n}\n\nmodule.exports = chunkedPush\n","'use strict'\n\nvar splice = require('../constant/splice.js')\n\n// causes a stack overflow in V8 when trying to insert 100k items for instance.\n\nfunction chunkedSplice(list, start, remove, items) {\n  var end = list.length\n  var chunkStart = 0\n  var parameters // Make start between zero and `end` (included).\n\n  if (start < 0) {\n    start = -start > end ? 0 : end + start\n  } else {\n    start = start > end ? end : start\n  }\n\n  remove = remove > 0 ? remove : 0 // No need to chunk the items if theres only a couple (10k) items.\n\n  if (items.length < 10000) {\n    parameters = Array.from(items)\n    parameters.unshift(start, remove)\n    splice.apply(list, parameters)\n  } else {\n    // Delete `remove` items starting from `start`\n    if (remove) splice.apply(list, [start, remove]) // Insert the items in chunks to not cause stack overflows.\n\n    while (chunkStart < items.length) {\n      parameters = items.slice(chunkStart, chunkStart + 10000)\n      parameters.unshift(start, 0)\n      splice.apply(list, parameters)\n      chunkStart += 10000\n      start += 10000\n    }\n  }\n}\n\nmodule.exports = chunkedSplice\n","'use strict'\n\nvar markdownLineEndingOrSpace = require('../character/markdown-line-ending-or-space.js')\nvar unicodePunctuation = require('../character/unicode-punctuation.js')\nvar unicodeWhitespace = require('../character/unicode-whitespace.js')\n\n// Classify whether a character is unicode whitespace, unicode punctuation, or\n// anything else.\n// Used for attention (emphasis, strong), whose sequences can open or close\n// based on the class of surrounding characters.\nfunction classifyCharacter(code) {\n  if (\n    code === null ||\n    markdownLineEndingOrSpace(code) ||\n    unicodeWhitespace(code)\n  ) {\n    return 1\n  }\n\n  if (unicodePunctuation(code)) {\n    return 2\n  }\n}\n\nmodule.exports = classifyCharacter\n","'use strict'\n\nvar hasOwnProperty = require('../constant/has-own-property.js')\nvar chunkedSplice = require('./chunked-splice.js')\nvar miniflat = require('./miniflat.js')\n\nfunction combineExtensions(extensions) {\n  var all = {}\n  var index = -1\n\n  while (++index < extensions.length) {\n    extension(all, extensions[index])\n  }\n\n  return all\n}\n\nfunction extension(all, extension) {\n  var hook\n  var left\n  var right\n  var code\n\n  for (hook in extension) {\n    left = hasOwnProperty.call(all, hook) ? all[hook] : (all[hook] = {})\n    right = extension[hook]\n\n    for (code in right) {\n      left[code] = constructs(\n        miniflat(right[code]),\n        hasOwnProperty.call(left, code) ? left[code] : []\n      )\n    }\n  }\n}\n\nfunction constructs(list, existing) {\n  var index = -1\n  var before = []\n\n  while (++index < list.length) {\n    ;(list[index].add === 'after' ? existing : before).push(list[index])\n  }\n\n  chunkedSplice(existing, 0, 0, before)\n  return existing\n}\n\nmodule.exports = combineExtensions\n","'use strict'\n\nvar assign = require('../constant/assign.js')\nvar markdownLineEnding = require('../character/markdown-line-ending.js')\nvar chunkedPush = require('./chunked-push.js')\nvar chunkedSplice = require('./chunked-splice.js')\nvar miniflat = require('./miniflat.js')\nvar resolveAll = require('./resolve-all.js')\nvar serializeChunks = require('./serialize-chunks.js')\nvar shallow = require('./shallow.js')\nvar sliceChunks = require('./slice-chunks.js')\n\n// Create a tokenizer.\n// Tokenizers deal with one type of data (e.g., containers, flow, text).\n// The parser is the object dealing with it all.\n// `initialize` works like other constructs, except that only its `tokenize`\n// function is used, in which case it doesnt receive an `ok` or `nok`.\n// `from` can be given to set the point before the first character, although\n// when further lines are indented, they must be set with `defineSkip`.\nfunction createTokenizer(parser, initialize, from) {\n  var point = from\n    ? shallow(from)\n    : {\n        line: 1,\n        column: 1,\n        offset: 0\n      }\n  var columnStart = {}\n  var resolveAllConstructs = []\n  var chunks = []\n  var stack = []\n\n  var effects = {\n    consume: consume,\n    enter: enter,\n    exit: exit,\n    attempt: constructFactory(onsuccessfulconstruct),\n    check: constructFactory(onsuccessfulcheck),\n    interrupt: constructFactory(onsuccessfulcheck, {\n      interrupt: true\n    }),\n    lazy: constructFactory(onsuccessfulcheck, {\n      lazy: true\n    })\n  } // State and tools for resolving and serializing.\n\n  var context = {\n    previous: null,\n    events: [],\n    parser: parser,\n    sliceStream: sliceStream,\n    sliceSerialize: sliceSerialize,\n    now: now,\n    defineSkip: skip,\n    write: write\n  } // The state function.\n\n  var state = initialize.tokenize.call(context, effects) // Track which character we expect to be consumed, to catch bugs.\n\n  if (initialize.resolveAll) {\n    resolveAllConstructs.push(initialize)\n  } // Store where we are in the input stream.\n\n  point._index = 0\n  point._bufferIndex = -1\n  return context\n\n  function write(slice) {\n    chunks = chunkedPush(chunks, slice)\n    main() // Exit if were not done, resolve might change stuff.\n\n    if (chunks[chunks.length - 1] !== null) {\n      return []\n    }\n\n    addResult(initialize, 0) // Otherwise, resolve, and exit.\n\n    context.events = resolveAll(resolveAllConstructs, context.events, context)\n    return context.events\n  } //\n  // Tools.\n  //\n\n  function sliceSerialize(token) {\n    return serializeChunks(sliceStream(token))\n  }\n\n  function sliceStream(token) {\n    return sliceChunks(chunks, token)\n  }\n\n  function now() {\n    return shallow(point)\n  }\n\n  function skip(value) {\n    columnStart[value.line] = value.column\n    accountForPotentialSkip()\n  } //\n  // State management.\n  //\n  // Main loop (note that `_index` and `_bufferIndex` in `point` are modified by\n  // `consume`).\n  // Here is where we walk through the chunks, which either include strings of\n  // several characters, or numerical character codes.\n  // The reason to do this in a loop instead of a call is so the stack can\n  // drain.\n\n  function main() {\n    var chunkIndex\n    var chunk\n\n    while (point._index < chunks.length) {\n      chunk = chunks[point._index] // If were in a buffer chunk, loop through it.\n\n      if (typeof chunk === 'string') {\n        chunkIndex = point._index\n\n        if (point._bufferIndex < 0) {\n          point._bufferIndex = 0\n        }\n\n        while (\n          point._index === chunkIndex &&\n          point._bufferIndex < chunk.length\n        ) {\n          go(chunk.charCodeAt(point._bufferIndex))\n        }\n      } else {\n        go(chunk)\n      }\n    }\n  } // Deal with one code.\n\n  function go(code) {\n    state = state(code)\n  } // Move a character forward.\n\n  function consume(code) {\n    if (markdownLineEnding(code)) {\n      point.line++\n      point.column = 1\n      point.offset += code === -3 ? 2 : 1\n      accountForPotentialSkip()\n    } else if (code !== -1) {\n      point.column++\n      point.offset++\n    } // Not in a string chunk.\n\n    if (point._bufferIndex < 0) {\n      point._index++\n    } else {\n      point._bufferIndex++ // At end of string chunk.\n\n      if (point._bufferIndex === chunks[point._index].length) {\n        point._bufferIndex = -1\n        point._index++\n      }\n    } // Expose the previous character.\n\n    context.previous = code // Mark as consumed.\n  } // Start a token.\n\n  function enter(type, fields) {\n    var token = fields || {}\n    token.type = type\n    token.start = now()\n    context.events.push(['enter', token, context])\n    stack.push(token)\n    return token\n  } // Stop a token.\n\n  function exit(type) {\n    var token = stack.pop()\n    token.end = now()\n    context.events.push(['exit', token, context])\n    return token\n  } // Use results.\n\n  function onsuccessfulconstruct(construct, info) {\n    addResult(construct, info.from)\n  } // Discard results.\n\n  function onsuccessfulcheck(construct, info) {\n    info.restore()\n  } // Factory to attempt/check/interrupt.\n\n  function constructFactory(onreturn, fields) {\n    return hook // Handle either an object mapping codes to constructs, a list of\n    // constructs, or a single construct.\n\n    function hook(constructs, returnState, bogusState) {\n      var listOfConstructs\n      var constructIndex\n      var currentConstruct\n      var info\n      return constructs.tokenize || 'length' in constructs\n        ? handleListOfConstructs(miniflat(constructs))\n        : handleMapOfConstructs\n\n      function handleMapOfConstructs(code) {\n        if (code in constructs || null in constructs) {\n          return handleListOfConstructs(\n            constructs.null\n              ? /* c8 ignore next */\n                miniflat(constructs[code]).concat(miniflat(constructs.null))\n              : constructs[code]\n          )(code)\n        }\n\n        return bogusState(code)\n      }\n\n      function handleListOfConstructs(list) {\n        listOfConstructs = list\n        constructIndex = 0\n        return handleConstruct(list[constructIndex])\n      }\n\n      function handleConstruct(construct) {\n        return start\n\n        function start(code) {\n          // To do: not nede to store if there is no bogus state, probably?\n          // Currently doesnt work because `inspect` in document does a check\n          // w/o a bogus, which doesnt make sense. But it does seem to help perf\n          // by not storing.\n          info = store()\n          currentConstruct = construct\n\n          if (!construct.partial) {\n            context.currentConstruct = construct\n          }\n\n          if (\n            construct.name &&\n            context.parser.constructs.disable.null.indexOf(construct.name) > -1\n          ) {\n            return nok()\n          }\n\n          return construct.tokenize.call(\n            fields ? assign({}, context, fields) : context,\n            effects,\n            ok,\n            nok\n          )(code)\n        }\n      }\n\n      function ok(code) {\n        onreturn(currentConstruct, info)\n        return returnState\n      }\n\n      function nok(code) {\n        info.restore()\n\n        if (++constructIndex < listOfConstructs.length) {\n          return handleConstruct(listOfConstructs[constructIndex])\n        }\n\n        return bogusState\n      }\n    }\n  }\n\n  function addResult(construct, from) {\n    if (construct.resolveAll && resolveAllConstructs.indexOf(construct) < 0) {\n      resolveAllConstructs.push(construct)\n    }\n\n    if (construct.resolve) {\n      chunkedSplice(\n        context.events,\n        from,\n        context.events.length - from,\n        construct.resolve(context.events.slice(from), context)\n      )\n    }\n\n    if (construct.resolveTo) {\n      context.events = construct.resolveTo(context.events, context)\n    }\n  }\n\n  function store() {\n    var startPoint = now()\n    var startPrevious = context.previous\n    var startCurrentConstruct = context.currentConstruct\n    var startEventsIndex = context.events.length\n    var startStack = Array.from(stack)\n    return {\n      restore: restore,\n      from: startEventsIndex\n    }\n\n    function restore() {\n      point = startPoint\n      context.previous = startPrevious\n      context.currentConstruct = startCurrentConstruct\n      context.events.length = startEventsIndex\n      stack = startStack\n      accountForPotentialSkip()\n    }\n  }\n\n  function accountForPotentialSkip() {\n    if (point.line in columnStart && point.column < 2) {\n      point.column = columnStart[point.line]\n      point.offset += columnStart[point.line] - 1\n    }\n  }\n}\n\nmodule.exports = createTokenizer\n","'use strict'\n\nfunction miniflat(value) {\n  return value === null || value === undefined\n    ? []\n    : 'length' in value\n    ? value\n    : [value]\n}\n\nmodule.exports = miniflat\n","'use strict'\n\n// chunks (replacement characters, tabs, or line endings).\n\nfunction movePoint(point, offset) {\n  point.column += offset\n  point.offset += offset\n  point._bufferIndex += offset\n  return point\n}\n\nmodule.exports = movePoint\n","'use strict'\n\nfunction normalizeIdentifier(value) {\n  return (\n    value // Collapse Markdown whitespace.\n      .replace(/[\\t\\n\\r ]+/g, ' ') // Trim.\n      .replace(/^ | $/g, '') // Some characters are considered uppercase, but if their lowercase\n      // counterpart is uppercased will result in a different uppercase\n      // character.\n      // Hence, to get that form, we perform both lower- and uppercase.\n      // Upper case makes sure keys will not interact with default prototypal\n      // methods: no object method is uppercase.\n      .toLowerCase()\n      .toUpperCase()\n  )\n}\n\nmodule.exports = normalizeIdentifier\n","'use strict'\n\nvar sizeChunks = require('./size-chunks.js')\n\nfunction prefixSize(events, type) {\n  var tail = events[events.length - 1]\n  if (!tail || tail[1].type !== type) return 0\n  return sizeChunks(tail[2].sliceStream(tail[1]))\n}\n\nmodule.exports = prefixSize\n","'use strict'\n\nvar fromCharCode = require('../constant/from-char-code.js')\n\nfunction regexCheck(regex) {\n  return check\n\n  function check(code) {\n    return regex.test(fromCharCode(code))\n  }\n}\n\nmodule.exports = regexCheck\n","'use strict'\n\nfunction resolveAll(constructs, events, context) {\n  var called = []\n  var index = -1\n  var resolve\n\n  while (++index < constructs.length) {\n    resolve = constructs[index].resolveAll\n\n    if (resolve && called.indexOf(resolve) < 0) {\n      events = resolve(events, context)\n      called.push(resolve)\n    }\n  }\n\n  return events\n}\n\nmodule.exports = resolveAll\n","'use strict'\n\nvar fromCharCode = require('../constant/from-char-code.js')\n\nfunction safeFromInt(value, base) {\n  var code = parseInt(value, base)\n\n  if (\n    // C0 except for HT, LF, FF, CR, space\n    code < 9 ||\n    code === 11 ||\n    (code > 13 && code < 32) || // Control character (DEL) of the basic block and C1 controls.\n    (code > 126 && code < 160) || // Lone high surrogates and low surrogates.\n    (code > 55295 && code < 57344) || // Noncharacters.\n    (code > 64975 && code < 65008) ||\n    (code & 65535) === 65535 ||\n    (code & 65535) === 65534 || // Out of range\n    code > 1114111\n  ) {\n    return '\\uFFFD'\n  }\n\n  return fromCharCode(code)\n}\n\nmodule.exports = safeFromInt\n","'use strict'\n\nvar fromCharCode = require('../constant/from-char-code.js')\n\nfunction serializeChunks(chunks) {\n  var index = -1\n  var result = []\n  var chunk\n  var value\n  var atTab\n\n  while (++index < chunks.length) {\n    chunk = chunks[index]\n\n    if (typeof chunk === 'string') {\n      value = chunk\n    } else if (chunk === -5) {\n      value = '\\r'\n    } else if (chunk === -4) {\n      value = '\\n'\n    } else if (chunk === -3) {\n      value = '\\r' + '\\n'\n    } else if (chunk === -2) {\n      value = '\\t'\n    } else if (chunk === -1) {\n      if (atTab) continue\n      value = ' '\n    } else {\n      // Currently only replacement character.\n      value = fromCharCode(chunk)\n    }\n\n    atTab = chunk === -2\n    result.push(value)\n  }\n\n  return result.join('')\n}\n\nmodule.exports = serializeChunks\n","'use strict'\n\nvar assign = require('../constant/assign.js')\n\nfunction shallow(object) {\n  return assign({}, object)\n}\n\nmodule.exports = shallow\n","'use strict'\n\n// Counts tabs based on their expanded size, and CR+LF as one character.\n\nfunction sizeChunks(chunks) {\n  var index = -1\n  var size = 0\n\n  while (++index < chunks.length) {\n    size += typeof chunks[index] === 'string' ? chunks[index].length : 1\n  }\n\n  return size\n}\n\nmodule.exports = sizeChunks\n","'use strict'\n\nfunction sliceChunks(chunks, token) {\n  var startIndex = token.start._index\n  var startBufferIndex = token.start._bufferIndex\n  var endIndex = token.end._index\n  var endBufferIndex = token.end._bufferIndex\n  var view\n\n  if (startIndex === endIndex) {\n    view = [chunks[startIndex].slice(startBufferIndex, endBufferIndex)]\n  } else {\n    view = chunks.slice(startIndex, endIndex)\n\n    if (startBufferIndex > -1) {\n      view[0] = view[0].slice(startBufferIndex)\n    }\n\n    if (endBufferIndex > 0) {\n      view.push(chunks[endIndex].slice(0, endBufferIndex))\n    }\n  }\n\n  return view\n}\n\nmodule.exports = sliceChunks\n","'use strict'\n\nvar assign = require('../constant/assign.js')\nvar chunkedSplice = require('./chunked-splice.js')\nvar shallow = require('./shallow.js')\n\nfunction subtokenize(events) {\n  var jumps = {}\n  var index = -1\n  var event\n  var lineIndex\n  var otherIndex\n  var otherEvent\n  var parameters\n  var subevents\n  var more\n\n  while (++index < events.length) {\n    while (index in jumps) {\n      index = jumps[index]\n    }\n\n    event = events[index] // Add a hook for the GFM tasklist extension, which needs to know if text\n    // is in the first content of a list item.\n\n    if (\n      index &&\n      event[1].type === 'chunkFlow' &&\n      events[index - 1][1].type === 'listItemPrefix'\n    ) {\n      subevents = event[1]._tokenizer.events\n      otherIndex = 0\n\n      if (\n        otherIndex < subevents.length &&\n        subevents[otherIndex][1].type === 'lineEndingBlank'\n      ) {\n        otherIndex += 2\n      }\n\n      if (\n        otherIndex < subevents.length &&\n        subevents[otherIndex][1].type === 'content'\n      ) {\n        while (++otherIndex < subevents.length) {\n          if (subevents[otherIndex][1].type === 'content') {\n            break\n          }\n\n          if (subevents[otherIndex][1].type === 'chunkText') {\n            subevents[otherIndex][1].isInFirstContentOfListItem = true\n            otherIndex++\n          }\n        }\n      }\n    } // Enter.\n\n    if (event[0] === 'enter') {\n      if (event[1].contentType) {\n        assign(jumps, subcontent(events, index))\n        index = jumps[index]\n        more = true\n      }\n    } // Exit.\n    else if (event[1]._container || event[1]._movePreviousLineEndings) {\n      otherIndex = index\n      lineIndex = undefined\n\n      while (otherIndex--) {\n        otherEvent = events[otherIndex]\n\n        if (\n          otherEvent[1].type === 'lineEnding' ||\n          otherEvent[1].type === 'lineEndingBlank'\n        ) {\n          if (otherEvent[0] === 'enter') {\n            if (lineIndex) {\n              events[lineIndex][1].type = 'lineEndingBlank'\n            }\n\n            otherEvent[1].type = 'lineEnding'\n            lineIndex = otherIndex\n          }\n        } else {\n          break\n        }\n      }\n\n      if (lineIndex) {\n        // Fix position.\n        event[1].end = shallow(events[lineIndex][1].start) // Switch container exit w/ line endings.\n\n        parameters = events.slice(lineIndex, index)\n        parameters.unshift(event)\n        chunkedSplice(events, lineIndex, index - lineIndex + 1, parameters)\n      }\n    }\n  }\n\n  return !more\n}\n\nfunction subcontent(events, eventIndex) {\n  var token = events[eventIndex][1]\n  var context = events[eventIndex][2]\n  var startPosition = eventIndex - 1\n  var startPositions = []\n  var tokenizer =\n    token._tokenizer || context.parser[token.contentType](token.start)\n  var childEvents = tokenizer.events\n  var jumps = []\n  var gaps = {}\n  var stream\n  var previous\n  var index\n  var entered\n  var end\n  var adjust // Loop forward through the linked tokens to pass them in order to the\n  // subtokenizer.\n\n  while (token) {\n    // Find the position of the event for this token.\n    while (events[++startPosition][1] !== token) {\n      // Empty.\n    }\n\n    startPositions.push(startPosition)\n\n    if (!token._tokenizer) {\n      stream = context.sliceStream(token)\n\n      if (!token.next) {\n        stream.push(null)\n      }\n\n      if (previous) {\n        tokenizer.defineSkip(token.start)\n      }\n\n      if (token.isInFirstContentOfListItem) {\n        tokenizer._gfmTasklistFirstContentOfListItem = true\n      }\n\n      tokenizer.write(stream)\n\n      if (token.isInFirstContentOfListItem) {\n        tokenizer._gfmTasklistFirstContentOfListItem = undefined\n      }\n    } // Unravel the next token.\n\n    previous = token\n    token = token.next\n  } // Now, loop back through all events (and linked tokens), to figure out which\n  // parts belong where.\n\n  token = previous\n  index = childEvents.length\n\n  while (index--) {\n    // Make sure weve at least seen something (final eol is part of the last\n    // token).\n    if (childEvents[index][0] === 'enter') {\n      entered = true\n    } else if (\n      // Find a void token that includes a break.\n      entered &&\n      childEvents[index][1].type === childEvents[index - 1][1].type &&\n      childEvents[index][1].start.line !== childEvents[index][1].end.line\n    ) {\n      add(childEvents.slice(index + 1, end))\n      // Help GC.\n      token._tokenizer = token.next = undefined\n      token = token.previous\n      end = index + 1\n    }\n  }\n\n  // Help GC.\n  tokenizer.events = token._tokenizer = token.next = undefined // Do head:\n\n  add(childEvents.slice(0, end))\n  index = -1\n  adjust = 0\n\n  while (++index < jumps.length) {\n    gaps[adjust + jumps[index][0]] = adjust + jumps[index][1]\n    adjust += jumps[index][1] - jumps[index][0] - 1\n  }\n\n  return gaps\n\n  function add(slice) {\n    var start = startPositions.pop()\n    jumps.unshift([start, start + slice.length - 1])\n    chunkedSplice(events, start, 2, slice)\n  }\n}\n\nmodule.exports = subtokenize\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nfunction _interopDefault (ex) { return (ex && (typeof ex === 'object') && 'default' in ex) ? ex['default'] : ex; }\n\nvar Stream = _interopDefault(require('stream'));\nvar http = _interopDefault(require('http'));\nvar Url = _interopDefault(require('url'));\nvar https = _interopDefault(require('https'));\nvar zlib = _interopDefault(require('zlib'));\n\n// Based on https://github.com/tmpvar/jsdom/blob/aa85b2abf07766ff7bf5c1f6daafb3726f2f2db5/lib/jsdom/living/blob.js\n\n// fix for \"Readable\" isn't a named export issue\nconst Readable = Stream.Readable;\n\nconst BUFFER = Symbol('buffer');\nconst TYPE = Symbol('type');\n\nclass Blob {\n\tconstructor() {\n\t\tthis[TYPE] = '';\n\n\t\tconst blobParts = arguments[0];\n\t\tconst options = arguments[1];\n\n\t\tconst buffers = [];\n\t\tlet size = 0;\n\n\t\tif (blobParts) {\n\t\t\tconst a = blobParts;\n\t\t\tconst length = Number(a.length);\n\t\t\tfor (let i = 0; i < length; i++) {\n\t\t\t\tconst element = a[i];\n\t\t\t\tlet buffer;\n\t\t\t\tif (element instanceof Buffer) {\n\t\t\t\t\tbuffer = element;\n\t\t\t\t} else if (ArrayBuffer.isView(element)) {\n\t\t\t\t\tbuffer = Buffer.from(element.buffer, element.byteOffset, element.byteLength);\n\t\t\t\t} else if (element instanceof ArrayBuffer) {\n\t\t\t\t\tbuffer = Buffer.from(element);\n\t\t\t\t} else if (element instanceof Blob) {\n\t\t\t\t\tbuffer = element[BUFFER];\n\t\t\t\t} else {\n\t\t\t\t\tbuffer = Buffer.from(typeof element === 'string' ? element : String(element));\n\t\t\t\t}\n\t\t\t\tsize += buffer.length;\n\t\t\t\tbuffers.push(buffer);\n\t\t\t}\n\t\t}\n\n\t\tthis[BUFFER] = Buffer.concat(buffers);\n\n\t\tlet type = options && options.type !== undefined && String(options.type).toLowerCase();\n\t\tif (type && !/[^\\u0020-\\u007E]/.test(type)) {\n\t\t\tthis[TYPE] = type;\n\t\t}\n\t}\n\tget size() {\n\t\treturn this[BUFFER].length;\n\t}\n\tget type() {\n\t\treturn this[TYPE];\n\t}\n\ttext() {\n\t\treturn Promise.resolve(this[BUFFER].toString());\n\t}\n\tarrayBuffer() {\n\t\tconst buf = this[BUFFER];\n\t\tconst ab = buf.buffer.slice(buf.byteOffset, buf.byteOffset + buf.byteLength);\n\t\treturn Promise.resolve(ab);\n\t}\n\tstream() {\n\t\tconst readable = new Readable();\n\t\treadable._read = function () {};\n\t\treadable.push(this[BUFFER]);\n\t\treadable.push(null);\n\t\treturn readable;\n\t}\n\ttoString() {\n\t\treturn '[object Blob]';\n\t}\n\tslice() {\n\t\tconst size = this.size;\n\n\t\tconst start = arguments[0];\n\t\tconst end = arguments[1];\n\t\tlet relativeStart, relativeEnd;\n\t\tif (start === undefined) {\n\t\t\trelativeStart = 0;\n\t\t} else if (start < 0) {\n\t\t\trelativeStart = Math.max(size + start, 0);\n\t\t} else {\n\t\t\trelativeStart = Math.min(start, size);\n\t\t}\n\t\tif (end === undefined) {\n\t\t\trelativeEnd = size;\n\t\t} else if (end < 0) {\n\t\t\trelativeEnd = Math.max(size + end, 0);\n\t\t} else {\n\t\t\trelativeEnd = Math.min(end, size);\n\t\t}\n\t\tconst span = Math.max(relativeEnd - relativeStart, 0);\n\n\t\tconst buffer = this[BUFFER];\n\t\tconst slicedBuffer = buffer.slice(relativeStart, relativeStart + span);\n\t\tconst blob = new Blob([], { type: arguments[2] });\n\t\tblob[BUFFER] = slicedBuffer;\n\t\treturn blob;\n\t}\n}\n\nObject.defineProperties(Blob.prototype, {\n\tsize: { enumerable: true },\n\ttype: { enumerable: true },\n\tslice: { enumerable: true }\n});\n\nObject.defineProperty(Blob.prototype, Symbol.toStringTag, {\n\tvalue: 'Blob',\n\twritable: false,\n\tenumerable: false,\n\tconfigurable: true\n});\n\n/**\n * fetch-error.js\n *\n * FetchError interface for operational errors\n */\n\n/**\n * Create FetchError instance\n *\n * @param   String      message      Error message for human\n * @param   String      type         Error type for machine\n * @param   String      systemError  For Node.js system error\n * @return  FetchError\n */\nfunction FetchError(message, type, systemError) {\n  Error.call(this, message);\n\n  this.message = message;\n  this.type = type;\n\n  // when err.type is `system`, err.code contains system error code\n  if (systemError) {\n    this.code = this.errno = systemError.code;\n  }\n\n  // hide custom error implementation details from end-users\n  Error.captureStackTrace(this, this.constructor);\n}\n\nFetchError.prototype = Object.create(Error.prototype);\nFetchError.prototype.constructor = FetchError;\nFetchError.prototype.name = 'FetchError';\n\nlet convert;\ntry {\n\tconvert = require('encoding').convert;\n} catch (e) {}\n\nconst INTERNALS = Symbol('Body internals');\n\n// fix an issue where \"PassThrough\" isn't a named export for node <10\nconst PassThrough = Stream.PassThrough;\n\n/**\n * Body mixin\n *\n * Ref: https://fetch.spec.whatwg.org/#body\n *\n * @param   Stream  body  Readable stream\n * @param   Object  opts  Response options\n * @return  Void\n */\nfunction Body(body) {\n\tvar _this = this;\n\n\tvar _ref = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {},\n\t    _ref$size = _ref.size;\n\n\tlet size = _ref$size === undefined ? 0 : _ref$size;\n\tvar _ref$timeout = _ref.timeout;\n\tlet timeout = _ref$timeout === undefined ? 0 : _ref$timeout;\n\n\tif (body == null) {\n\t\t// body is undefined or null\n\t\tbody = null;\n\t} else if (isURLSearchParams(body)) {\n\t\t// body is a URLSearchParams\n\t\tbody = Buffer.from(body.toString());\n\t} else if (isBlob(body)) ; else if (Buffer.isBuffer(body)) ; else if (Object.prototype.toString.call(body) === '[object ArrayBuffer]') {\n\t\t// body is ArrayBuffer\n\t\tbody = Buffer.from(body);\n\t} else if (ArrayBuffer.isView(body)) {\n\t\t// body is ArrayBufferView\n\t\tbody = Buffer.from(body.buffer, body.byteOffset, body.byteLength);\n\t} else if (body instanceof Stream) ; else {\n\t\t// none of the above\n\t\t// coerce to string then buffer\n\t\tbody = Buffer.from(String(body));\n\t}\n\tthis[INTERNALS] = {\n\t\tbody,\n\t\tdisturbed: false,\n\t\terror: null\n\t};\n\tthis.size = size;\n\tthis.timeout = timeout;\n\n\tif (body instanceof Stream) {\n\t\tbody.on('error', function (err) {\n\t\t\tconst error = err.name === 'AbortError' ? err : new FetchError(`Invalid response body while trying to fetch ${_this.url}: ${err.message}`, 'system', err);\n\t\t\t_this[INTERNALS].error = error;\n\t\t});\n\t}\n}\n\nBody.prototype = {\n\tget body() {\n\t\treturn this[INTERNALS].body;\n\t},\n\n\tget bodyUsed() {\n\t\treturn this[INTERNALS].disturbed;\n\t},\n\n\t/**\n  * Decode response as ArrayBuffer\n  *\n  * @return  Promise\n  */\n\tarrayBuffer() {\n\t\treturn consumeBody.call(this).then(function (buf) {\n\t\t\treturn buf.buffer.slice(buf.byteOffset, buf.byteOffset + buf.byteLength);\n\t\t});\n\t},\n\n\t/**\n  * Return raw response as Blob\n  *\n  * @return Promise\n  */\n\tblob() {\n\t\tlet ct = this.headers && this.headers.get('content-type') || '';\n\t\treturn consumeBody.call(this).then(function (buf) {\n\t\t\treturn Object.assign(\n\t\t\t// Prevent copying\n\t\t\tnew Blob([], {\n\t\t\t\ttype: ct.toLowerCase()\n\t\t\t}), {\n\t\t\t\t[BUFFER]: buf\n\t\t\t});\n\t\t});\n\t},\n\n\t/**\n  * Decode response as json\n  *\n  * @return  Promise\n  */\n\tjson() {\n\t\tvar _this2 = this;\n\n\t\treturn consumeBody.call(this).then(function (buffer) {\n\t\t\ttry {\n\t\t\t\treturn JSON.parse(buffer.toString());\n\t\t\t} catch (err) {\n\t\t\t\treturn Body.Promise.reject(new FetchError(`invalid json response body at ${_this2.url} reason: ${err.message}`, 'invalid-json'));\n\t\t\t}\n\t\t});\n\t},\n\n\t/**\n  * Decode response as text\n  *\n  * @return  Promise\n  */\n\ttext() {\n\t\treturn consumeBody.call(this).then(function (buffer) {\n\t\t\treturn buffer.toString();\n\t\t});\n\t},\n\n\t/**\n  * Decode response as buffer (non-spec api)\n  *\n  * @return  Promise\n  */\n\tbuffer() {\n\t\treturn consumeBody.call(this);\n\t},\n\n\t/**\n  * Decode response as text, while automatically detecting the encoding and\n  * trying to decode to UTF-8 (non-spec api)\n  *\n  * @return  Promise\n  */\n\ttextConverted() {\n\t\tvar _this3 = this;\n\n\t\treturn consumeBody.call(this).then(function (buffer) {\n\t\t\treturn convertBody(buffer, _this3.headers);\n\t\t});\n\t}\n};\n\n// In browsers, all properties are enumerable.\nObject.defineProperties(Body.prototype, {\n\tbody: { enumerable: true },\n\tbodyUsed: { enumerable: true },\n\tarrayBuffer: { enumerable: true },\n\tblob: { enumerable: true },\n\tjson: { enumerable: true },\n\ttext: { enumerable: true }\n});\n\nBody.mixIn = function (proto) {\n\tfor (const name of Object.getOwnPropertyNames(Body.prototype)) {\n\t\t// istanbul ignore else: future proof\n\t\tif (!(name in proto)) {\n\t\t\tconst desc = Object.getOwnPropertyDescriptor(Body.prototype, name);\n\t\t\tObject.defineProperty(proto, name, desc);\n\t\t}\n\t}\n};\n\n/**\n * Consume and convert an entire Body to a Buffer.\n *\n * Ref: https://fetch.spec.whatwg.org/#concept-body-consume-body\n *\n * @return  Promise\n */\nfunction consumeBody() {\n\tvar _this4 = this;\n\n\tif (this[INTERNALS].disturbed) {\n\t\treturn Body.Promise.reject(new TypeError(`body used already for: ${this.url}`));\n\t}\n\n\tthis[INTERNALS].disturbed = true;\n\n\tif (this[INTERNALS].error) {\n\t\treturn Body.Promise.reject(this[INTERNALS].error);\n\t}\n\n\tlet body = this.body;\n\n\t// body is null\n\tif (body === null) {\n\t\treturn Body.Promise.resolve(Buffer.alloc(0));\n\t}\n\n\t// body is blob\n\tif (isBlob(body)) {\n\t\tbody = body.stream();\n\t}\n\n\t// body is buffer\n\tif (Buffer.isBuffer(body)) {\n\t\treturn Body.Promise.resolve(body);\n\t}\n\n\t// istanbul ignore if: should never happen\n\tif (!(body instanceof Stream)) {\n\t\treturn Body.Promise.resolve(Buffer.alloc(0));\n\t}\n\n\t// body is stream\n\t// get ready to actually consume the body\n\tlet accum = [];\n\tlet accumBytes = 0;\n\tlet abort = false;\n\n\treturn new Body.Promise(function (resolve, reject) {\n\t\tlet resTimeout;\n\n\t\t// allow timeout on slow response body\n\t\tif (_this4.timeout) {\n\t\t\tresTimeout = setTimeout(function () {\n\t\t\t\tabort = true;\n\t\t\t\treject(new FetchError(`Response timeout while trying to fetch ${_this4.url} (over ${_this4.timeout}ms)`, 'body-timeout'));\n\t\t\t}, _this4.timeout);\n\t\t}\n\n\t\t// handle stream errors\n\t\tbody.on('error', function (err) {\n\t\t\tif (err.name === 'AbortError') {\n\t\t\t\t// if the request was aborted, reject with this Error\n\t\t\t\tabort = true;\n\t\t\t\treject(err);\n\t\t\t} else {\n\t\t\t\t// other errors, such as incorrect content-encoding\n\t\t\t\treject(new FetchError(`Invalid response body while trying to fetch ${_this4.url}: ${err.message}`, 'system', err));\n\t\t\t}\n\t\t});\n\n\t\tbody.on('data', function (chunk) {\n\t\t\tif (abort || chunk === null) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tif (_this4.size && accumBytes + chunk.length > _this4.size) {\n\t\t\t\tabort = true;\n\t\t\t\treject(new FetchError(`content size at ${_this4.url} over limit: ${_this4.size}`, 'max-size'));\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\taccumBytes += chunk.length;\n\t\t\taccum.push(chunk);\n\t\t});\n\n\t\tbody.on('end', function () {\n\t\t\tif (abort) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tclearTimeout(resTimeout);\n\n\t\t\ttry {\n\t\t\t\tresolve(Buffer.concat(accum, accumBytes));\n\t\t\t} catch (err) {\n\t\t\t\t// handle streams that have accumulated too much data (issue #414)\n\t\t\t\treject(new FetchError(`Could not create Buffer from response body for ${_this4.url}: ${err.message}`, 'system', err));\n\t\t\t}\n\t\t});\n\t});\n}\n\n/**\n * Detect buffer encoding and convert to target encoding\n * ref: http://www.w3.org/TR/2011/WD-html5-20110113/parsing.html#determining-the-character-encoding\n *\n * @param   Buffer  buffer    Incoming buffer\n * @param   String  encoding  Target encoding\n * @return  String\n */\nfunction convertBody(buffer, headers) {\n\tif (typeof convert !== 'function') {\n\t\tthrow new Error('The package `encoding` must be installed to use the textConverted() function');\n\t}\n\n\tconst ct = headers.get('content-type');\n\tlet charset = 'utf-8';\n\tlet res, str;\n\n\t// header\n\tif (ct) {\n\t\tres = /charset=([^;]*)/i.exec(ct);\n\t}\n\n\t// no charset in content type, peek at response body for at most 1024 bytes\n\tstr = buffer.slice(0, 1024).toString();\n\n\t// html5\n\tif (!res && str) {\n\t\tres = /<meta.+?charset=(['\"])(.+?)\\1/i.exec(str);\n\t}\n\n\t// html4\n\tif (!res && str) {\n\t\tres = /<meta[\\s]+?http-equiv=(['\"])content-type\\1[\\s]+?content=(['\"])(.+?)\\2/i.exec(str);\n\t\tif (!res) {\n\t\t\tres = /<meta[\\s]+?content=(['\"])(.+?)\\1[\\s]+?http-equiv=(['\"])content-type\\3/i.exec(str);\n\t\t\tif (res) {\n\t\t\t\tres.pop(); // drop last quote\n\t\t\t}\n\t\t}\n\n\t\tif (res) {\n\t\t\tres = /charset=(.*)/i.exec(res.pop());\n\t\t}\n\t}\n\n\t// xml\n\tif (!res && str) {\n\t\tres = /<\\?xml.+?encoding=(['\"])(.+?)\\1/i.exec(str);\n\t}\n\n\t// found charset\n\tif (res) {\n\t\tcharset = res.pop();\n\n\t\t// prevent decode issues when sites use incorrect encoding\n\t\t// ref: https://hsivonen.fi/encoding-menu/\n\t\tif (charset === 'gb2312' || charset === 'gbk') {\n\t\t\tcharset = 'gb18030';\n\t\t}\n\t}\n\n\t// turn raw buffers into a single utf-8 buffer\n\treturn convert(buffer, 'UTF-8', charset).toString();\n}\n\n/**\n * Detect a URLSearchParams object\n * ref: https://github.com/bitinn/node-fetch/issues/296#issuecomment-307598143\n *\n * @param   Object  obj     Object to detect by type or brand\n * @return  String\n */\nfunction isURLSearchParams(obj) {\n\t// Duck-typing as a necessary condition.\n\tif (typeof obj !== 'object' || typeof obj.append !== 'function' || typeof obj.delete !== 'function' || typeof obj.get !== 'function' || typeof obj.getAll !== 'function' || typeof obj.has !== 'function' || typeof obj.set !== 'function') {\n\t\treturn false;\n\t}\n\n\t// Brand-checking and more duck-typing as optional condition.\n\treturn obj.constructor.name === 'URLSearchParams' || Object.prototype.toString.call(obj) === '[object URLSearchParams]' || typeof obj.sort === 'function';\n}\n\n/**\n * Check if `obj` is a W3C `Blob` object (which `File` inherits from)\n * @param  {*} obj\n * @return {boolean}\n */\nfunction isBlob(obj) {\n\treturn typeof obj === 'object' && typeof obj.arrayBuffer === 'function' && typeof obj.type === 'string' && typeof obj.stream === 'function' && typeof obj.constructor === 'function' && typeof obj.constructor.name === 'string' && /^(Blob|File)$/.test(obj.constructor.name) && /^(Blob|File)$/.test(obj[Symbol.toStringTag]);\n}\n\n/**\n * Clone body given Res/Req instance\n *\n * @param   Mixed  instance  Response or Request instance\n * @return  Mixed\n */\nfunction clone(instance) {\n\tlet p1, p2;\n\tlet body = instance.body;\n\n\t// don't allow cloning a used body\n\tif (instance.bodyUsed) {\n\t\tthrow new Error('cannot clone body after it is used');\n\t}\n\n\t// check that body is a stream and not form-data object\n\t// note: we can't clone the form-data object without having it as a dependency\n\tif (body instanceof Stream && typeof body.getBoundary !== 'function') {\n\t\t// tee instance body\n\t\tp1 = new PassThrough();\n\t\tp2 = new PassThrough();\n\t\tbody.pipe(p1);\n\t\tbody.pipe(p2);\n\t\t// set instance body to teed body and return the other teed body\n\t\tinstance[INTERNALS].body = p1;\n\t\tbody = p2;\n\t}\n\n\treturn body;\n}\n\n/**\n * Performs the operation \"extract a `Content-Type` value from |object|\" as\n * specified in the specification:\n * https://fetch.spec.whatwg.org/#concept-bodyinit-extract\n *\n * This function assumes that instance.body is present.\n *\n * @param   Mixed  instance  Any options.body input\n */\nfunction extractContentType(body) {\n\tif (body === null) {\n\t\t// body is null\n\t\treturn null;\n\t} else if (typeof body === 'string') {\n\t\t// body is string\n\t\treturn 'text/plain;charset=UTF-8';\n\t} else if (isURLSearchParams(body)) {\n\t\t// body is a URLSearchParams\n\t\treturn 'application/x-www-form-urlencoded;charset=UTF-8';\n\t} else if (isBlob(body)) {\n\t\t// body is blob\n\t\treturn body.type || null;\n\t} else if (Buffer.isBuffer(body)) {\n\t\t// body is buffer\n\t\treturn null;\n\t} else if (Object.prototype.toString.call(body) === '[object ArrayBuffer]') {\n\t\t// body is ArrayBuffer\n\t\treturn null;\n\t} else if (ArrayBuffer.isView(body)) {\n\t\t// body is ArrayBufferView\n\t\treturn null;\n\t} else if (typeof body.getBoundary === 'function') {\n\t\t// detect form data input from form-data module\n\t\treturn `multipart/form-data;boundary=${body.getBoundary()}`;\n\t} else if (body instanceof Stream) {\n\t\t// body is stream\n\t\t// can't really do much about this\n\t\treturn null;\n\t} else {\n\t\t// Body constructor defaults other things to string\n\t\treturn 'text/plain;charset=UTF-8';\n\t}\n}\n\n/**\n * The Fetch Standard treats this as if \"total bytes\" is a property on the body.\n * For us, we have to explicitly get it with a function.\n *\n * ref: https://fetch.spec.whatwg.org/#concept-body-total-bytes\n *\n * @param   Body    instance   Instance of Body\n * @return  Number?            Number of bytes, or null if not possible\n */\nfunction getTotalBytes(instance) {\n\tconst body = instance.body;\n\n\n\tif (body === null) {\n\t\t// body is null\n\t\treturn 0;\n\t} else if (isBlob(body)) {\n\t\treturn body.size;\n\t} else if (Buffer.isBuffer(body)) {\n\t\t// body is buffer\n\t\treturn body.length;\n\t} else if (body && typeof body.getLengthSync === 'function') {\n\t\t// detect form data input from form-data module\n\t\tif (body._lengthRetrievers && body._lengthRetrievers.length == 0 || // 1.x\n\t\tbody.hasKnownLength && body.hasKnownLength()) {\n\t\t\t// 2.x\n\t\t\treturn body.getLengthSync();\n\t\t}\n\t\treturn null;\n\t} else {\n\t\t// body is stream\n\t\treturn null;\n\t}\n}\n\n/**\n * Write a Body to a Node.js WritableStream (e.g. http.Request) object.\n *\n * @param   Body    instance   Instance of Body\n * @return  Void\n */\nfunction writeToStream(dest, instance) {\n\tconst body = instance.body;\n\n\n\tif (body === null) {\n\t\t// body is null\n\t\tdest.end();\n\t} else if (isBlob(body)) {\n\t\tbody.stream().pipe(dest);\n\t} else if (Buffer.isBuffer(body)) {\n\t\t// body is buffer\n\t\tdest.write(body);\n\t\tdest.end();\n\t} else {\n\t\t// body is stream\n\t\tbody.pipe(dest);\n\t}\n}\n\n// expose Promise\nBody.Promise = global.Promise;\n\n/**\n * headers.js\n *\n * Headers class offers convenient helpers\n */\n\nconst invalidTokenRegex = /[^\\^_`a-zA-Z\\-0-9!#$%&'*+.|~]/;\nconst invalidHeaderCharRegex = /[^\\t\\x20-\\x7e\\x80-\\xff]/;\n\nfunction validateName(name) {\n\tname = `${name}`;\n\tif (invalidTokenRegex.test(name) || name === '') {\n\t\tthrow new TypeError(`${name} is not a legal HTTP header name`);\n\t}\n}\n\nfunction validateValue(value) {\n\tvalue = `${value}`;\n\tif (invalidHeaderCharRegex.test(value)) {\n\t\tthrow new TypeError(`${value} is not a legal HTTP header value`);\n\t}\n}\n\n/**\n * Find the key in the map object given a header name.\n *\n * Returns undefined if not found.\n *\n * @param   String  name  Header name\n * @return  String|Undefined\n */\nfunction find(map, name) {\n\tname = name.toLowerCase();\n\tfor (const key in map) {\n\t\tif (key.toLowerCase() === name) {\n\t\t\treturn key;\n\t\t}\n\t}\n\treturn undefined;\n}\n\nconst MAP = Symbol('map');\nclass Headers {\n\t/**\n  * Headers class\n  *\n  * @param   Object  headers  Response headers\n  * @return  Void\n  */\n\tconstructor() {\n\t\tlet init = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : undefined;\n\n\t\tthis[MAP] = Object.create(null);\n\n\t\tif (init instanceof Headers) {\n\t\t\tconst rawHeaders = init.raw();\n\t\t\tconst headerNames = Object.keys(rawHeaders);\n\n\t\t\tfor (const headerName of headerNames) {\n\t\t\t\tfor (const value of rawHeaders[headerName]) {\n\t\t\t\t\tthis.append(headerName, value);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\treturn;\n\t\t}\n\n\t\t// We don't worry about converting prop to ByteString here as append()\n\t\t// will handle it.\n\t\tif (init == null) ; else if (typeof init === 'object') {\n\t\t\tconst method = init[Symbol.iterator];\n\t\t\tif (method != null) {\n\t\t\t\tif (typeof method !== 'function') {\n\t\t\t\t\tthrow new TypeError('Header pairs must be iterable');\n\t\t\t\t}\n\n\t\t\t\t// sequence<sequence<ByteString>>\n\t\t\t\t// Note: per spec we have to first exhaust the lists then process them\n\t\t\t\tconst pairs = [];\n\t\t\t\tfor (const pair of init) {\n\t\t\t\t\tif (typeof pair !== 'object' || typeof pair[Symbol.iterator] !== 'function') {\n\t\t\t\t\t\tthrow new TypeError('Each header pair must be iterable');\n\t\t\t\t\t}\n\t\t\t\t\tpairs.push(Array.from(pair));\n\t\t\t\t}\n\n\t\t\t\tfor (const pair of pairs) {\n\t\t\t\t\tif (pair.length !== 2) {\n\t\t\t\t\t\tthrow new TypeError('Each header pair must be a name/value tuple');\n\t\t\t\t\t}\n\t\t\t\t\tthis.append(pair[0], pair[1]);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\t// record<ByteString, ByteString>\n\t\t\t\tfor (const key of Object.keys(init)) {\n\t\t\t\t\tconst value = init[key];\n\t\t\t\t\tthis.append(key, value);\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\tthrow new TypeError('Provided initializer must be an object');\n\t\t}\n\t}\n\n\t/**\n  * Return combined header value given name\n  *\n  * @param   String  name  Header name\n  * @return  Mixed\n  */\n\tget(name) {\n\t\tname = `${name}`;\n\t\tvalidateName(name);\n\t\tconst key = find(this[MAP], name);\n\t\tif (key === undefined) {\n\t\t\treturn null;\n\t\t}\n\n\t\treturn this[MAP][key].join(', ');\n\t}\n\n\t/**\n  * Iterate over all headers\n  *\n  * @param   Function  callback  Executed for each item with parameters (value, name, thisArg)\n  * @param   Boolean   thisArg   `this` context for callback function\n  * @return  Void\n  */\n\tforEach(callback) {\n\t\tlet thisArg = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : undefined;\n\n\t\tlet pairs = getHeaders(this);\n\t\tlet i = 0;\n\t\twhile (i < pairs.length) {\n\t\t\tvar _pairs$i = pairs[i];\n\t\t\tconst name = _pairs$i[0],\n\t\t\t      value = _pairs$i[1];\n\n\t\t\tcallback.call(thisArg, value, name, this);\n\t\t\tpairs = getHeaders(this);\n\t\t\ti++;\n\t\t}\n\t}\n\n\t/**\n  * Overwrite header values given name\n  *\n  * @param   String  name   Header name\n  * @param   String  value  Header value\n  * @return  Void\n  */\n\tset(name, value) {\n\t\tname = `${name}`;\n\t\tvalue = `${value}`;\n\t\tvalidateName(name);\n\t\tvalidateValue(value);\n\t\tconst key = find(this[MAP], name);\n\t\tthis[MAP][key !== undefined ? key : name] = [value];\n\t}\n\n\t/**\n  * Append a value onto existing header\n  *\n  * @param   String  name   Header name\n  * @param   String  value  Header value\n  * @return  Void\n  */\n\tappend(name, value) {\n\t\tname = `${name}`;\n\t\tvalue = `${value}`;\n\t\tvalidateName(name);\n\t\tvalidateValue(value);\n\t\tconst key = find(this[MAP], name);\n\t\tif (key !== undefined) {\n\t\t\tthis[MAP][key].push(value);\n\t\t} else {\n\t\t\tthis[MAP][name] = [value];\n\t\t}\n\t}\n\n\t/**\n  * Check for header name existence\n  *\n  * @param   String   name  Header name\n  * @return  Boolean\n  */\n\thas(name) {\n\t\tname = `${name}`;\n\t\tvalidateName(name);\n\t\treturn find(this[MAP], name) !== undefined;\n\t}\n\n\t/**\n  * Delete all header values given name\n  *\n  * @param   String  name  Header name\n  * @return  Void\n  */\n\tdelete(name) {\n\t\tname = `${name}`;\n\t\tvalidateName(name);\n\t\tconst key = find(this[MAP], name);\n\t\tif (key !== undefined) {\n\t\t\tdelete this[MAP][key];\n\t\t}\n\t}\n\n\t/**\n  * Return raw headers (non-spec api)\n  *\n  * @return  Object\n  */\n\traw() {\n\t\treturn this[MAP];\n\t}\n\n\t/**\n  * Get an iterator on keys.\n  *\n  * @return  Iterator\n  */\n\tkeys() {\n\t\treturn createHeadersIterator(this, 'key');\n\t}\n\n\t/**\n  * Get an iterator on values.\n  *\n  * @return  Iterator\n  */\n\tvalues() {\n\t\treturn createHeadersIterator(this, 'value');\n\t}\n\n\t/**\n  * Get an iterator on entries.\n  *\n  * This is the default iterator of the Headers object.\n  *\n  * @return  Iterator\n  */\n\t[Symbol.iterator]() {\n\t\treturn createHeadersIterator(this, 'key+value');\n\t}\n}\nHeaders.prototype.entries = Headers.prototype[Symbol.iterator];\n\nObject.defineProperty(Headers.prototype, Symbol.toStringTag, {\n\tvalue: 'Headers',\n\twritable: false,\n\tenumerable: false,\n\tconfigurable: true\n});\n\nObject.defineProperties(Headers.prototype, {\n\tget: { enumerable: true },\n\tforEach: { enumerable: true },\n\tset: { enumerable: true },\n\tappend: { enumerable: true },\n\thas: { enumerable: true },\n\tdelete: { enumerable: true },\n\tkeys: { enumerable: true },\n\tvalues: { enumerable: true },\n\tentries: { enumerable: true }\n});\n\nfunction getHeaders(headers) {\n\tlet kind = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 'key+value';\n\n\tconst keys = Object.keys(headers[MAP]).sort();\n\treturn keys.map(kind === 'key' ? function (k) {\n\t\treturn k.toLowerCase();\n\t} : kind === 'value' ? function (k) {\n\t\treturn headers[MAP][k].join(', ');\n\t} : function (k) {\n\t\treturn [k.toLowerCase(), headers[MAP][k].join(', ')];\n\t});\n}\n\nconst INTERNAL = Symbol('internal');\n\nfunction createHeadersIterator(target, kind) {\n\tconst iterator = Object.create(HeadersIteratorPrototype);\n\titerator[INTERNAL] = {\n\t\ttarget,\n\t\tkind,\n\t\tindex: 0\n\t};\n\treturn iterator;\n}\n\nconst HeadersIteratorPrototype = Object.setPrototypeOf({\n\tnext() {\n\t\t// istanbul ignore if\n\t\tif (!this || Object.getPrototypeOf(this) !== HeadersIteratorPrototype) {\n\t\t\tthrow new TypeError('Value of `this` is not a HeadersIterator');\n\t\t}\n\n\t\tvar _INTERNAL = this[INTERNAL];\n\t\tconst target = _INTERNAL.target,\n\t\t      kind = _INTERNAL.kind,\n\t\t      index = _INTERNAL.index;\n\n\t\tconst values = getHeaders(target, kind);\n\t\tconst len = values.length;\n\t\tif (index >= len) {\n\t\t\treturn {\n\t\t\t\tvalue: undefined,\n\t\t\t\tdone: true\n\t\t\t};\n\t\t}\n\n\t\tthis[INTERNAL].index = index + 1;\n\n\t\treturn {\n\t\t\tvalue: values[index],\n\t\t\tdone: false\n\t\t};\n\t}\n}, Object.getPrototypeOf(Object.getPrototypeOf([][Symbol.iterator]())));\n\nObject.defineProperty(HeadersIteratorPrototype, Symbol.toStringTag, {\n\tvalue: 'HeadersIterator',\n\twritable: false,\n\tenumerable: false,\n\tconfigurable: true\n});\n\n/**\n * Export the Headers object in a form that Node.js can consume.\n *\n * @param   Headers  headers\n * @return  Object\n */\nfunction exportNodeCompatibleHeaders(headers) {\n\tconst obj = Object.assign({ __proto__: null }, headers[MAP]);\n\n\t// http.request() only supports string as Host header. This hack makes\n\t// specifying custom Host header possible.\n\tconst hostHeaderKey = find(headers[MAP], 'Host');\n\tif (hostHeaderKey !== undefined) {\n\t\tobj[hostHeaderKey] = obj[hostHeaderKey][0];\n\t}\n\n\treturn obj;\n}\n\n/**\n * Create a Headers object from an object of headers, ignoring those that do\n * not conform to HTTP grammar productions.\n *\n * @param   Object  obj  Object of headers\n * @return  Headers\n */\nfunction createHeadersLenient(obj) {\n\tconst headers = new Headers();\n\tfor (const name of Object.keys(obj)) {\n\t\tif (invalidTokenRegex.test(name)) {\n\t\t\tcontinue;\n\t\t}\n\t\tif (Array.isArray(obj[name])) {\n\t\t\tfor (const val of obj[name]) {\n\t\t\t\tif (invalidHeaderCharRegex.test(val)) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tif (headers[MAP][name] === undefined) {\n\t\t\t\t\theaders[MAP][name] = [val];\n\t\t\t\t} else {\n\t\t\t\t\theaders[MAP][name].push(val);\n\t\t\t\t}\n\t\t\t}\n\t\t} else if (!invalidHeaderCharRegex.test(obj[name])) {\n\t\t\theaders[MAP][name] = [obj[name]];\n\t\t}\n\t}\n\treturn headers;\n}\n\nconst INTERNALS$1 = Symbol('Response internals');\n\n// fix an issue where \"STATUS_CODES\" aren't a named export for node <10\nconst STATUS_CODES = http.STATUS_CODES;\n\n/**\n * Response class\n *\n * @param   Stream  body  Readable stream\n * @param   Object  opts  Response options\n * @return  Void\n */\nclass Response {\n\tconstructor() {\n\t\tlet body = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : null;\n\t\tlet opts = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n\n\t\tBody.call(this, body, opts);\n\n\t\tconst status = opts.status || 200;\n\t\tconst headers = new Headers(opts.headers);\n\n\t\tif (body != null && !headers.has('Content-Type')) {\n\t\t\tconst contentType = extractContentType(body);\n\t\t\tif (contentType) {\n\t\t\t\theaders.append('Content-Type', contentType);\n\t\t\t}\n\t\t}\n\n\t\tthis[INTERNALS$1] = {\n\t\t\turl: opts.url,\n\t\t\tstatus,\n\t\t\tstatusText: opts.statusText || STATUS_CODES[status],\n\t\t\theaders,\n\t\t\tcounter: opts.counter\n\t\t};\n\t}\n\n\tget url() {\n\t\treturn this[INTERNALS$1].url || '';\n\t}\n\n\tget status() {\n\t\treturn this[INTERNALS$1].status;\n\t}\n\n\t/**\n  * Convenience property representing if the request ended normally\n  */\n\tget ok() {\n\t\treturn this[INTERNALS$1].status >= 200 && this[INTERNALS$1].status < 300;\n\t}\n\n\tget redirected() {\n\t\treturn this[INTERNALS$1].counter > 0;\n\t}\n\n\tget statusText() {\n\t\treturn this[INTERNALS$1].statusText;\n\t}\n\n\tget headers() {\n\t\treturn this[INTERNALS$1].headers;\n\t}\n\n\t/**\n  * Clone this response\n  *\n  * @return  Response\n  */\n\tclone() {\n\t\treturn new Response(clone(this), {\n\t\t\turl: this.url,\n\t\t\tstatus: this.status,\n\t\t\tstatusText: this.statusText,\n\t\t\theaders: this.headers,\n\t\t\tok: this.ok,\n\t\t\tredirected: this.redirected\n\t\t});\n\t}\n}\n\nBody.mixIn(Response.prototype);\n\nObject.defineProperties(Response.prototype, {\n\turl: { enumerable: true },\n\tstatus: { enumerable: true },\n\tok: { enumerable: true },\n\tredirected: { enumerable: true },\n\tstatusText: { enumerable: true },\n\theaders: { enumerable: true },\n\tclone: { enumerable: true }\n});\n\nObject.defineProperty(Response.prototype, Symbol.toStringTag, {\n\tvalue: 'Response',\n\twritable: false,\n\tenumerable: false,\n\tconfigurable: true\n});\n\nconst INTERNALS$2 = Symbol('Request internals');\n\n// fix an issue where \"format\", \"parse\" aren't a named export for node <10\nconst parse_url = Url.parse;\nconst format_url = Url.format;\n\nconst streamDestructionSupported = 'destroy' in Stream.Readable.prototype;\n\n/**\n * Check if a value is an instance of Request.\n *\n * @param   Mixed   input\n * @return  Boolean\n */\nfunction isRequest(input) {\n\treturn typeof input === 'object' && typeof input[INTERNALS$2] === 'object';\n}\n\nfunction isAbortSignal(signal) {\n\tconst proto = signal && typeof signal === 'object' && Object.getPrototypeOf(signal);\n\treturn !!(proto && proto.constructor.name === 'AbortSignal');\n}\n\n/**\n * Request class\n *\n * @param   Mixed   input  Url or Request instance\n * @param   Object  init   Custom options\n * @return  Void\n */\nclass Request {\n\tconstructor(input) {\n\t\tlet init = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n\n\t\tlet parsedURL;\n\n\t\t// normalize input\n\t\tif (!isRequest(input)) {\n\t\t\tif (input && input.href) {\n\t\t\t\t// in order to support Node.js' Url objects; though WHATWG's URL objects\n\t\t\t\t// will fall into this branch also (since their `toString()` will return\n\t\t\t\t// `href` property anyway)\n\t\t\t\tparsedURL = parse_url(input.href);\n\t\t\t} else {\n\t\t\t\t// coerce input to a string before attempting to parse\n\t\t\t\tparsedURL = parse_url(`${input}`);\n\t\t\t}\n\t\t\tinput = {};\n\t\t} else {\n\t\t\tparsedURL = parse_url(input.url);\n\t\t}\n\n\t\tlet method = init.method || input.method || 'GET';\n\t\tmethod = method.toUpperCase();\n\n\t\tif ((init.body != null || isRequest(input) && input.body !== null) && (method === 'GET' || method === 'HEAD')) {\n\t\t\tthrow new TypeError('Request with GET/HEAD method cannot have body');\n\t\t}\n\n\t\tlet inputBody = init.body != null ? init.body : isRequest(input) && input.body !== null ? clone(input) : null;\n\n\t\tBody.call(this, inputBody, {\n\t\t\ttimeout: init.timeout || input.timeout || 0,\n\t\t\tsize: init.size || input.size || 0\n\t\t});\n\n\t\tconst headers = new Headers(init.headers || input.headers || {});\n\n\t\tif (inputBody != null && !headers.has('Content-Type')) {\n\t\t\tconst contentType = extractContentType(inputBody);\n\t\t\tif (contentType) {\n\t\t\t\theaders.append('Content-Type', contentType);\n\t\t\t}\n\t\t}\n\n\t\tlet signal = isRequest(input) ? input.signal : null;\n\t\tif ('signal' in init) signal = init.signal;\n\n\t\tif (signal != null && !isAbortSignal(signal)) {\n\t\t\tthrow new TypeError('Expected signal to be an instanceof AbortSignal');\n\t\t}\n\n\t\tthis[INTERNALS$2] = {\n\t\t\tmethod,\n\t\t\tredirect: init.redirect || input.redirect || 'follow',\n\t\t\theaders,\n\t\t\tparsedURL,\n\t\t\tsignal\n\t\t};\n\n\t\t// node-fetch-only options\n\t\tthis.follow = init.follow !== undefined ? init.follow : input.follow !== undefined ? input.follow : 20;\n\t\tthis.compress = init.compress !== undefined ? init.compress : input.compress !== undefined ? input.compress : true;\n\t\tthis.counter = init.counter || input.counter || 0;\n\t\tthis.agent = init.agent || input.agent;\n\t}\n\n\tget method() {\n\t\treturn this[INTERNALS$2].method;\n\t}\n\n\tget url() {\n\t\treturn format_url(this[INTERNALS$2].parsedURL);\n\t}\n\n\tget headers() {\n\t\treturn this[INTERNALS$2].headers;\n\t}\n\n\tget redirect() {\n\t\treturn this[INTERNALS$2].redirect;\n\t}\n\n\tget signal() {\n\t\treturn this[INTERNALS$2].signal;\n\t}\n\n\t/**\n  * Clone this request\n  *\n  * @return  Request\n  */\n\tclone() {\n\t\treturn new Request(this);\n\t}\n}\n\nBody.mixIn(Request.prototype);\n\nObject.defineProperty(Request.prototype, Symbol.toStringTag, {\n\tvalue: 'Request',\n\twritable: false,\n\tenumerable: false,\n\tconfigurable: true\n});\n\nObject.defineProperties(Request.prototype, {\n\tmethod: { enumerable: true },\n\turl: { enumerable: true },\n\theaders: { enumerable: true },\n\tredirect: { enumerable: true },\n\tclone: { enumerable: true },\n\tsignal: { enumerable: true }\n});\n\n/**\n * Convert a Request to Node.js http request options.\n *\n * @param   Request  A Request instance\n * @return  Object   The options object to be passed to http.request\n */\nfunction getNodeRequestOptions(request) {\n\tconst parsedURL = request[INTERNALS$2].parsedURL;\n\tconst headers = new Headers(request[INTERNALS$2].headers);\n\n\t// fetch step 1.3\n\tif (!headers.has('Accept')) {\n\t\theaders.set('Accept', '*/*');\n\t}\n\n\t// Basic fetch\n\tif (!parsedURL.protocol || !parsedURL.hostname) {\n\t\tthrow new TypeError('Only absolute URLs are supported');\n\t}\n\n\tif (!/^https?:$/.test(parsedURL.protocol)) {\n\t\tthrow new TypeError('Only HTTP(S) protocols are supported');\n\t}\n\n\tif (request.signal && request.body instanceof Stream.Readable && !streamDestructionSupported) {\n\t\tthrow new Error('Cancellation of streamed requests with AbortSignal is not supported in node < 8');\n\t}\n\n\t// HTTP-network-or-cache fetch steps 2.4-2.7\n\tlet contentLengthValue = null;\n\tif (request.body == null && /^(POST|PUT)$/i.test(request.method)) {\n\t\tcontentLengthValue = '0';\n\t}\n\tif (request.body != null) {\n\t\tconst totalBytes = getTotalBytes(request);\n\t\tif (typeof totalBytes === 'number') {\n\t\t\tcontentLengthValue = String(totalBytes);\n\t\t}\n\t}\n\tif (contentLengthValue) {\n\t\theaders.set('Content-Length', contentLengthValue);\n\t}\n\n\t// HTTP-network-or-cache fetch step 2.11\n\tif (!headers.has('User-Agent')) {\n\t\theaders.set('User-Agent', 'node-fetch/1.0 (+https://github.com/bitinn/node-fetch)');\n\t}\n\n\t// HTTP-network-or-cache fetch step 2.15\n\tif (request.compress && !headers.has('Accept-Encoding')) {\n\t\theaders.set('Accept-Encoding', 'gzip,deflate');\n\t}\n\n\tlet agent = request.agent;\n\tif (typeof agent === 'function') {\n\t\tagent = agent(parsedURL);\n\t}\n\n\tif (!headers.has('Connection') && !agent) {\n\t\theaders.set('Connection', 'close');\n\t}\n\n\t// HTTP-network fetch step 4.2\n\t// chunked encoding is handled by Node.js\n\n\treturn Object.assign({}, parsedURL, {\n\t\tmethod: request.method,\n\t\theaders: exportNodeCompatibleHeaders(headers),\n\t\tagent\n\t});\n}\n\n/**\n * abort-error.js\n *\n * AbortError interface for cancelled requests\n */\n\n/**\n * Create AbortError instance\n *\n * @param   String      message      Error message for human\n * @return  AbortError\n */\nfunction AbortError(message) {\n  Error.call(this, message);\n\n  this.type = 'aborted';\n  this.message = message;\n\n  // hide custom error implementation details from end-users\n  Error.captureStackTrace(this, this.constructor);\n}\n\nAbortError.prototype = Object.create(Error.prototype);\nAbortError.prototype.constructor = AbortError;\nAbortError.prototype.name = 'AbortError';\n\n// fix an issue where \"PassThrough\", \"resolve\" aren't a named export for node <10\nconst PassThrough$1 = Stream.PassThrough;\nconst resolve_url = Url.resolve;\n\n/**\n * Fetch function\n *\n * @param   Mixed    url   Absolute url or Request instance\n * @param   Object   opts  Fetch options\n * @return  Promise\n */\nfunction fetch(url, opts) {\n\n\t// allow custom promise\n\tif (!fetch.Promise) {\n\t\tthrow new Error('native promise missing, set fetch.Promise to your favorite alternative');\n\t}\n\n\tBody.Promise = fetch.Promise;\n\n\t// wrap http.request into fetch\n\treturn new fetch.Promise(function (resolve, reject) {\n\t\t// build request object\n\t\tconst request = new Request(url, opts);\n\t\tconst options = getNodeRequestOptions(request);\n\n\t\tconst send = (options.protocol === 'https:' ? https : http).request;\n\t\tconst signal = request.signal;\n\n\t\tlet response = null;\n\n\t\tconst abort = function abort() {\n\t\t\tlet error = new AbortError('The user aborted a request.');\n\t\t\treject(error);\n\t\t\tif (request.body && request.body instanceof Stream.Readable) {\n\t\t\t\trequest.body.destroy(error);\n\t\t\t}\n\t\t\tif (!response || !response.body) return;\n\t\t\tresponse.body.emit('error', error);\n\t\t};\n\n\t\tif (signal && signal.aborted) {\n\t\t\tabort();\n\t\t\treturn;\n\t\t}\n\n\t\tconst abortAndFinalize = function abortAndFinalize() {\n\t\t\tabort();\n\t\t\tfinalize();\n\t\t};\n\n\t\t// send request\n\t\tconst req = send(options);\n\t\tlet reqTimeout;\n\n\t\tif (signal) {\n\t\t\tsignal.addEventListener('abort', abortAndFinalize);\n\t\t}\n\n\t\tfunction finalize() {\n\t\t\treq.abort();\n\t\t\tif (signal) signal.removeEventListener('abort', abortAndFinalize);\n\t\t\tclearTimeout(reqTimeout);\n\t\t}\n\n\t\tif (request.timeout) {\n\t\t\treq.once('socket', function (socket) {\n\t\t\t\treqTimeout = setTimeout(function () {\n\t\t\t\t\treject(new FetchError(`network timeout at: ${request.url}`, 'request-timeout'));\n\t\t\t\t\tfinalize();\n\t\t\t\t}, request.timeout);\n\t\t\t});\n\t\t}\n\n\t\treq.on('error', function (err) {\n\t\t\treject(new FetchError(`request to ${request.url} failed, reason: ${err.message}`, 'system', err));\n\t\t\tfinalize();\n\t\t});\n\n\t\treq.on('response', function (res) {\n\t\t\tclearTimeout(reqTimeout);\n\n\t\t\tconst headers = createHeadersLenient(res.headers);\n\n\t\t\t// HTTP fetch step 5\n\t\t\tif (fetch.isRedirect(res.statusCode)) {\n\t\t\t\t// HTTP fetch step 5.2\n\t\t\t\tconst location = headers.get('Location');\n\n\t\t\t\t// HTTP fetch step 5.3\n\t\t\t\tconst locationURL = location === null ? null : resolve_url(request.url, location);\n\n\t\t\t\t// HTTP fetch step 5.5\n\t\t\t\tswitch (request.redirect) {\n\t\t\t\t\tcase 'error':\n\t\t\t\t\t\treject(new FetchError(`uri requested responds with a redirect, redirect mode is set to error: ${request.url}`, 'no-redirect'));\n\t\t\t\t\t\tfinalize();\n\t\t\t\t\t\treturn;\n\t\t\t\t\tcase 'manual':\n\t\t\t\t\t\t// node-fetch-specific step: make manual redirect a bit easier to use by setting the Location header value to the resolved URL.\n\t\t\t\t\t\tif (locationURL !== null) {\n\t\t\t\t\t\t\t// handle corrupted header\n\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\theaders.set('Location', locationURL);\n\t\t\t\t\t\t\t} catch (err) {\n\t\t\t\t\t\t\t\t// istanbul ignore next: nodejs server prevent invalid response headers, we can't test this through normal request\n\t\t\t\t\t\t\t\treject(err);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase 'follow':\n\t\t\t\t\t\t// HTTP-redirect fetch step 2\n\t\t\t\t\t\tif (locationURL === null) {\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// HTTP-redirect fetch step 5\n\t\t\t\t\t\tif (request.counter >= request.follow) {\n\t\t\t\t\t\t\treject(new FetchError(`maximum redirect reached at: ${request.url}`, 'max-redirect'));\n\t\t\t\t\t\t\tfinalize();\n\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// HTTP-redirect fetch step 6 (counter increment)\n\t\t\t\t\t\t// Create a new Request object.\n\t\t\t\t\t\tconst requestOpts = {\n\t\t\t\t\t\t\theaders: new Headers(request.headers),\n\t\t\t\t\t\t\tfollow: request.follow,\n\t\t\t\t\t\t\tcounter: request.counter + 1,\n\t\t\t\t\t\t\tagent: request.agent,\n\t\t\t\t\t\t\tcompress: request.compress,\n\t\t\t\t\t\t\tmethod: request.method,\n\t\t\t\t\t\t\tbody: request.body,\n\t\t\t\t\t\t\tsignal: request.signal,\n\t\t\t\t\t\t\ttimeout: request.timeout,\n\t\t\t\t\t\t\tsize: request.size\n\t\t\t\t\t\t};\n\n\t\t\t\t\t\t// HTTP-redirect fetch step 9\n\t\t\t\t\t\tif (res.statusCode !== 303 && request.body && getTotalBytes(request) === null) {\n\t\t\t\t\t\t\treject(new FetchError('Cannot follow redirect with body being a readable stream', 'unsupported-redirect'));\n\t\t\t\t\t\t\tfinalize();\n\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// HTTP-redirect fetch step 11\n\t\t\t\t\t\tif (res.statusCode === 303 || (res.statusCode === 301 || res.statusCode === 302) && request.method === 'POST') {\n\t\t\t\t\t\t\trequestOpts.method = 'GET';\n\t\t\t\t\t\t\trequestOpts.body = undefined;\n\t\t\t\t\t\t\trequestOpts.headers.delete('content-length');\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// HTTP-redirect fetch step 15\n\t\t\t\t\t\tresolve(fetch(new Request(locationURL, requestOpts)));\n\t\t\t\t\t\tfinalize();\n\t\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// prepare response\n\t\t\tres.once('end', function () {\n\t\t\t\tif (signal) signal.removeEventListener('abort', abortAndFinalize);\n\t\t\t});\n\t\t\tlet body = res.pipe(new PassThrough$1());\n\n\t\t\tconst response_options = {\n\t\t\t\turl: request.url,\n\t\t\t\tstatus: res.statusCode,\n\t\t\t\tstatusText: res.statusMessage,\n\t\t\t\theaders: headers,\n\t\t\t\tsize: request.size,\n\t\t\t\ttimeout: request.timeout,\n\t\t\t\tcounter: request.counter\n\t\t\t};\n\n\t\t\t// HTTP-network fetch step 12.1.1.3\n\t\t\tconst codings = headers.get('Content-Encoding');\n\n\t\t\t// HTTP-network fetch step 12.1.1.4: handle content codings\n\n\t\t\t// in following scenarios we ignore compression support\n\t\t\t// 1. compression support is disabled\n\t\t\t// 2. HEAD request\n\t\t\t// 3. no Content-Encoding header\n\t\t\t// 4. no content response (204)\n\t\t\t// 5. content not modified response (304)\n\t\t\tif (!request.compress || request.method === 'HEAD' || codings === null || res.statusCode === 204 || res.statusCode === 304) {\n\t\t\t\tresponse = new Response(body, response_options);\n\t\t\t\tresolve(response);\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\t// For Node v6+\n\t\t\t// Be less strict when decoding compressed responses, since sometimes\n\t\t\t// servers send slightly invalid responses that are still accepted\n\t\t\t// by common browsers.\n\t\t\t// Always using Z_SYNC_FLUSH is what cURL does.\n\t\t\tconst zlibOptions = {\n\t\t\t\tflush: zlib.Z_SYNC_FLUSH,\n\t\t\t\tfinishFlush: zlib.Z_SYNC_FLUSH\n\t\t\t};\n\n\t\t\t// for gzip\n\t\t\tif (codings == 'gzip' || codings == 'x-gzip') {\n\t\t\t\tbody = body.pipe(zlib.createGunzip(zlibOptions));\n\t\t\t\tresponse = new Response(body, response_options);\n\t\t\t\tresolve(response);\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\t// for deflate\n\t\t\tif (codings == 'deflate' || codings == 'x-deflate') {\n\t\t\t\t// handle the infamous raw deflate response from old servers\n\t\t\t\t// a hack for old IIS and Apache servers\n\t\t\t\tconst raw = res.pipe(new PassThrough$1());\n\t\t\t\traw.once('data', function (chunk) {\n\t\t\t\t\t// see http://stackoverflow.com/questions/37519828\n\t\t\t\t\tif ((chunk[0] & 0x0F) === 0x08) {\n\t\t\t\t\t\tbody = body.pipe(zlib.createInflate());\n\t\t\t\t\t} else {\n\t\t\t\t\t\tbody = body.pipe(zlib.createInflateRaw());\n\t\t\t\t\t}\n\t\t\t\t\tresponse = new Response(body, response_options);\n\t\t\t\t\tresolve(response);\n\t\t\t\t});\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\t// for br\n\t\t\tif (codings == 'br' && typeof zlib.createBrotliDecompress === 'function') {\n\t\t\t\tbody = body.pipe(zlib.createBrotliDecompress());\n\t\t\t\tresponse = new Response(body, response_options);\n\t\t\t\tresolve(response);\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\t// otherwise, use response as-is\n\t\t\tresponse = new Response(body, response_options);\n\t\t\tresolve(response);\n\t\t});\n\n\t\twriteToStream(req, request);\n\t});\n}\n/**\n * Redirect code matching\n *\n * @param   Number   code  Status code\n * @return  Boolean\n */\nfetch.isRedirect = function (code) {\n\treturn code === 301 || code === 302 || code === 303 || code === 307 || code === 308;\n};\n\n// expose Promise\nfetch.Promise = global.Promise;\n\nmodule.exports = exports = fetch;\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.default = exports;\nexports.Headers = Headers;\nexports.Request = Request;\nexports.Response = Response;\nexports.FetchError = FetchError;\n","var wrappy = require('wrappy')\nmodule.exports = wrappy(once)\nmodule.exports.strict = wrappy(onceStrict)\n\nonce.proto = once(function () {\n  Object.defineProperty(Function.prototype, 'once', {\n    value: function () {\n      return once(this)\n    },\n    configurable: true\n  })\n\n  Object.defineProperty(Function.prototype, 'onceStrict', {\n    value: function () {\n      return onceStrict(this)\n    },\n    configurable: true\n  })\n})\n\nfunction once (fn) {\n  var f = function () {\n    if (f.called) return f.value\n    f.called = true\n    return f.value = fn.apply(this, arguments)\n  }\n  f.called = false\n  return f\n}\n\nfunction onceStrict (fn) {\n  var f = function () {\n    if (f.called)\n      throw new Error(f.onceError)\n    f.called = true\n    return f.value = fn.apply(this, arguments)\n  }\n  var name = fn.name || 'Function wrapped with `once`'\n  f.onceError = name + \" shouldn't be called more than once\"\n  f.called = false\n  return f\n}\n","'use strict'\n\nvar characterEntities = require('character-entities')\n\nmodule.exports = decodeEntity\n\nvar own = {}.hasOwnProperty\n\nfunction decodeEntity(characters) {\n  return own.call(characterEntities, characters)\n    ? characterEntities[characters]\n    : false\n}\n","'use strict'\n\nvar syntax = require('micromark-extension-frontmatter')\nvar fromMarkdown = require('mdast-util-frontmatter/from-markdown')\nvar toMarkdown = require('mdast-util-frontmatter/to-markdown')\n\nmodule.exports = frontmatter\n\nfunction frontmatter(options) {\n  var data = this.data()\n  add('micromarkExtensions', syntax(options))\n  add('fromMarkdownExtensions', fromMarkdown(options))\n  add('toMarkdownExtensions', toMarkdown(options))\n  function add(field, value) {\n    /* istanbul ignore if - other extensions. */\n    if (data[field]) data[field].push(value)\n    else data[field] = [value]\n  }\n}\n","'use strict'\n\nmodule.exports = parse\n\nvar fromMarkdown = require('mdast-util-from-markdown')\n\nfunction parse(options) {\n  var self = this\n\n  this.Parser = parse\n\n  function parse(doc) {\n    return fromMarkdown(\n      doc,\n      Object.assign({}, self.data('settings'), options, {\n        // Note: these options are not in the readme.\n        // The goal is for them to be set by plugins on `data` instead of being\n        // passed by users.\n        extensions: self.data('micromarkExtensions') || [],\n        mdastExtensions: self.data('fromMarkdownExtensions') || []\n      })\n    )\n  }\n}\n","'use strict'\n\nmodule.exports = stringify\n\nvar toMarkdown = require('mdast-util-to-markdown')\n\nfunction stringify(options) {\n  var self = this\n\n  this.Compiler = compile\n\n  function compile(tree) {\n    return toMarkdown(\n      tree,\n      Object.assign({}, self.data('settings'), options, {\n        // Note: this option is not in the readme.\n        // The goal is for it to be set by plugins on `data` instead of being\n        // passed by users.\n        extensions: self.data('toMarkdownExtensions') || []\n      })\n    )\n  }\n}\n","/*!\n * repeat-string <https://github.com/jonschlinkert/repeat-string>\n *\n * Copyright (c) 2014-2015, Jon Schlinkert.\n * Licensed under the MIT License.\n */\n\n'use strict';\n\n/**\n * Results cache\n */\n\nvar res = '';\nvar cache;\n\n/**\n * Expose `repeat`\n */\n\nmodule.exports = repeat;\n\n/**\n * Repeat the given `string` the specified `number`\n * of times.\n *\n * **Example:**\n *\n * ```js\n * var repeat = require('repeat-string');\n * repeat('A', 5);\n * //=> AAAAA\n * ```\n *\n * @param {String} `string` The string to repeat\n * @param {Number} `number` The number of times to repeat the string\n * @return {String} Repeated string\n * @api public\n */\n\nfunction repeat(str, num) {\n  if (typeof str !== 'string') {\n    throw new TypeError('expected a string');\n  }\n\n  // cover common, quick use cases\n  if (num === 1) return str;\n  if (num === 2) return str + str;\n\n  var max = str.length * num;\n  if (cache !== str || typeof cache === 'undefined') {\n    cache = str;\n    res = '';\n  } else if (res.length >= max) {\n    return res.substr(0, max);\n  }\n\n  while (max > res.length && num > 1) {\n    if (num & 1) {\n      res += str;\n    }\n\n    num >>= 1;\n    str += str;\n  }\n\n  res += str;\n  res = res.substr(0, max);\n  return res;\n}\n","'use strict'\n\nvar wrap = require('./wrap.js')\n\nmodule.exports = trough\n\ntrough.wrap = wrap\n\nvar slice = [].slice\n\n// Create new middleware.\nfunction trough() {\n  var fns = []\n  var middleware = {}\n\n  middleware.run = run\n  middleware.use = use\n\n  return middleware\n\n  // Run `fns`.  Last argument must be a completion handler.\n  function run() {\n    var index = -1\n    var input = slice.call(arguments, 0, -1)\n    var done = arguments[arguments.length - 1]\n\n    if (typeof done !== 'function') {\n      throw new Error('Expected function as last argument, not ' + done)\n    }\n\n    next.apply(null, [null].concat(input))\n\n    // Run the next `fn`, if any.\n    function next(err) {\n      var fn = fns[++index]\n      var params = slice.call(arguments, 0)\n      var values = params.slice(1)\n      var length = input.length\n      var pos = -1\n\n      if (err) {\n        done(err)\n        return\n      }\n\n      // Copy non-nully input into values.\n      while (++pos < length) {\n        if (values[pos] === null || values[pos] === undefined) {\n          values[pos] = input[pos]\n        }\n      }\n\n      input = values\n\n      // Next or done.\n      if (fn) {\n        wrap(fn, next).apply(null, input)\n      } else {\n        done.apply(null, [null].concat(input))\n      }\n    }\n  }\n\n  // Add `fn` to the list.\n  function use(fn) {\n    if (typeof fn !== 'function') {\n      throw new Error('Expected `fn` to be a function, not ' + fn)\n    }\n\n    fns.push(fn)\n\n    return middleware\n  }\n}\n","'use strict'\n\nvar slice = [].slice\n\nmodule.exports = wrap\n\n// Wrap `fn`.\n// Can be sync or async; return a promise, receive a completion handler, return\n// new values and errors.\nfunction wrap(fn, callback) {\n  var invoked\n\n  return wrapped\n\n  function wrapped() {\n    var params = slice.call(arguments, 0)\n    var callback = fn.length > params.length\n    var result\n\n    if (callback) {\n      params.push(done)\n    }\n\n    try {\n      result = fn.apply(null, params)\n    } catch (error) {\n      // Well, this is quite the pickle.\n      // `fn` received a callback and invoked it (thus continuing the pipeline),\n      // but later also threw an error.\n      // Were not about to restart the pipeline again, so the only thing left\n      // to do is to throw the thing instead.\n      if (callback && invoked) {\n        throw error\n      }\n\n      return done(error)\n    }\n\n    if (!callback) {\n      if (result && typeof result.then === 'function') {\n        result.then(then, done)\n      } else if (result instanceof Error) {\n        done(result)\n      } else {\n        then(result)\n      }\n    }\n  }\n\n  // Invoke `next`, only once.\n  function done() {\n    if (!invoked) {\n      invoked = true\n\n      callback.apply(null, arguments)\n    }\n  }\n\n  // Invoke `done` with one value.\n  // Tracks if an error is passed, too.\n  function then(value) {\n    done(null, value)\n  }\n}\n","module.exports = require('./lib/tunnel');\n","'use strict';\n\nvar net = require('net');\nvar tls = require('tls');\nvar http = require('http');\nvar https = require('https');\nvar events = require('events');\nvar assert = require('assert');\nvar util = require('util');\n\n\nexports.httpOverHttp = httpOverHttp;\nexports.httpsOverHttp = httpsOverHttp;\nexports.httpOverHttps = httpOverHttps;\nexports.httpsOverHttps = httpsOverHttps;\n\n\nfunction httpOverHttp(options) {\n  var agent = new TunnelingAgent(options);\n  agent.request = http.request;\n  return agent;\n}\n\nfunction httpsOverHttp(options) {\n  var agent = new TunnelingAgent(options);\n  agent.request = http.request;\n  agent.createSocket = createSecureSocket;\n  agent.defaultPort = 443;\n  return agent;\n}\n\nfunction httpOverHttps(options) {\n  var agent = new TunnelingAgent(options);\n  agent.request = https.request;\n  return agent;\n}\n\nfunction httpsOverHttps(options) {\n  var agent = new TunnelingAgent(options);\n  agent.request = https.request;\n  agent.createSocket = createSecureSocket;\n  agent.defaultPort = 443;\n  return agent;\n}\n\n\nfunction TunnelingAgent(options) {\n  var self = this;\n  self.options = options || {};\n  self.proxyOptions = self.options.proxy || {};\n  self.maxSockets = self.options.maxSockets || http.Agent.defaultMaxSockets;\n  self.requests = [];\n  self.sockets = [];\n\n  self.on('free', function onFree(socket, host, port, localAddress) {\n    var options = toOptions(host, port, localAddress);\n    for (var i = 0, len = self.requests.length; i < len; ++i) {\n      var pending = self.requests[i];\n      if (pending.host === options.host && pending.port === options.port) {\n        // Detect the request to connect same origin server,\n        // reuse the connection.\n        self.requests.splice(i, 1);\n        pending.request.onSocket(socket);\n        return;\n      }\n    }\n    socket.destroy();\n    self.removeSocket(socket);\n  });\n}\nutil.inherits(TunnelingAgent, events.EventEmitter);\n\nTunnelingAgent.prototype.addRequest = function addRequest(req, host, port, localAddress) {\n  var self = this;\n  var options = mergeOptions({request: req}, self.options, toOptions(host, port, localAddress));\n\n  if (self.sockets.length >= this.maxSockets) {\n    // We are over limit so we'll add it to the queue.\n    self.requests.push(options);\n    return;\n  }\n\n  // If we are under maxSockets create a new one.\n  self.createSocket(options, function(socket) {\n    socket.on('free', onFree);\n    socket.on('close', onCloseOrRemove);\n    socket.on('agentRemove', onCloseOrRemove);\n    req.onSocket(socket);\n\n    function onFree() {\n      self.emit('free', socket, options);\n    }\n\n    function onCloseOrRemove(err) {\n      self.removeSocket(socket);\n      socket.removeListener('free', onFree);\n      socket.removeListener('close', onCloseOrRemove);\n      socket.removeListener('agentRemove', onCloseOrRemove);\n    }\n  });\n};\n\nTunnelingAgent.prototype.createSocket = function createSocket(options, cb) {\n  var self = this;\n  var placeholder = {};\n  self.sockets.push(placeholder);\n\n  var connectOptions = mergeOptions({}, self.proxyOptions, {\n    method: 'CONNECT',\n    path: options.host + ':' + options.port,\n    agent: false,\n    headers: {\n      host: options.host + ':' + options.port\n    }\n  });\n  if (options.localAddress) {\n    connectOptions.localAddress = options.localAddress;\n  }\n  if (connectOptions.proxyAuth) {\n    connectOptions.headers = connectOptions.headers || {};\n    connectOptions.headers['Proxy-Authorization'] = 'Basic ' +\n        new Buffer(connectOptions.proxyAuth).toString('base64');\n  }\n\n  debug('making CONNECT request');\n  var connectReq = self.request(connectOptions);\n  connectReq.useChunkedEncodingByDefault = false; // for v0.6\n  connectReq.once('response', onResponse); // for v0.6\n  connectReq.once('upgrade', onUpgrade);   // for v0.6\n  connectReq.once('connect', onConnect);   // for v0.7 or later\n  connectReq.once('error', onError);\n  connectReq.end();\n\n  function onResponse(res) {\n    // Very hacky. This is necessary to avoid http-parser leaks.\n    res.upgrade = true;\n  }\n\n  function onUpgrade(res, socket, head) {\n    // Hacky.\n    process.nextTick(function() {\n      onConnect(res, socket, head);\n    });\n  }\n\n  function onConnect(res, socket, head) {\n    connectReq.removeAllListeners();\n    socket.removeAllListeners();\n\n    if (res.statusCode !== 200) {\n      debug('tunneling socket could not be established, statusCode=%d',\n        res.statusCode);\n      socket.destroy();\n      var error = new Error('tunneling socket could not be established, ' +\n        'statusCode=' + res.statusCode);\n      error.code = 'ECONNRESET';\n      options.request.emit('error', error);\n      self.removeSocket(placeholder);\n      return;\n    }\n    if (head.length > 0) {\n      debug('got illegal response body from proxy');\n      socket.destroy();\n      var error = new Error('got illegal response body from proxy');\n      error.code = 'ECONNRESET';\n      options.request.emit('error', error);\n      self.removeSocket(placeholder);\n      return;\n    }\n    debug('tunneling connection has established');\n    self.sockets[self.sockets.indexOf(placeholder)] = socket;\n    return cb(socket);\n  }\n\n  function onError(cause) {\n    connectReq.removeAllListeners();\n\n    debug('tunneling socket could not be established, cause=%s\\n',\n          cause.message, cause.stack);\n    var error = new Error('tunneling socket could not be established, ' +\n                          'cause=' + cause.message);\n    error.code = 'ECONNRESET';\n    options.request.emit('error', error);\n    self.removeSocket(placeholder);\n  }\n};\n\nTunnelingAgent.prototype.removeSocket = function removeSocket(socket) {\n  var pos = this.sockets.indexOf(socket)\n  if (pos === -1) {\n    return;\n  }\n  this.sockets.splice(pos, 1);\n\n  var pending = this.requests.shift();\n  if (pending) {\n    // If we have pending requests and a socket gets closed a new one\n    // needs to be created to take over in the pool for the one that closed.\n    this.createSocket(pending, function(socket) {\n      pending.request.onSocket(socket);\n    });\n  }\n};\n\nfunction createSecureSocket(options, cb) {\n  var self = this;\n  TunnelingAgent.prototype.createSocket.call(self, options, function(socket) {\n    var hostHeader = options.request.getHeader('host');\n    var tlsOptions = mergeOptions({}, self.options, {\n      socket: socket,\n      servername: hostHeader ? hostHeader.replace(/:.*$/, '') : options.host\n    });\n\n    // 0 is dummy port for v0.6\n    var secureSocket = tls.connect(0, tlsOptions);\n    self.sockets[self.sockets.indexOf(socket)] = secureSocket;\n    cb(secureSocket);\n  });\n}\n\n\nfunction toOptions(host, port, localAddress) {\n  if (typeof host === 'string') { // since v0.10\n    return {\n      host: host,\n      port: port,\n      localAddress: localAddress\n    };\n  }\n  return host; // for v0.11 or later\n}\n\nfunction mergeOptions(target) {\n  for (var i = 1, len = arguments.length; i < len; ++i) {\n    var overrides = arguments[i];\n    if (typeof overrides === 'object') {\n      var keys = Object.keys(overrides);\n      for (var j = 0, keyLen = keys.length; j < keyLen; ++j) {\n        var k = keys[j];\n        if (overrides[k] !== undefined) {\n          target[k] = overrides[k];\n        }\n      }\n    }\n  }\n  return target;\n}\n\n\nvar debug;\nif (process.env.NODE_DEBUG && /\\btunnel\\b/.test(process.env.NODE_DEBUG)) {\n  debug = function() {\n    var args = Array.prototype.slice.call(arguments);\n    if (typeof args[0] === 'string') {\n      args[0] = 'TUNNEL: ' + args[0];\n    } else {\n      args.unshift('TUNNEL:');\n    }\n    console.error.apply(console, args);\n  }\n} else {\n  debug = function() {};\n}\nexports.debug = debug; // for test\n","'use strict'\n\nvar bail = require('bail')\nvar buffer = require('is-buffer')\nvar extend = require('extend')\nvar plain = require('is-plain-obj')\nvar trough = require('trough')\nvar vfile = require('vfile')\n\n// Expose a frozen processor.\nmodule.exports = unified().freeze()\n\nvar slice = [].slice\nvar own = {}.hasOwnProperty\n\n// Process pipeline.\nvar pipeline = trough()\n  .use(pipelineParse)\n  .use(pipelineRun)\n  .use(pipelineStringify)\n\nfunction pipelineParse(p, ctx) {\n  ctx.tree = p.parse(ctx.file)\n}\n\nfunction pipelineRun(p, ctx, next) {\n  p.run(ctx.tree, ctx.file, done)\n\n  function done(error, tree, file) {\n    if (error) {\n      next(error)\n    } else {\n      ctx.tree = tree\n      ctx.file = file\n      next()\n    }\n  }\n}\n\nfunction pipelineStringify(p, ctx) {\n  var result = p.stringify(ctx.tree, ctx.file)\n\n  if (result === undefined || result === null) {\n    // Empty.\n  } else if (typeof result === 'string' || buffer(result)) {\n    ctx.file.contents = result\n  } else {\n    ctx.file.result = result\n  }\n}\n\n// Function to create the first processor.\nfunction unified() {\n  var attachers = []\n  var transformers = trough()\n  var namespace = {}\n  var freezeIndex = -1\n  var frozen\n\n  // Data management.\n  processor.data = data\n\n  // Lock.\n  processor.freeze = freeze\n\n  // Plugins.\n  processor.attachers = attachers\n  processor.use = use\n\n  // API.\n  processor.parse = parse\n  processor.stringify = stringify\n  processor.run = run\n  processor.runSync = runSync\n  processor.process = process\n  processor.processSync = processSync\n\n  // Expose.\n  return processor\n\n  // Create a new processor based on the processor in the current scope.\n  function processor() {\n    var destination = unified()\n    var index = -1\n\n    while (++index < attachers.length) {\n      destination.use.apply(null, attachers[index])\n    }\n\n    destination.data(extend(true, {}, namespace))\n\n    return destination\n  }\n\n  // Freeze: used to signal a processor that has finished configuration.\n  //\n  // For example, take unified itself: its frozen.\n  // Plugins should not be added to it.\n  // Rather, it should be extended, by invoking it, before modifying it.\n  //\n  // In essence, always invoke this when exporting a processor.\n  function freeze() {\n    var values\n    var transformer\n\n    if (frozen) {\n      return processor\n    }\n\n    while (++freezeIndex < attachers.length) {\n      values = attachers[freezeIndex]\n\n      if (values[1] === false) {\n        continue\n      }\n\n      if (values[1] === true) {\n        values[1] = undefined\n      }\n\n      transformer = values[0].apply(processor, values.slice(1))\n\n      if (typeof transformer === 'function') {\n        transformers.use(transformer)\n      }\n    }\n\n    frozen = true\n    freezeIndex = Infinity\n\n    return processor\n  }\n\n  // Data management.\n  // Getter / setter for processor-specific informtion.\n  function data(key, value) {\n    if (typeof key === 'string') {\n      // Set `key`.\n      if (arguments.length === 2) {\n        assertUnfrozen('data', frozen)\n        namespace[key] = value\n        return processor\n      }\n\n      // Get `key`.\n      return (own.call(namespace, key) && namespace[key]) || null\n    }\n\n    // Set space.\n    if (key) {\n      assertUnfrozen('data', frozen)\n      namespace = key\n      return processor\n    }\n\n    // Get space.\n    return namespace\n  }\n\n  // Plugin management.\n  //\n  // Pass it:\n  // *   an attacher and options,\n  // *   a preset,\n  // *   a list of presets, attachers, and arguments (list of attachers and\n  //     options).\n  function use(value) {\n    var settings\n\n    assertUnfrozen('use', frozen)\n\n    if (value === null || value === undefined) {\n      // Empty.\n    } else if (typeof value === 'function') {\n      addPlugin.apply(null, arguments)\n    } else if (typeof value === 'object') {\n      if ('length' in value) {\n        addList(value)\n      } else {\n        addPreset(value)\n      }\n    } else {\n      throw new Error('Expected usable value, not `' + value + '`')\n    }\n\n    if (settings) {\n      namespace.settings = extend(namespace.settings || {}, settings)\n    }\n\n    return processor\n\n    function addPreset(result) {\n      addList(result.plugins)\n\n      if (result.settings) {\n        settings = extend(settings || {}, result.settings)\n      }\n    }\n\n    function add(value) {\n      if (typeof value === 'function') {\n        addPlugin(value)\n      } else if (typeof value === 'object') {\n        if ('length' in value) {\n          addPlugin.apply(null, value)\n        } else {\n          addPreset(value)\n        }\n      } else {\n        throw new Error('Expected usable value, not `' + value + '`')\n      }\n    }\n\n    function addList(plugins) {\n      var index = -1\n\n      if (plugins === null || plugins === undefined) {\n        // Empty.\n      } else if (typeof plugins === 'object' && 'length' in plugins) {\n        while (++index < plugins.length) {\n          add(plugins[index])\n        }\n      } else {\n        throw new Error('Expected a list of plugins, not `' + plugins + '`')\n      }\n    }\n\n    function addPlugin(plugin, value) {\n      var entry = find(plugin)\n\n      if (entry) {\n        if (plain(entry[1]) && plain(value)) {\n          value = extend(true, entry[1], value)\n        }\n\n        entry[1] = value\n      } else {\n        attachers.push(slice.call(arguments))\n      }\n    }\n  }\n\n  function find(plugin) {\n    var index = -1\n\n    while (++index < attachers.length) {\n      if (attachers[index][0] === plugin) {\n        return attachers[index]\n      }\n    }\n  }\n\n  // Parse a file (in string or vfile representation) into a unist node using\n  // the `Parser` on the processor.\n  function parse(doc) {\n    var file = vfile(doc)\n    var Parser\n\n    freeze()\n    Parser = processor.Parser\n    assertParser('parse', Parser)\n\n    if (newable(Parser, 'parse')) {\n      return new Parser(String(file), file).parse()\n    }\n\n    return Parser(String(file), file) // eslint-disable-line new-cap\n  }\n\n  // Run transforms on a unist node representation of a file (in string or\n  // vfile representation), async.\n  function run(node, file, cb) {\n    assertNode(node)\n    freeze()\n\n    if (!cb && typeof file === 'function') {\n      cb = file\n      file = null\n    }\n\n    if (!cb) {\n      return new Promise(executor)\n    }\n\n    executor(null, cb)\n\n    function executor(resolve, reject) {\n      transformers.run(node, vfile(file), done)\n\n      function done(error, tree, file) {\n        tree = tree || node\n        if (error) {\n          reject(error)\n        } else if (resolve) {\n          resolve(tree)\n        } else {\n          cb(null, tree, file)\n        }\n      }\n    }\n  }\n\n  // Run transforms on a unist node representation of a file (in string or\n  // vfile representation), sync.\n  function runSync(node, file) {\n    var result\n    var complete\n\n    run(node, file, done)\n\n    assertDone('runSync', 'run', complete)\n\n    return result\n\n    function done(error, tree) {\n      complete = true\n      result = tree\n      bail(error)\n    }\n  }\n\n  // Stringify a unist node representation of a file (in string or vfile\n  // representation) into a string using the `Compiler` on the processor.\n  function stringify(node, doc) {\n    var file = vfile(doc)\n    var Compiler\n\n    freeze()\n    Compiler = processor.Compiler\n    assertCompiler('stringify', Compiler)\n    assertNode(node)\n\n    if (newable(Compiler, 'compile')) {\n      return new Compiler(node, file).compile()\n    }\n\n    return Compiler(node, file) // eslint-disable-line new-cap\n  }\n\n  // Parse a file (in string or vfile representation) into a unist node using\n  // the `Parser` on the processor, then run transforms on that node, and\n  // compile the resulting node using the `Compiler` on the processor, and\n  // store that result on the vfile.\n  function process(doc, cb) {\n    freeze()\n    assertParser('process', processor.Parser)\n    assertCompiler('process', processor.Compiler)\n\n    if (!cb) {\n      return new Promise(executor)\n    }\n\n    executor(null, cb)\n\n    function executor(resolve, reject) {\n      var file = vfile(doc)\n\n      pipeline.run(processor, {file: file}, done)\n\n      function done(error) {\n        if (error) {\n          reject(error)\n        } else if (resolve) {\n          resolve(file)\n        } else {\n          cb(null, file)\n        }\n      }\n    }\n  }\n\n  // Process the given document (in string or vfile representation), sync.\n  function processSync(doc) {\n    var file\n    var complete\n\n    freeze()\n    assertParser('processSync', processor.Parser)\n    assertCompiler('processSync', processor.Compiler)\n    file = vfile(doc)\n\n    process(file, done)\n\n    assertDone('processSync', 'process', complete)\n\n    return file\n\n    function done(error) {\n      complete = true\n      bail(error)\n    }\n  }\n}\n\n// Check if `value` is a constructor.\nfunction newable(value, name) {\n  return (\n    typeof value === 'function' &&\n    value.prototype &&\n    // A function with keys in its prototype is probably a constructor.\n    // Classes prototype methods are not enumerable, so we check if some value\n    // exists in the prototype.\n    (keys(value.prototype) || name in value.prototype)\n  )\n}\n\n// Check if `value` is an object with keys.\nfunction keys(value) {\n  var key\n  for (key in value) {\n    return true\n  }\n\n  return false\n}\n\n// Assert a parser is available.\nfunction assertParser(name, Parser) {\n  if (typeof Parser !== 'function') {\n    throw new Error('Cannot `' + name + '` without `Parser`')\n  }\n}\n\n// Assert a compiler is available.\nfunction assertCompiler(name, Compiler) {\n  if (typeof Compiler !== 'function') {\n    throw new Error('Cannot `' + name + '` without `Compiler`')\n  }\n}\n\n// Assert the processor is not frozen.\nfunction assertUnfrozen(name, frozen) {\n  if (frozen) {\n    throw new Error(\n      'Cannot invoke `' +\n        name +\n        '` on a frozen processor.\\nCreate a new processor first, by invoking it: use `processor()` instead of `processor`.'\n    )\n  }\n}\n\n// Assert `node` is a unist node.\nfunction assertNode(node) {\n  if (!node || typeof node.type !== 'string') {\n    throw new Error('Expected node, got `' + node + '`')\n  }\n}\n\n// Assert that `complete` is `true`.\nfunction assertDone(name, asyncName, complete) {\n  if (!complete) {\n    throw new Error(\n      '`' + name + '` finished async. Use `' + asyncName + '` instead'\n    )\n  }\n}\n","/*!\n * Determine if an object is a Buffer\n *\n * @author   Feross Aboukhadijeh <https://feross.org>\n * @license  MIT\n */\n\nmodule.exports = function isBuffer (obj) {\n  return obj != null && obj.constructor != null &&\n    typeof obj.constructor.isBuffer === 'function' && obj.constructor.isBuffer(obj)\n}\n","'use strict'\n\nmodule.exports = convert\n\nfunction convert(test) {\n  if (test == null) {\n    return ok\n  }\n\n  if (typeof test === 'string') {\n    return typeFactory(test)\n  }\n\n  if (typeof test === 'object') {\n    return 'length' in test ? anyFactory(test) : allFactory(test)\n  }\n\n  if (typeof test === 'function') {\n    return test\n  }\n\n  throw new Error('Expected function, string, or object as test')\n}\n\n// Utility assert each property in `test` is represented in `node`, and each\n// values are strictly equal.\nfunction allFactory(test) {\n  return all\n\n  function all(node) {\n    var key\n\n    for (key in test) {\n      if (node[key] !== test[key]) return false\n    }\n\n    return true\n  }\n}\n\nfunction anyFactory(tests) {\n  var checks = []\n  var index = -1\n\n  while (++index < tests.length) {\n    checks[index] = convert(tests[index])\n  }\n\n  return any\n\n  function any() {\n    var index = -1\n\n    while (++index < checks.length) {\n      if (checks[index].apply(this, arguments)) {\n        return true\n      }\n    }\n\n    return false\n  }\n}\n\n// Utility to convert a string into a function which checks a given nodes type\n// for said string.\nfunction typeFactory(test) {\n  return type\n\n  function type(node) {\n    return Boolean(node && node.type === test)\n  }\n}\n\n// Utility to return true.\nfunction ok() {\n  return true\n}\n","'use strict'\n\nvar own = {}.hasOwnProperty\n\nmodule.exports = stringify\n\nfunction stringify(value) {\n  // Nothing.\n  if (!value || typeof value !== 'object') {\n    return ''\n  }\n\n  // Node.\n  if (own.call(value, 'position') || own.call(value, 'type')) {\n    return position(value.position)\n  }\n\n  // Position.\n  if (own.call(value, 'start') || own.call(value, 'end')) {\n    return position(value)\n  }\n\n  // Point.\n  if (own.call(value, 'line') || own.call(value, 'column')) {\n    return point(value)\n  }\n\n  // ?\n  return ''\n}\n\nfunction point(point) {\n  if (!point || typeof point !== 'object') {\n    point = {}\n  }\n\n  return index(point.line) + ':' + index(point.column)\n}\n\nfunction position(pos) {\n  if (!pos || typeof pos !== 'object') {\n    pos = {}\n  }\n\n  return point(pos.start) + '-' + point(pos.end)\n}\n\nfunction index(value) {\n  return value && typeof value === 'number' ? value : 1\n}\n","module.exports = color\nfunction color(d) {\n  return '\\u001B[33m' + d + '\\u001B[39m'\n}\n","'use strict'\n\nmodule.exports = visitParents\n\nvar convert = require('unist-util-is/convert')\nvar color = require('./color')\n\nvar CONTINUE = true\nvar SKIP = 'skip'\nvar EXIT = false\n\nvisitParents.CONTINUE = CONTINUE\nvisitParents.SKIP = SKIP\nvisitParents.EXIT = EXIT\n\nfunction visitParents(tree, test, visitor, reverse) {\n  var step\n  var is\n\n  if (typeof test === 'function' && typeof visitor !== 'function') {\n    reverse = visitor\n    visitor = test\n    test = null\n  }\n\n  is = convert(test)\n  step = reverse ? -1 : 1\n\n  factory(tree, null, [])()\n\n  function factory(node, index, parents) {\n    var value = typeof node === 'object' && node !== null ? node : {}\n    var name\n\n    if (typeof value.type === 'string') {\n      name =\n        typeof value.tagName === 'string'\n          ? value.tagName\n          : typeof value.name === 'string'\n          ? value.name\n          : undefined\n\n      visit.displayName =\n        'node (' + color(value.type + (name ? '<' + name + '>' : '')) + ')'\n    }\n\n    return visit\n\n    function visit() {\n      var grandparents = parents.concat(node)\n      var result = []\n      var subresult\n      var offset\n\n      if (!test || is(node, index, parents[parents.length - 1] || null)) {\n        result = toResult(visitor(node, parents))\n\n        if (result[0] === EXIT) {\n          return result\n        }\n      }\n\n      if (node.children && result[0] !== SKIP) {\n        offset = (reverse ? node.children.length : -1) + step\n\n        while (offset > -1 && offset < node.children.length) {\n          subresult = factory(node.children[offset], offset, grandparents)()\n\n          if (subresult[0] === EXIT) {\n            return subresult\n          }\n\n          offset =\n            typeof subresult[1] === 'number' ? subresult[1] : offset + step\n        }\n      }\n\n      return result\n    }\n  }\n}\n\nfunction toResult(value) {\n  if (value !== null && typeof value === 'object' && 'length' in value) {\n    return value\n  }\n\n  if (typeof value === 'number') {\n    return [CONTINUE, value]\n  }\n\n  return [value]\n}\n","'use strict'\n\nmodule.exports = visit\n\nvar visitParents = require('unist-util-visit-parents')\n\nvar CONTINUE = visitParents.CONTINUE\nvar SKIP = visitParents.SKIP\nvar EXIT = visitParents.EXIT\n\nvisit.CONTINUE = CONTINUE\nvisit.SKIP = SKIP\nvisit.EXIT = EXIT\n\nfunction visit(tree, test, visitor, reverse) {\n  if (typeof test === 'function' && typeof visitor !== 'function') {\n    reverse = visitor\n    visitor = test\n    test = null\n  }\n\n  visitParents(tree, test, overload, reverse)\n\n  function overload(node, parents) {\n    var parent = parents[parents.length - 1]\n    var index = parent ? parent.children.indexOf(node) : null\n    return visitor(node, index, parent)\n  }\n}\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nfunction getUserAgent() {\n  if (typeof navigator === \"object\" && \"userAgent\" in navigator) {\n    return navigator.userAgent;\n  }\n\n  if (typeof process === \"object\" && \"version\" in process) {\n    return `Node.js/${process.version.substr(1)} (${process.platform}; ${process.arch})`;\n  }\n\n  return \"<environment undetectable>\";\n}\n\nexports.getUserAgent = getUserAgent;\n//# sourceMappingURL=index.js.map\n","'use strict'\n\nvar stringify = require('unist-util-stringify-position')\n\nmodule.exports = VMessage\n\n// Inherit from `Error#`.\nfunction VMessagePrototype() {}\nVMessagePrototype.prototype = Error.prototype\nVMessage.prototype = new VMessagePrototype()\n\n// Message properties.\nvar proto = VMessage.prototype\n\nproto.file = ''\nproto.name = ''\nproto.reason = ''\nproto.message = ''\nproto.stack = ''\nproto.fatal = null\nproto.column = null\nproto.line = null\n\n// Construct a new VMessage.\n//\n// Note: We cannot invoke `Error` on the created context, as that adds readonly\n// `line` and `column` attributes on Safari 9, thus throwing and failing the\n// data.\nfunction VMessage(reason, position, origin) {\n  var parts\n  var range\n  var location\n\n  if (typeof position === 'string') {\n    origin = position\n    position = null\n  }\n\n  parts = parseOrigin(origin)\n  range = stringify(position) || '1:1'\n\n  location = {\n    start: {line: null, column: null},\n    end: {line: null, column: null}\n  }\n\n  // Node.\n  if (position && position.position) {\n    position = position.position\n  }\n\n  if (position) {\n    // Position.\n    if (position.start) {\n      location = position\n      position = position.start\n    } else {\n      // Point.\n      location.start = position\n    }\n  }\n\n  if (reason.stack) {\n    this.stack = reason.stack\n    reason = reason.message\n  }\n\n  this.message = reason\n  this.name = range\n  this.reason = reason\n  this.line = position ? position.line : null\n  this.column = position ? position.column : null\n  this.location = location\n  this.source = parts[0]\n  this.ruleId = parts[1]\n}\n\nfunction parseOrigin(origin) {\n  var result = [null, null]\n  var index\n\n  if (typeof origin === 'string') {\n    index = origin.indexOf(':')\n\n    if (index === -1) {\n      result[1] = origin\n    } else {\n      result[0] = origin.slice(0, index)\n      result[1] = origin.slice(index + 1)\n    }\n  }\n\n  return result\n}\n","'use strict'\n\nmodule.exports = require('./lib')\n","'use strict'\n\nvar p = require('./minpath')\nvar proc = require('./minproc')\nvar buffer = require('is-buffer')\n\nmodule.exports = VFile\n\nvar own = {}.hasOwnProperty\n\n// Order of setting (least specific to most), we need this because otherwise\n// `{stem: 'a', path: '~/b.js'}` would throw, as a path is needed before a\n// stem can be set.\nvar order = ['history', 'path', 'basename', 'stem', 'extname', 'dirname']\n\nVFile.prototype.toString = toString\n\n// Access full path (`~/index.min.js`).\nObject.defineProperty(VFile.prototype, 'path', {get: getPath, set: setPath})\n\n// Access parent path (`~`).\nObject.defineProperty(VFile.prototype, 'dirname', {\n  get: getDirname,\n  set: setDirname\n})\n\n// Access basename (`index.min.js`).\nObject.defineProperty(VFile.prototype, 'basename', {\n  get: getBasename,\n  set: setBasename\n})\n\n// Access extname (`.js`).\nObject.defineProperty(VFile.prototype, 'extname', {\n  get: getExtname,\n  set: setExtname\n})\n\n// Access stem (`index.min`).\nObject.defineProperty(VFile.prototype, 'stem', {get: getStem, set: setStem})\n\n// Construct a new file.\nfunction VFile(options) {\n  var prop\n  var index\n\n  if (!options) {\n    options = {}\n  } else if (typeof options === 'string' || buffer(options)) {\n    options = {contents: options}\n  } else if ('message' in options && 'messages' in options) {\n    return options\n  }\n\n  if (!(this instanceof VFile)) {\n    return new VFile(options)\n  }\n\n  this.data = {}\n  this.messages = []\n  this.history = []\n  this.cwd = proc.cwd()\n\n  // Set path related properties in the correct order.\n  index = -1\n\n  while (++index < order.length) {\n    prop = order[index]\n\n    if (own.call(options, prop)) {\n      this[prop] = options[prop]\n    }\n  }\n\n  // Set non-path related properties.\n  for (prop in options) {\n    if (order.indexOf(prop) < 0) {\n      this[prop] = options[prop]\n    }\n  }\n}\n\nfunction getPath() {\n  return this.history[this.history.length - 1]\n}\n\nfunction setPath(path) {\n  assertNonEmpty(path, 'path')\n\n  if (this.path !== path) {\n    this.history.push(path)\n  }\n}\n\nfunction getDirname() {\n  return typeof this.path === 'string' ? p.dirname(this.path) : undefined\n}\n\nfunction setDirname(dirname) {\n  assertPath(this.path, 'dirname')\n  this.path = p.join(dirname || '', this.basename)\n}\n\nfunction getBasename() {\n  return typeof this.path === 'string' ? p.basename(this.path) : undefined\n}\n\nfunction setBasename(basename) {\n  assertNonEmpty(basename, 'basename')\n  assertPart(basename, 'basename')\n  this.path = p.join(this.dirname || '', basename)\n}\n\nfunction getExtname() {\n  return typeof this.path === 'string' ? p.extname(this.path) : undefined\n}\n\nfunction setExtname(extname) {\n  assertPart(extname, 'extname')\n  assertPath(this.path, 'extname')\n\n  if (extname) {\n    if (extname.charCodeAt(0) !== 46 /* `.` */) {\n      throw new Error('`extname` must start with `.`')\n    }\n\n    if (extname.indexOf('.', 1) > -1) {\n      throw new Error('`extname` cannot contain multiple dots')\n    }\n  }\n\n  this.path = p.join(this.dirname, this.stem + (extname || ''))\n}\n\nfunction getStem() {\n  return typeof this.path === 'string'\n    ? p.basename(this.path, this.extname)\n    : undefined\n}\n\nfunction setStem(stem) {\n  assertNonEmpty(stem, 'stem')\n  assertPart(stem, 'stem')\n  this.path = p.join(this.dirname || '', stem + (this.extname || ''))\n}\n\n// Get the value of the file.\nfunction toString(encoding) {\n  return (this.contents || '').toString(encoding)\n}\n\n// Assert that `part` is not a path (i.e., does not contain `p.sep`).\nfunction assertPart(part, name) {\n  if (part && part.indexOf(p.sep) > -1) {\n    throw new Error(\n      '`' + name + '` cannot be a path: did not expect `' + p.sep + '`'\n    )\n  }\n}\n\n// Assert that `part` is not empty.\nfunction assertNonEmpty(part, name) {\n  if (!part) {\n    throw new Error('`' + name + '` cannot be empty')\n  }\n}\n\n// Assert `path` exists.\nfunction assertPath(path, name) {\n  if (!path) {\n    throw new Error('Setting `' + name + '` requires `path` to be set too')\n  }\n}\n","'use strict'\n\nvar VMessage = require('vfile-message')\nvar VFile = require('./core.js')\n\nmodule.exports = VFile\n\nVFile.prototype.message = message\nVFile.prototype.info = info\nVFile.prototype.fail = fail\n\n// Create a message with `reason` at `position`.\n// When an error is passed in as `reason`, copies the stack.\nfunction message(reason, position, origin) {\n  var message = new VMessage(reason, position, origin)\n\n  if (this.path) {\n    message.name = this.path + ':' + message.name\n    message.file = this.path\n  }\n\n  message.fatal = false\n\n  this.messages.push(message)\n\n  return message\n}\n\n// Fail: creates a vmessage, associates it with the file, and throws it.\nfunction fail() {\n  var message = this.message.apply(this, arguments)\n\n  message.fatal = true\n\n  throw message\n}\n\n// Info: creates a vmessage, associates it with the file, and marks the fatality\n// as null.\nfunction info() {\n  var message = this.message.apply(this, arguments)\n\n  message.fatal = null\n\n  return message\n}\n","'use strict'\n\nmodule.exports = require('path')\n","'use strict'\n\nmodule.exports = process\n","/*!\n * Determine if an object is a Buffer\n *\n * @author   Feross Aboukhadijeh <https://feross.org>\n * @license  MIT\n */\n\nmodule.exports = function isBuffer (obj) {\n  return obj != null && obj.constructor != null &&\n    typeof obj.constructor.isBuffer === 'function' && obj.constructor.isBuffer(obj)\n}\n","// Returns a wrapper function that returns a wrapped callback\n// The wrapper function should do some stuff, and return a\n// presumably different callback function.\n// This makes sure that own properties are retained, so that\n// decorations and such are not lost along the way.\nmodule.exports = wrappy\nfunction wrappy (fn, cb) {\n  if (fn && cb) return wrappy(fn)(cb)\n\n  if (typeof fn !== 'function')\n    throw new TypeError('need wrapper function')\n\n  Object.keys(fn).forEach(function (k) {\n    wrapper[k] = fn[k]\n  })\n\n  return wrapper\n\n  function wrapper() {\n    var args = new Array(arguments.length)\n    for (var i = 0; i < args.length; i++) {\n      args[i] = arguments[i]\n    }\n    var ret = fn.apply(this, args)\n    var cb = args[args.length-1]\n    if (typeof ret === 'function' && ret !== cb) {\n      Object.keys(cb).forEach(function (k) {\n        ret[k] = cb[k]\n      })\n    }\n    return ret\n  }\n}\n","'use strict';\n\nvar PlainValue = require('./PlainValue-ec8e588e.js');\nvar resolveSeq = require('./resolveSeq-4a68b39b.js');\nvar Schema = require('./Schema-42e9705c.js');\n\nconst defaultOptions = {\n  anchorPrefix: 'a',\n  customTags: null,\n  indent: 2,\n  indentSeq: true,\n  keepCstNodes: false,\n  keepNodeTypes: true,\n  keepBlobsInJSON: true,\n  mapAsMap: false,\n  maxAliasCount: 100,\n  prettyErrors: false,\n  // TODO Set true in v2\n  simpleKeys: false,\n  version: '1.2'\n};\nconst scalarOptions = {\n  get binary() {\n    return resolveSeq.binaryOptions;\n  },\n\n  set binary(opt) {\n    Object.assign(resolveSeq.binaryOptions, opt);\n  },\n\n  get bool() {\n    return resolveSeq.boolOptions;\n  },\n\n  set bool(opt) {\n    Object.assign(resolveSeq.boolOptions, opt);\n  },\n\n  get int() {\n    return resolveSeq.intOptions;\n  },\n\n  set int(opt) {\n    Object.assign(resolveSeq.intOptions, opt);\n  },\n\n  get null() {\n    return resolveSeq.nullOptions;\n  },\n\n  set null(opt) {\n    Object.assign(resolveSeq.nullOptions, opt);\n  },\n\n  get str() {\n    return resolveSeq.strOptions;\n  },\n\n  set str(opt) {\n    Object.assign(resolveSeq.strOptions, opt);\n  }\n\n};\nconst documentOptions = {\n  '1.0': {\n    schema: 'yaml-1.1',\n    merge: true,\n    tagPrefixes: [{\n      handle: '!',\n      prefix: PlainValue.defaultTagPrefix\n    }, {\n      handle: '!!',\n      prefix: 'tag:private.yaml.org,2002:'\n    }]\n  },\n  '1.1': {\n    schema: 'yaml-1.1',\n    merge: true,\n    tagPrefixes: [{\n      handle: '!',\n      prefix: '!'\n    }, {\n      handle: '!!',\n      prefix: PlainValue.defaultTagPrefix\n    }]\n  },\n  '1.2': {\n    schema: 'core',\n    merge: false,\n    tagPrefixes: [{\n      handle: '!',\n      prefix: '!'\n    }, {\n      handle: '!!',\n      prefix: PlainValue.defaultTagPrefix\n    }]\n  }\n};\n\nfunction stringifyTag(doc, tag) {\n  if ((doc.version || doc.options.version) === '1.0') {\n    const priv = tag.match(/^tag:private\\.yaml\\.org,2002:([^:/]+)$/);\n    if (priv) return '!' + priv[1];\n    const vocab = tag.match(/^tag:([a-zA-Z0-9-]+)\\.yaml\\.org,2002:(.*)/);\n    return vocab ? `!${vocab[1]}/${vocab[2]}` : `!${tag.replace(/^tag:/, '')}`;\n  }\n\n  let p = doc.tagPrefixes.find(p => tag.indexOf(p.prefix) === 0);\n\n  if (!p) {\n    const dtp = doc.getDefaults().tagPrefixes;\n    p = dtp && dtp.find(p => tag.indexOf(p.prefix) === 0);\n  }\n\n  if (!p) return tag[0] === '!' ? tag : `!<${tag}>`;\n  const suffix = tag.substr(p.prefix.length).replace(/[!,[\\]{}]/g, ch => ({\n    '!': '%21',\n    ',': '%2C',\n    '[': '%5B',\n    ']': '%5D',\n    '{': '%7B',\n    '}': '%7D'\n  })[ch]);\n  return p.handle + suffix;\n}\n\nfunction getTagObject(tags, item) {\n  if (item instanceof resolveSeq.Alias) return resolveSeq.Alias;\n\n  if (item.tag) {\n    const match = tags.filter(t => t.tag === item.tag);\n    if (match.length > 0) return match.find(t => t.format === item.format) || match[0];\n  }\n\n  let tagObj, obj;\n\n  if (item instanceof resolveSeq.Scalar) {\n    obj = item.value; // TODO: deprecate/remove class check\n\n    const match = tags.filter(t => t.identify && t.identify(obj) || t.class && obj instanceof t.class);\n    tagObj = match.find(t => t.format === item.format) || match.find(t => !t.format);\n  } else {\n    obj = item;\n    tagObj = tags.find(t => t.nodeClass && obj instanceof t.nodeClass);\n  }\n\n  if (!tagObj) {\n    const name = obj && obj.constructor ? obj.constructor.name : typeof obj;\n    throw new Error(`Tag not resolved for ${name} value`);\n  }\n\n  return tagObj;\n} // needs to be called before value stringifier to allow for circular anchor refs\n\n\nfunction stringifyProps(node, tagObj, {\n  anchors,\n  doc\n}) {\n  const props = [];\n  const anchor = doc.anchors.getName(node);\n\n  if (anchor) {\n    anchors[anchor] = node;\n    props.push(`&${anchor}`);\n  }\n\n  if (node.tag) {\n    props.push(stringifyTag(doc, node.tag));\n  } else if (!tagObj.default) {\n    props.push(stringifyTag(doc, tagObj.tag));\n  }\n\n  return props.join(' ');\n}\n\nfunction stringify(item, ctx, onComment, onChompKeep) {\n  const {\n    anchors,\n    schema\n  } = ctx.doc;\n  let tagObj;\n\n  if (!(item instanceof resolveSeq.Node)) {\n    const createCtx = {\n      aliasNodes: [],\n      onTagObj: o => tagObj = o,\n      prevObjects: new Map()\n    };\n    item = schema.createNode(item, true, null, createCtx);\n\n    for (const alias of createCtx.aliasNodes) {\n      alias.source = alias.source.node;\n      let name = anchors.getName(alias.source);\n\n      if (!name) {\n        name = anchors.newName();\n        anchors.map[name] = alias.source;\n      }\n    }\n  }\n\n  if (item instanceof resolveSeq.Pair) return item.toString(ctx, onComment, onChompKeep);\n  if (!tagObj) tagObj = getTagObject(schema.tags, item);\n  const props = stringifyProps(item, tagObj, ctx);\n  if (props.length > 0) ctx.indentAtStart = (ctx.indentAtStart || 0) + props.length + 1;\n  const str = typeof tagObj.stringify === 'function' ? tagObj.stringify(item, ctx, onComment, onChompKeep) : item instanceof resolveSeq.Scalar ? resolveSeq.stringifyString(item, ctx, onComment, onChompKeep) : item.toString(ctx, onComment, onChompKeep);\n  if (!props) return str;\n  return item instanceof resolveSeq.Scalar || str[0] === '{' || str[0] === '[' ? `${props} ${str}` : `${props}\\n${ctx.indent}${str}`;\n}\n\nclass Anchors {\n  static validAnchorNode(node) {\n    return node instanceof resolveSeq.Scalar || node instanceof resolveSeq.YAMLSeq || node instanceof resolveSeq.YAMLMap;\n  }\n\n  constructor(prefix) {\n    PlainValue._defineProperty(this, \"map\", {});\n\n    this.prefix = prefix;\n  }\n\n  createAlias(node, name) {\n    this.setAnchor(node, name);\n    return new resolveSeq.Alias(node);\n  }\n\n  createMergePair(...sources) {\n    const merge = new resolveSeq.Merge();\n    merge.value.items = sources.map(s => {\n      if (s instanceof resolveSeq.Alias) {\n        if (s.source instanceof resolveSeq.YAMLMap) return s;\n      } else if (s instanceof resolveSeq.YAMLMap) {\n        return this.createAlias(s);\n      }\n\n      throw new Error('Merge sources must be Map nodes or their Aliases');\n    });\n    return merge;\n  }\n\n  getName(node) {\n    const {\n      map\n    } = this;\n    return Object.keys(map).find(a => map[a] === node);\n  }\n\n  getNames() {\n    return Object.keys(this.map);\n  }\n\n  getNode(name) {\n    return this.map[name];\n  }\n\n  newName(prefix) {\n    if (!prefix) prefix = this.prefix;\n    const names = Object.keys(this.map);\n\n    for (let i = 1; true; ++i) {\n      const name = `${prefix}${i}`;\n      if (!names.includes(name)) return name;\n    }\n  } // During parsing, map & aliases contain CST nodes\n\n\n  resolveNodes() {\n    const {\n      map,\n      _cstAliases\n    } = this;\n    Object.keys(map).forEach(a => {\n      map[a] = map[a].resolved;\n    });\n\n    _cstAliases.forEach(a => {\n      a.source = a.source.resolved;\n    });\n\n    delete this._cstAliases;\n  }\n\n  setAnchor(node, name) {\n    if (node != null && !Anchors.validAnchorNode(node)) {\n      throw new Error('Anchors may only be set for Scalar, Seq and Map nodes');\n    }\n\n    if (name && /[\\x00-\\x19\\s,[\\]{}]/.test(name)) {\n      throw new Error('Anchor names must not contain whitespace or control characters');\n    }\n\n    const {\n      map\n    } = this;\n    const prev = node && Object.keys(map).find(a => map[a] === node);\n\n    if (prev) {\n      if (!name) {\n        return prev;\n      } else if (prev !== name) {\n        delete map[prev];\n        map[name] = node;\n      }\n    } else {\n      if (!name) {\n        if (!node) return null;\n        name = this.newName();\n      }\n\n      map[name] = node;\n    }\n\n    return name;\n  }\n\n}\n\nconst visit = (node, tags) => {\n  if (node && typeof node === 'object') {\n    const {\n      tag\n    } = node;\n\n    if (node instanceof resolveSeq.Collection) {\n      if (tag) tags[tag] = true;\n      node.items.forEach(n => visit(n, tags));\n    } else if (node instanceof resolveSeq.Pair) {\n      visit(node.key, tags);\n      visit(node.value, tags);\n    } else if (node instanceof resolveSeq.Scalar) {\n      if (tag) tags[tag] = true;\n    }\n  }\n\n  return tags;\n};\n\nconst listTagNames = node => Object.keys(visit(node, {}));\n\nfunction parseContents(doc, contents) {\n  const comments = {\n    before: [],\n    after: []\n  };\n  let body = undefined;\n  let spaceBefore = false;\n\n  for (const node of contents) {\n    if (node.valueRange) {\n      if (body !== undefined) {\n        const msg = 'Document contains trailing content not separated by a ... or --- line';\n        doc.errors.push(new PlainValue.YAMLSyntaxError(node, msg));\n        break;\n      }\n\n      const res = resolveSeq.resolveNode(doc, node);\n\n      if (spaceBefore) {\n        res.spaceBefore = true;\n        spaceBefore = false;\n      }\n\n      body = res;\n    } else if (node.comment !== null) {\n      const cc = body === undefined ? comments.before : comments.after;\n      cc.push(node.comment);\n    } else if (node.type === PlainValue.Type.BLANK_LINE) {\n      spaceBefore = true;\n\n      if (body === undefined && comments.before.length > 0 && !doc.commentBefore) {\n        // space-separated comments at start are parsed as document comments\n        doc.commentBefore = comments.before.join('\\n');\n        comments.before = [];\n      }\n    }\n  }\n\n  doc.contents = body || null;\n\n  if (!body) {\n    doc.comment = comments.before.concat(comments.after).join('\\n') || null;\n  } else {\n    const cb = comments.before.join('\\n');\n\n    if (cb) {\n      const cbNode = body instanceof resolveSeq.Collection && body.items[0] ? body.items[0] : body;\n      cbNode.commentBefore = cbNode.commentBefore ? `${cb}\\n${cbNode.commentBefore}` : cb;\n    }\n\n    doc.comment = comments.after.join('\\n') || null;\n  }\n}\n\nfunction resolveTagDirective({\n  tagPrefixes\n}, directive) {\n  const [handle, prefix] = directive.parameters;\n\n  if (!handle || !prefix) {\n    const msg = 'Insufficient parameters given for %TAG directive';\n    throw new PlainValue.YAMLSemanticError(directive, msg);\n  }\n\n  if (tagPrefixes.some(p => p.handle === handle)) {\n    const msg = 'The %TAG directive must only be given at most once per handle in the same document.';\n    throw new PlainValue.YAMLSemanticError(directive, msg);\n  }\n\n  return {\n    handle,\n    prefix\n  };\n}\n\nfunction resolveYamlDirective(doc, directive) {\n  let [version] = directive.parameters;\n  if (directive.name === 'YAML:1.0') version = '1.0';\n\n  if (!version) {\n    const msg = 'Insufficient parameters given for %YAML directive';\n    throw new PlainValue.YAMLSemanticError(directive, msg);\n  }\n\n  if (!documentOptions[version]) {\n    const v0 = doc.version || doc.options.version;\n    const msg = `Document will be parsed as YAML ${v0} rather than YAML ${version}`;\n    doc.warnings.push(new PlainValue.YAMLWarning(directive, msg));\n  }\n\n  return version;\n}\n\nfunction parseDirectives(doc, directives, prevDoc) {\n  const directiveComments = [];\n  let hasDirectives = false;\n\n  for (const directive of directives) {\n    const {\n      comment,\n      name\n    } = directive;\n\n    switch (name) {\n      case 'TAG':\n        try {\n          doc.tagPrefixes.push(resolveTagDirective(doc, directive));\n        } catch (error) {\n          doc.errors.push(error);\n        }\n\n        hasDirectives = true;\n        break;\n\n      case 'YAML':\n      case 'YAML:1.0':\n        if (doc.version) {\n          const msg = 'The %YAML directive must only be given at most once per document.';\n          doc.errors.push(new PlainValue.YAMLSemanticError(directive, msg));\n        }\n\n        try {\n          doc.version = resolveYamlDirective(doc, directive);\n        } catch (error) {\n          doc.errors.push(error);\n        }\n\n        hasDirectives = true;\n        break;\n\n      default:\n        if (name) {\n          const msg = `YAML only supports %TAG and %YAML directives, and not %${name}`;\n          doc.warnings.push(new PlainValue.YAMLWarning(directive, msg));\n        }\n\n    }\n\n    if (comment) directiveComments.push(comment);\n  }\n\n  if (prevDoc && !hasDirectives && '1.1' === (doc.version || prevDoc.version || doc.options.version)) {\n    const copyTagPrefix = ({\n      handle,\n      prefix\n    }) => ({\n      handle,\n      prefix\n    });\n\n    doc.tagPrefixes = prevDoc.tagPrefixes.map(copyTagPrefix);\n    doc.version = prevDoc.version;\n  }\n\n  doc.commentBefore = directiveComments.join('\\n') || null;\n}\n\nfunction assertCollection(contents) {\n  if (contents instanceof resolveSeq.Collection) return true;\n  throw new Error('Expected a YAML collection as document contents');\n}\n\nclass Document {\n  constructor(options) {\n    this.anchors = new Anchors(options.anchorPrefix);\n    this.commentBefore = null;\n    this.comment = null;\n    this.contents = null;\n    this.directivesEndMarker = null;\n    this.errors = [];\n    this.options = options;\n    this.schema = null;\n    this.tagPrefixes = [];\n    this.version = null;\n    this.warnings = [];\n  }\n\n  add(value) {\n    assertCollection(this.contents);\n    return this.contents.add(value);\n  }\n\n  addIn(path, value) {\n    assertCollection(this.contents);\n    this.contents.addIn(path, value);\n  }\n\n  delete(key) {\n    assertCollection(this.contents);\n    return this.contents.delete(key);\n  }\n\n  deleteIn(path) {\n    if (resolveSeq.isEmptyPath(path)) {\n      if (this.contents == null) return false;\n      this.contents = null;\n      return true;\n    }\n\n    assertCollection(this.contents);\n    return this.contents.deleteIn(path);\n  }\n\n  getDefaults() {\n    return Document.defaults[this.version] || Document.defaults[this.options.version] || {};\n  }\n\n  get(key, keepScalar) {\n    return this.contents instanceof resolveSeq.Collection ? this.contents.get(key, keepScalar) : undefined;\n  }\n\n  getIn(path, keepScalar) {\n    if (resolveSeq.isEmptyPath(path)) return !keepScalar && this.contents instanceof resolveSeq.Scalar ? this.contents.value : this.contents;\n    return this.contents instanceof resolveSeq.Collection ? this.contents.getIn(path, keepScalar) : undefined;\n  }\n\n  has(key) {\n    return this.contents instanceof resolveSeq.Collection ? this.contents.has(key) : false;\n  }\n\n  hasIn(path) {\n    if (resolveSeq.isEmptyPath(path)) return this.contents !== undefined;\n    return this.contents instanceof resolveSeq.Collection ? this.contents.hasIn(path) : false;\n  }\n\n  set(key, value) {\n    assertCollection(this.contents);\n    this.contents.set(key, value);\n  }\n\n  setIn(path, value) {\n    if (resolveSeq.isEmptyPath(path)) this.contents = value;else {\n      assertCollection(this.contents);\n      this.contents.setIn(path, value);\n    }\n  }\n\n  setSchema(id, customTags) {\n    if (!id && !customTags && this.schema) return;\n    if (typeof id === 'number') id = id.toFixed(1);\n\n    if (id === '1.0' || id === '1.1' || id === '1.2') {\n      if (this.version) this.version = id;else this.options.version = id;\n      delete this.options.schema;\n    } else if (id && typeof id === 'string') {\n      this.options.schema = id;\n    }\n\n    if (Array.isArray(customTags)) this.options.customTags = customTags;\n    const opt = Object.assign({}, this.getDefaults(), this.options);\n    this.schema = new Schema.Schema(opt);\n  }\n\n  parse(node, prevDoc) {\n    if (this.options.keepCstNodes) this.cstNode = node;\n    if (this.options.keepNodeTypes) this.type = 'DOCUMENT';\n    const {\n      directives = [],\n      contents = [],\n      directivesEndMarker,\n      error,\n      valueRange\n    } = node;\n\n    if (error) {\n      if (!error.source) error.source = this;\n      this.errors.push(error);\n    }\n\n    parseDirectives(this, directives, prevDoc);\n    if (directivesEndMarker) this.directivesEndMarker = true;\n    this.range = valueRange ? [valueRange.start, valueRange.end] : null;\n    this.setSchema();\n    this.anchors._cstAliases = [];\n    parseContents(this, contents);\n    this.anchors.resolveNodes();\n\n    if (this.options.prettyErrors) {\n      for (const error of this.errors) if (error instanceof PlainValue.YAMLError) error.makePretty();\n\n      for (const warn of this.warnings) if (warn instanceof PlainValue.YAMLError) warn.makePretty();\n    }\n\n    return this;\n  }\n\n  listNonDefaultTags() {\n    return listTagNames(this.contents).filter(t => t.indexOf(Schema.Schema.defaultPrefix) !== 0);\n  }\n\n  setTagPrefix(handle, prefix) {\n    if (handle[0] !== '!' || handle[handle.length - 1] !== '!') throw new Error('Handle must start and end with !');\n\n    if (prefix) {\n      const prev = this.tagPrefixes.find(p => p.handle === handle);\n      if (prev) prev.prefix = prefix;else this.tagPrefixes.push({\n        handle,\n        prefix\n      });\n    } else {\n      this.tagPrefixes = this.tagPrefixes.filter(p => p.handle !== handle);\n    }\n  }\n\n  toJSON(arg, onAnchor) {\n    const {\n      keepBlobsInJSON,\n      mapAsMap,\n      maxAliasCount\n    } = this.options;\n    const keep = keepBlobsInJSON && (typeof arg !== 'string' || !(this.contents instanceof resolveSeq.Scalar));\n    const ctx = {\n      doc: this,\n      indentStep: '  ',\n      keep,\n      mapAsMap: keep && !!mapAsMap,\n      maxAliasCount,\n      stringify // Requiring directly in Pair would create circular dependencies\n\n    };\n    const anchorNames = Object.keys(this.anchors.map);\n    if (anchorNames.length > 0) ctx.anchors = new Map(anchorNames.map(name => [this.anchors.map[name], {\n      alias: [],\n      aliasCount: 0,\n      count: 1\n    }]));\n    const res = resolveSeq.toJSON(this.contents, arg, ctx);\n    if (typeof onAnchor === 'function' && ctx.anchors) for (const {\n      count,\n      res\n    } of ctx.anchors.values()) onAnchor(res, count);\n    return res;\n  }\n\n  toString() {\n    if (this.errors.length > 0) throw new Error('Document with errors cannot be stringified');\n    const indentSize = this.options.indent;\n\n    if (!Number.isInteger(indentSize) || indentSize <= 0) {\n      const s = JSON.stringify(indentSize);\n      throw new Error(`\"indent\" option must be a positive integer, not ${s}`);\n    }\n\n    this.setSchema();\n    const lines = [];\n    let hasDirectives = false;\n\n    if (this.version) {\n      let vd = '%YAML 1.2';\n\n      if (this.schema.name === 'yaml-1.1') {\n        if (this.version === '1.0') vd = '%YAML:1.0';else if (this.version === '1.1') vd = '%YAML 1.1';\n      }\n\n      lines.push(vd);\n      hasDirectives = true;\n    }\n\n    const tagNames = this.listNonDefaultTags();\n    this.tagPrefixes.forEach(({\n      handle,\n      prefix\n    }) => {\n      if (tagNames.some(t => t.indexOf(prefix) === 0)) {\n        lines.push(`%TAG ${handle} ${prefix}`);\n        hasDirectives = true;\n      }\n    });\n    if (hasDirectives || this.directivesEndMarker) lines.push('---');\n\n    if (this.commentBefore) {\n      if (hasDirectives || !this.directivesEndMarker) lines.unshift('');\n      lines.unshift(this.commentBefore.replace(/^/gm, '#'));\n    }\n\n    const ctx = {\n      anchors: {},\n      doc: this,\n      indent: '',\n      indentStep: ' '.repeat(indentSize),\n      stringify // Requiring directly in nodes would create circular dependencies\n\n    };\n    let chompKeep = false;\n    let contentComment = null;\n\n    if (this.contents) {\n      if (this.contents instanceof resolveSeq.Node) {\n        if (this.contents.spaceBefore && (hasDirectives || this.directivesEndMarker)) lines.push('');\n        if (this.contents.commentBefore) lines.push(this.contents.commentBefore.replace(/^/gm, '#')); // top-level block scalars need to be indented if followed by a comment\n\n        ctx.forceBlockIndent = !!this.comment;\n        contentComment = this.contents.comment;\n      }\n\n      const onChompKeep = contentComment ? null : () => chompKeep = true;\n      const body = stringify(this.contents, ctx, () => contentComment = null, onChompKeep);\n      lines.push(resolveSeq.addComment(body, '', contentComment));\n    } else if (this.contents !== undefined) {\n      lines.push(stringify(this.contents, ctx));\n    }\n\n    if (this.comment) {\n      if ((!chompKeep || contentComment) && lines[lines.length - 1] !== '') lines.push('');\n      lines.push(this.comment.replace(/^/gm, '#'));\n    }\n\n    return lines.join('\\n') + '\\n';\n  }\n\n}\n\nPlainValue._defineProperty(Document, \"defaults\", documentOptions);\n\nexports.Document = Document;\nexports.defaultOptions = defaultOptions;\nexports.scalarOptions = scalarOptions;\n","'use strict';\n\nconst Char = {\n  ANCHOR: '&',\n  COMMENT: '#',\n  TAG: '!',\n  DIRECTIVES_END: '-',\n  DOCUMENT_END: '.'\n};\nconst Type = {\n  ALIAS: 'ALIAS',\n  BLANK_LINE: 'BLANK_LINE',\n  BLOCK_FOLDED: 'BLOCK_FOLDED',\n  BLOCK_LITERAL: 'BLOCK_LITERAL',\n  COMMENT: 'COMMENT',\n  DIRECTIVE: 'DIRECTIVE',\n  DOCUMENT: 'DOCUMENT',\n  FLOW_MAP: 'FLOW_MAP',\n  FLOW_SEQ: 'FLOW_SEQ',\n  MAP: 'MAP',\n  MAP_KEY: 'MAP_KEY',\n  MAP_VALUE: 'MAP_VALUE',\n  PLAIN: 'PLAIN',\n  QUOTE_DOUBLE: 'QUOTE_DOUBLE',\n  QUOTE_SINGLE: 'QUOTE_SINGLE',\n  SEQ: 'SEQ',\n  SEQ_ITEM: 'SEQ_ITEM'\n};\nconst defaultTagPrefix = 'tag:yaml.org,2002:';\nconst defaultTags = {\n  MAP: 'tag:yaml.org,2002:map',\n  SEQ: 'tag:yaml.org,2002:seq',\n  STR: 'tag:yaml.org,2002:str'\n};\n\nfunction findLineStarts(src) {\n  const ls = [0];\n  let offset = src.indexOf('\\n');\n\n  while (offset !== -1) {\n    offset += 1;\n    ls.push(offset);\n    offset = src.indexOf('\\n', offset);\n  }\n\n  return ls;\n}\n\nfunction getSrcInfo(cst) {\n  let lineStarts, src;\n\n  if (typeof cst === 'string') {\n    lineStarts = findLineStarts(cst);\n    src = cst;\n  } else {\n    if (Array.isArray(cst)) cst = cst[0];\n\n    if (cst && cst.context) {\n      if (!cst.lineStarts) cst.lineStarts = findLineStarts(cst.context.src);\n      lineStarts = cst.lineStarts;\n      src = cst.context.src;\n    }\n  }\n\n  return {\n    lineStarts,\n    src\n  };\n}\n/**\n * @typedef {Object} LinePos - One-indexed position in the source\n * @property {number} line\n * @property {number} col\n */\n\n/**\n * Determine the line/col position matching a character offset.\n *\n * Accepts a source string or a CST document as the second parameter. With\n * the latter, starting indices for lines are cached in the document as\n * `lineStarts: number[]`.\n *\n * Returns a one-indexed `{ line, col }` location if found, or\n * `undefined` otherwise.\n *\n * @param {number} offset\n * @param {string|Document|Document[]} cst\n * @returns {?LinePos}\n */\n\n\nfunction getLinePos(offset, cst) {\n  if (typeof offset !== 'number' || offset < 0) return null;\n  const {\n    lineStarts,\n    src\n  } = getSrcInfo(cst);\n  if (!lineStarts || !src || offset > src.length) return null;\n\n  for (let i = 0; i < lineStarts.length; ++i) {\n    const start = lineStarts[i];\n\n    if (offset < start) {\n      return {\n        line: i,\n        col: offset - lineStarts[i - 1] + 1\n      };\n    }\n\n    if (offset === start) return {\n      line: i + 1,\n      col: 1\n    };\n  }\n\n  const line = lineStarts.length;\n  return {\n    line,\n    col: offset - lineStarts[line - 1] + 1\n  };\n}\n/**\n * Get a specified line from the source.\n *\n * Accepts a source string or a CST document as the second parameter. With\n * the latter, starting indices for lines are cached in the document as\n * `lineStarts: number[]`.\n *\n * Returns the line as a string if found, or `null` otherwise.\n *\n * @param {number} line One-indexed line number\n * @param {string|Document|Document[]} cst\n * @returns {?string}\n */\n\nfunction getLine(line, cst) {\n  const {\n    lineStarts,\n    src\n  } = getSrcInfo(cst);\n  if (!lineStarts || !(line >= 1) || line > lineStarts.length) return null;\n  const start = lineStarts[line - 1];\n  let end = lineStarts[line]; // undefined for last line; that's ok for slice()\n\n  while (end && end > start && src[end - 1] === '\\n') --end;\n\n  return src.slice(start, end);\n}\n/**\n * Pretty-print the starting line from the source indicated by the range `pos`\n *\n * Trims output to `maxWidth` chars while keeping the starting column visible,\n * using `` at either end to indicate dropped characters.\n *\n * Returns a two-line string (or `null`) with `\\n` as separator; the second line\n * will hold appropriately indented `^` marks indicating the column range.\n *\n * @param {Object} pos\n * @param {LinePos} pos.start\n * @param {LinePos} [pos.end]\n * @param {string|Document|Document[]*} cst\n * @param {number} [maxWidth=80]\n * @returns {?string}\n */\n\nfunction getPrettyContext({\n  start,\n  end\n}, cst, maxWidth = 80) {\n  let src = getLine(start.line, cst);\n  if (!src) return null;\n  let {\n    col\n  } = start;\n\n  if (src.length > maxWidth) {\n    if (col <= maxWidth - 10) {\n      src = src.substr(0, maxWidth - 1) + '';\n    } else {\n      const halfWidth = Math.round(maxWidth / 2);\n      if (src.length > col + halfWidth) src = src.substr(0, col + halfWidth - 1) + '';\n      col -= src.length - maxWidth;\n      src = '' + src.substr(1 - maxWidth);\n    }\n  }\n\n  let errLen = 1;\n  let errEnd = '';\n\n  if (end) {\n    if (end.line === start.line && col + (end.col - start.col) <= maxWidth + 1) {\n      errLen = end.col - start.col;\n    } else {\n      errLen = Math.min(src.length + 1, maxWidth) - col;\n      errEnd = '';\n    }\n  }\n\n  const offset = col > 1 ? ' '.repeat(col - 1) : '';\n  const err = '^'.repeat(errLen);\n  return `${src}\\n${offset}${err}${errEnd}`;\n}\n\nclass Range {\n  static copy(orig) {\n    return new Range(orig.start, orig.end);\n  }\n\n  constructor(start, end) {\n    this.start = start;\n    this.end = end || start;\n  }\n\n  isEmpty() {\n    return typeof this.start !== 'number' || !this.end || this.end <= this.start;\n  }\n  /**\n   * Set `origStart` and `origEnd` to point to the original source range for\n   * this node, which may differ due to dropped CR characters.\n   *\n   * @param {number[]} cr - Positions of dropped CR characters\n   * @param {number} offset - Starting index of `cr` from the last call\n   * @returns {number} - The next offset, matching the one found for `origStart`\n   */\n\n\n  setOrigRange(cr, offset) {\n    const {\n      start,\n      end\n    } = this;\n\n    if (cr.length === 0 || end <= cr[0]) {\n      this.origStart = start;\n      this.origEnd = end;\n      return offset;\n    }\n\n    let i = offset;\n\n    while (i < cr.length) {\n      if (cr[i] > start) break;else ++i;\n    }\n\n    this.origStart = start + i;\n    const nextOffset = i;\n\n    while (i < cr.length) {\n      // if end was at \\n, it should now be at \\r\n      if (cr[i] >= end) break;else ++i;\n    }\n\n    this.origEnd = end + i;\n    return nextOffset;\n  }\n\n}\n\n/** Root class of all nodes */\n\nclass Node {\n  static addStringTerminator(src, offset, str) {\n    if (str[str.length - 1] === '\\n') return str;\n    const next = Node.endOfWhiteSpace(src, offset);\n    return next >= src.length || src[next] === '\\n' ? str + '\\n' : str;\n  } // ^(---|...)\n\n\n  static atDocumentBoundary(src, offset, sep) {\n    const ch0 = src[offset];\n    if (!ch0) return true;\n    const prev = src[offset - 1];\n    if (prev && prev !== '\\n') return false;\n\n    if (sep) {\n      if (ch0 !== sep) return false;\n    } else {\n      if (ch0 !== Char.DIRECTIVES_END && ch0 !== Char.DOCUMENT_END) return false;\n    }\n\n    const ch1 = src[offset + 1];\n    const ch2 = src[offset + 2];\n    if (ch1 !== ch0 || ch2 !== ch0) return false;\n    const ch3 = src[offset + 3];\n    return !ch3 || ch3 === '\\n' || ch3 === '\\t' || ch3 === ' ';\n  }\n\n  static endOfIdentifier(src, offset) {\n    let ch = src[offset];\n    const isVerbatim = ch === '<';\n    const notOk = isVerbatim ? ['\\n', '\\t', ' ', '>'] : ['\\n', '\\t', ' ', '[', ']', '{', '}', ','];\n\n    while (ch && notOk.indexOf(ch) === -1) ch = src[offset += 1];\n\n    if (isVerbatim && ch === '>') offset += 1;\n    return offset;\n  }\n\n  static endOfIndent(src, offset) {\n    let ch = src[offset];\n\n    while (ch === ' ') ch = src[offset += 1];\n\n    return offset;\n  }\n\n  static endOfLine(src, offset) {\n    let ch = src[offset];\n\n    while (ch && ch !== '\\n') ch = src[offset += 1];\n\n    return offset;\n  }\n\n  static endOfWhiteSpace(src, offset) {\n    let ch = src[offset];\n\n    while (ch === '\\t' || ch === ' ') ch = src[offset += 1];\n\n    return offset;\n  }\n\n  static startOfLine(src, offset) {\n    let ch = src[offset - 1];\n    if (ch === '\\n') return offset;\n\n    while (ch && ch !== '\\n') ch = src[offset -= 1];\n\n    return offset + 1;\n  }\n  /**\n   * End of indentation, or null if the line's indent level is not more\n   * than `indent`\n   *\n   * @param {string} src\n   * @param {number} indent\n   * @param {number} lineStart\n   * @returns {?number}\n   */\n\n\n  static endOfBlockIndent(src, indent, lineStart) {\n    const inEnd = Node.endOfIndent(src, lineStart);\n\n    if (inEnd > lineStart + indent) {\n      return inEnd;\n    } else {\n      const wsEnd = Node.endOfWhiteSpace(src, inEnd);\n      const ch = src[wsEnd];\n      if (!ch || ch === '\\n') return wsEnd;\n    }\n\n    return null;\n  }\n\n  static atBlank(src, offset, endAsBlank) {\n    const ch = src[offset];\n    return ch === '\\n' || ch === '\\t' || ch === ' ' || endAsBlank && !ch;\n  }\n\n  static nextNodeIsIndented(ch, indentDiff, indicatorAsIndent) {\n    if (!ch || indentDiff < 0) return false;\n    if (indentDiff > 0) return true;\n    return indicatorAsIndent && ch === '-';\n  } // should be at line or string end, or at next non-whitespace char\n\n\n  static normalizeOffset(src, offset) {\n    const ch = src[offset];\n    return !ch ? offset : ch !== '\\n' && src[offset - 1] === '\\n' ? offset - 1 : Node.endOfWhiteSpace(src, offset);\n  } // fold single newline into space, multiple newlines to N - 1 newlines\n  // presumes src[offset] === '\\n'\n\n\n  static foldNewline(src, offset, indent) {\n    let inCount = 0;\n    let error = false;\n    let fold = '';\n    let ch = src[offset + 1];\n\n    while (ch === ' ' || ch === '\\t' || ch === '\\n') {\n      switch (ch) {\n        case '\\n':\n          inCount = 0;\n          offset += 1;\n          fold += '\\n';\n          break;\n\n        case '\\t':\n          if (inCount <= indent) error = true;\n          offset = Node.endOfWhiteSpace(src, offset + 2) - 1;\n          break;\n\n        case ' ':\n          inCount += 1;\n          offset += 1;\n          break;\n      }\n\n      ch = src[offset + 1];\n    }\n\n    if (!fold) fold = ' ';\n    if (ch && inCount <= indent) error = true;\n    return {\n      fold,\n      offset,\n      error\n    };\n  }\n\n  constructor(type, props, context) {\n    Object.defineProperty(this, 'context', {\n      value: context || null,\n      writable: true\n    });\n    this.error = null;\n    this.range = null;\n    this.valueRange = null;\n    this.props = props || [];\n    this.type = type;\n    this.value = null;\n  }\n\n  getPropValue(idx, key, skipKey) {\n    if (!this.context) return null;\n    const {\n      src\n    } = this.context;\n    const prop = this.props[idx];\n    return prop && src[prop.start] === key ? src.slice(prop.start + (skipKey ? 1 : 0), prop.end) : null;\n  }\n\n  get anchor() {\n    for (let i = 0; i < this.props.length; ++i) {\n      const anchor = this.getPropValue(i, Char.ANCHOR, true);\n      if (anchor != null) return anchor;\n    }\n\n    return null;\n  }\n\n  get comment() {\n    const comments = [];\n\n    for (let i = 0; i < this.props.length; ++i) {\n      const comment = this.getPropValue(i, Char.COMMENT, true);\n      if (comment != null) comments.push(comment);\n    }\n\n    return comments.length > 0 ? comments.join('\\n') : null;\n  }\n\n  commentHasRequiredWhitespace(start) {\n    const {\n      src\n    } = this.context;\n    if (this.header && start === this.header.end) return false;\n    if (!this.valueRange) return false;\n    const {\n      end\n    } = this.valueRange;\n    return start !== end || Node.atBlank(src, end - 1);\n  }\n\n  get hasComment() {\n    if (this.context) {\n      const {\n        src\n      } = this.context;\n\n      for (let i = 0; i < this.props.length; ++i) {\n        if (src[this.props[i].start] === Char.COMMENT) return true;\n      }\n    }\n\n    return false;\n  }\n\n  get hasProps() {\n    if (this.context) {\n      const {\n        src\n      } = this.context;\n\n      for (let i = 0; i < this.props.length; ++i) {\n        if (src[this.props[i].start] !== Char.COMMENT) return true;\n      }\n    }\n\n    return false;\n  }\n\n  get includesTrailingLines() {\n    return false;\n  }\n\n  get jsonLike() {\n    const jsonLikeTypes = [Type.FLOW_MAP, Type.FLOW_SEQ, Type.QUOTE_DOUBLE, Type.QUOTE_SINGLE];\n    return jsonLikeTypes.indexOf(this.type) !== -1;\n  }\n\n  get rangeAsLinePos() {\n    if (!this.range || !this.context) return undefined;\n    const start = getLinePos(this.range.start, this.context.root);\n    if (!start) return undefined;\n    const end = getLinePos(this.range.end, this.context.root);\n    return {\n      start,\n      end\n    };\n  }\n\n  get rawValue() {\n    if (!this.valueRange || !this.context) return null;\n    const {\n      start,\n      end\n    } = this.valueRange;\n    return this.context.src.slice(start, end);\n  }\n\n  get tag() {\n    for (let i = 0; i < this.props.length; ++i) {\n      const tag = this.getPropValue(i, Char.TAG, false);\n\n      if (tag != null) {\n        if (tag[1] === '<') {\n          return {\n            verbatim: tag.slice(2, -1)\n          };\n        } else {\n          // eslint-disable-next-line no-unused-vars\n          const [_, handle, suffix] = tag.match(/^(.*!)([^!]*)$/);\n          return {\n            handle,\n            suffix\n          };\n        }\n      }\n    }\n\n    return null;\n  }\n\n  get valueRangeContainsNewline() {\n    if (!this.valueRange || !this.context) return false;\n    const {\n      start,\n      end\n    } = this.valueRange;\n    const {\n      src\n    } = this.context;\n\n    for (let i = start; i < end; ++i) {\n      if (src[i] === '\\n') return true;\n    }\n\n    return false;\n  }\n\n  parseComment(start) {\n    const {\n      src\n    } = this.context;\n\n    if (src[start] === Char.COMMENT) {\n      const end = Node.endOfLine(src, start + 1);\n      const commentRange = new Range(start, end);\n      this.props.push(commentRange);\n      return end;\n    }\n\n    return start;\n  }\n  /**\n   * Populates the `origStart` and `origEnd` values of all ranges for this\n   * node. Extended by child classes to handle descendant nodes.\n   *\n   * @param {number[]} cr - Positions of dropped CR characters\n   * @param {number} offset - Starting index of `cr` from the last call\n   * @returns {number} - The next offset, matching the one found for `origStart`\n   */\n\n\n  setOrigRanges(cr, offset) {\n    if (this.range) offset = this.range.setOrigRange(cr, offset);\n    if (this.valueRange) this.valueRange.setOrigRange(cr, offset);\n    this.props.forEach(prop => prop.setOrigRange(cr, offset));\n    return offset;\n  }\n\n  toString() {\n    const {\n      context: {\n        src\n      },\n      range,\n      value\n    } = this;\n    if (value != null) return value;\n    const str = src.slice(range.start, range.end);\n    return Node.addStringTerminator(src, range.end, str);\n  }\n\n}\n\nclass YAMLError extends Error {\n  constructor(name, source, message) {\n    if (!message || !(source instanceof Node)) throw new Error(`Invalid arguments for new ${name}`);\n    super();\n    this.name = name;\n    this.message = message;\n    this.source = source;\n  }\n\n  makePretty() {\n    if (!this.source) return;\n    this.nodeType = this.source.type;\n    const cst = this.source.context && this.source.context.root;\n\n    if (typeof this.offset === 'number') {\n      this.range = new Range(this.offset, this.offset + 1);\n      const start = cst && getLinePos(this.offset, cst);\n\n      if (start) {\n        const end = {\n          line: start.line,\n          col: start.col + 1\n        };\n        this.linePos = {\n          start,\n          end\n        };\n      }\n\n      delete this.offset;\n    } else {\n      this.range = this.source.range;\n      this.linePos = this.source.rangeAsLinePos;\n    }\n\n    if (this.linePos) {\n      const {\n        line,\n        col\n      } = this.linePos.start;\n      this.message += ` at line ${line}, column ${col}`;\n      const ctx = cst && getPrettyContext(this.linePos, cst);\n      if (ctx) this.message += `:\\n\\n${ctx}\\n`;\n    }\n\n    delete this.source;\n  }\n\n}\nclass YAMLReferenceError extends YAMLError {\n  constructor(source, message) {\n    super('YAMLReferenceError', source, message);\n  }\n\n}\nclass YAMLSemanticError extends YAMLError {\n  constructor(source, message) {\n    super('YAMLSemanticError', source, message);\n  }\n\n}\nclass YAMLSyntaxError extends YAMLError {\n  constructor(source, message) {\n    super('YAMLSyntaxError', source, message);\n  }\n\n}\nclass YAMLWarning extends YAMLError {\n  constructor(source, message) {\n    super('YAMLWarning', source, message);\n  }\n\n}\n\nfunction _defineProperty(obj, key, value) {\n  if (key in obj) {\n    Object.defineProperty(obj, key, {\n      value: value,\n      enumerable: true,\n      configurable: true,\n      writable: true\n    });\n  } else {\n    obj[key] = value;\n  }\n\n  return obj;\n}\n\nclass PlainValue extends Node {\n  static endOfLine(src, start, inFlow) {\n    let ch = src[start];\n    let offset = start;\n\n    while (ch && ch !== '\\n') {\n      if (inFlow && (ch === '[' || ch === ']' || ch === '{' || ch === '}' || ch === ',')) break;\n      const next = src[offset + 1];\n      if (ch === ':' && (!next || next === '\\n' || next === '\\t' || next === ' ' || inFlow && next === ',')) break;\n      if ((ch === ' ' || ch === '\\t') && next === '#') break;\n      offset += 1;\n      ch = next;\n    }\n\n    return offset;\n  }\n\n  get strValue() {\n    if (!this.valueRange || !this.context) return null;\n    let {\n      start,\n      end\n    } = this.valueRange;\n    const {\n      src\n    } = this.context;\n    let ch = src[end - 1];\n\n    while (start < end && (ch === '\\n' || ch === '\\t' || ch === ' ')) ch = src[--end - 1];\n\n    let str = '';\n\n    for (let i = start; i < end; ++i) {\n      const ch = src[i];\n\n      if (ch === '\\n') {\n        const {\n          fold,\n          offset\n        } = Node.foldNewline(src, i, -1);\n        str += fold;\n        i = offset;\n      } else if (ch === ' ' || ch === '\\t') {\n        // trim trailing whitespace\n        const wsStart = i;\n        let next = src[i + 1];\n\n        while (i < end && (next === ' ' || next === '\\t')) {\n          i += 1;\n          next = src[i + 1];\n        }\n\n        if (next !== '\\n') str += i > wsStart ? src.slice(wsStart, i + 1) : ch;\n      } else {\n        str += ch;\n      }\n    }\n\n    const ch0 = src[start];\n\n    switch (ch0) {\n      case '\\t':\n        {\n          const msg = 'Plain value cannot start with a tab character';\n          const errors = [new YAMLSemanticError(this, msg)];\n          return {\n            errors,\n            str\n          };\n        }\n\n      case '@':\n      case '`':\n        {\n          const msg = `Plain value cannot start with reserved character ${ch0}`;\n          const errors = [new YAMLSemanticError(this, msg)];\n          return {\n            errors,\n            str\n          };\n        }\n\n      default:\n        return str;\n    }\n  }\n\n  parseBlockValue(start) {\n    const {\n      indent,\n      inFlow,\n      src\n    } = this.context;\n    let offset = start;\n    let valueEnd = start;\n\n    for (let ch = src[offset]; ch === '\\n'; ch = src[offset]) {\n      if (Node.atDocumentBoundary(src, offset + 1)) break;\n      const end = Node.endOfBlockIndent(src, indent, offset + 1);\n      if (end === null || src[end] === '#') break;\n\n      if (src[end] === '\\n') {\n        offset = end;\n      } else {\n        valueEnd = PlainValue.endOfLine(src, end, inFlow);\n        offset = valueEnd;\n      }\n    }\n\n    if (this.valueRange.isEmpty()) this.valueRange.start = start;\n    this.valueRange.end = valueEnd;\n    return valueEnd;\n  }\n  /**\n   * Parses a plain value from the source\n   *\n   * Accepted forms are:\n   * ```\n   * #comment\n   *\n   * first line\n   *\n   * first line #comment\n   *\n   * first line\n   * block\n   * lines\n   *\n   * #comment\n   * block\n   * lines\n   * ```\n   * where block lines are empty or have an indent level greater than `indent`.\n   *\n   * @param {ParseContext} context\n   * @param {number} start - Index of first character\n   * @returns {number} - Index of the character after this scalar, may be `\\n`\n   */\n\n\n  parse(context, start) {\n    this.context = context;\n    const {\n      inFlow,\n      src\n    } = context;\n    let offset = start;\n    const ch = src[offset];\n\n    if (ch && ch !== '#' && ch !== '\\n') {\n      offset = PlainValue.endOfLine(src, start, inFlow);\n    }\n\n    this.valueRange = new Range(start, offset);\n    offset = Node.endOfWhiteSpace(src, offset);\n    offset = this.parseComment(offset);\n\n    if (!this.hasComment || this.valueRange.isEmpty()) {\n      offset = this.parseBlockValue(offset);\n    }\n\n    return offset;\n  }\n\n}\n\nexports.Char = Char;\nexports.Node = Node;\nexports.PlainValue = PlainValue;\nexports.Range = Range;\nexports.Type = Type;\nexports.YAMLError = YAMLError;\nexports.YAMLReferenceError = YAMLReferenceError;\nexports.YAMLSemanticError = YAMLSemanticError;\nexports.YAMLSyntaxError = YAMLSyntaxError;\nexports.YAMLWarning = YAMLWarning;\nexports._defineProperty = _defineProperty;\nexports.defaultTagPrefix = defaultTagPrefix;\nexports.defaultTags = defaultTags;\n","'use strict';\n\nvar PlainValue = require('./PlainValue-ec8e588e.js');\nvar resolveSeq = require('./resolveSeq-4a68b39b.js');\nvar warnings = require('./warnings-39684f17.js');\n\nfunction createMap(schema, obj, ctx) {\n  const map = new resolveSeq.YAMLMap(schema);\n\n  if (obj instanceof Map) {\n    for (const [key, value] of obj) map.items.push(schema.createPair(key, value, ctx));\n  } else if (obj && typeof obj === 'object') {\n    for (const key of Object.keys(obj)) map.items.push(schema.createPair(key, obj[key], ctx));\n  }\n\n  if (typeof schema.sortMapEntries === 'function') {\n    map.items.sort(schema.sortMapEntries);\n  }\n\n  return map;\n}\n\nconst map = {\n  createNode: createMap,\n  default: true,\n  nodeClass: resolveSeq.YAMLMap,\n  tag: 'tag:yaml.org,2002:map',\n  resolve: resolveSeq.resolveMap\n};\n\nfunction createSeq(schema, obj, ctx) {\n  const seq = new resolveSeq.YAMLSeq(schema);\n\n  if (obj && obj[Symbol.iterator]) {\n    for (const it of obj) {\n      const v = schema.createNode(it, ctx.wrapScalars, null, ctx);\n      seq.items.push(v);\n    }\n  }\n\n  return seq;\n}\n\nconst seq = {\n  createNode: createSeq,\n  default: true,\n  nodeClass: resolveSeq.YAMLSeq,\n  tag: 'tag:yaml.org,2002:seq',\n  resolve: resolveSeq.resolveSeq\n};\n\nconst string = {\n  identify: value => typeof value === 'string',\n  default: true,\n  tag: 'tag:yaml.org,2002:str',\n  resolve: resolveSeq.resolveString,\n\n  stringify(item, ctx, onComment, onChompKeep) {\n    ctx = Object.assign({\n      actualString: true\n    }, ctx);\n    return resolveSeq.stringifyString(item, ctx, onComment, onChompKeep);\n  },\n\n  options: resolveSeq.strOptions\n};\n\nconst failsafe = [map, seq, string];\n\n/* global BigInt */\n\nconst intIdentify = value => typeof value === 'bigint' || Number.isInteger(value);\n\nconst intResolve = (src, part, radix) => resolveSeq.intOptions.asBigInt ? BigInt(src) : parseInt(part, radix);\n\nfunction intStringify(node, radix, prefix) {\n  const {\n    value\n  } = node;\n  if (intIdentify(value) && value >= 0) return prefix + value.toString(radix);\n  return resolveSeq.stringifyNumber(node);\n}\n\nconst nullObj = {\n  identify: value => value == null,\n  createNode: (schema, value, ctx) => ctx.wrapScalars ? new resolveSeq.Scalar(null) : null,\n  default: true,\n  tag: 'tag:yaml.org,2002:null',\n  test: /^(?:~|[Nn]ull|NULL)?$/,\n  resolve: () => null,\n  options: resolveSeq.nullOptions,\n  stringify: () => resolveSeq.nullOptions.nullStr\n};\nconst boolObj = {\n  identify: value => typeof value === 'boolean',\n  default: true,\n  tag: 'tag:yaml.org,2002:bool',\n  test: /^(?:[Tt]rue|TRUE|[Ff]alse|FALSE)$/,\n  resolve: str => str[0] === 't' || str[0] === 'T',\n  options: resolveSeq.boolOptions,\n  stringify: ({\n    value\n  }) => value ? resolveSeq.boolOptions.trueStr : resolveSeq.boolOptions.falseStr\n};\nconst octObj = {\n  identify: value => intIdentify(value) && value >= 0,\n  default: true,\n  tag: 'tag:yaml.org,2002:int',\n  format: 'OCT',\n  test: /^0o([0-7]+)$/,\n  resolve: (str, oct) => intResolve(str, oct, 8),\n  options: resolveSeq.intOptions,\n  stringify: node => intStringify(node, 8, '0o')\n};\nconst intObj = {\n  identify: intIdentify,\n  default: true,\n  tag: 'tag:yaml.org,2002:int',\n  test: /^[-+]?[0-9]+$/,\n  resolve: str => intResolve(str, str, 10),\n  options: resolveSeq.intOptions,\n  stringify: resolveSeq.stringifyNumber\n};\nconst hexObj = {\n  identify: value => intIdentify(value) && value >= 0,\n  default: true,\n  tag: 'tag:yaml.org,2002:int',\n  format: 'HEX',\n  test: /^0x([0-9a-fA-F]+)$/,\n  resolve: (str, hex) => intResolve(str, hex, 16),\n  options: resolveSeq.intOptions,\n  stringify: node => intStringify(node, 16, '0x')\n};\nconst nanObj = {\n  identify: value => typeof value === 'number',\n  default: true,\n  tag: 'tag:yaml.org,2002:float',\n  test: /^(?:[-+]?\\.inf|(\\.nan))$/i,\n  resolve: (str, nan) => nan ? NaN : str[0] === '-' ? Number.NEGATIVE_INFINITY : Number.POSITIVE_INFINITY,\n  stringify: resolveSeq.stringifyNumber\n};\nconst expObj = {\n  identify: value => typeof value === 'number',\n  default: true,\n  tag: 'tag:yaml.org,2002:float',\n  format: 'EXP',\n  test: /^[-+]?(?:\\.[0-9]+|[0-9]+(?:\\.[0-9]*)?)[eE][-+]?[0-9]+$/,\n  resolve: str => parseFloat(str),\n  stringify: ({\n    value\n  }) => Number(value).toExponential()\n};\nconst floatObj = {\n  identify: value => typeof value === 'number',\n  default: true,\n  tag: 'tag:yaml.org,2002:float',\n  test: /^[-+]?(?:\\.([0-9]+)|[0-9]+\\.([0-9]*))$/,\n\n  resolve(str, frac1, frac2) {\n    const frac = frac1 || frac2;\n    const node = new resolveSeq.Scalar(parseFloat(str));\n    if (frac && frac[frac.length - 1] === '0') node.minFractionDigits = frac.length;\n    return node;\n  },\n\n  stringify: resolveSeq.stringifyNumber\n};\nconst core = failsafe.concat([nullObj, boolObj, octObj, intObj, hexObj, nanObj, expObj, floatObj]);\n\n/* global BigInt */\n\nconst intIdentify$1 = value => typeof value === 'bigint' || Number.isInteger(value);\n\nconst stringifyJSON = ({\n  value\n}) => JSON.stringify(value);\n\nconst json = [map, seq, {\n  identify: value => typeof value === 'string',\n  default: true,\n  tag: 'tag:yaml.org,2002:str',\n  resolve: resolveSeq.resolveString,\n  stringify: stringifyJSON\n}, {\n  identify: value => value == null,\n  createNode: (schema, value, ctx) => ctx.wrapScalars ? new resolveSeq.Scalar(null) : null,\n  default: true,\n  tag: 'tag:yaml.org,2002:null',\n  test: /^null$/,\n  resolve: () => null,\n  stringify: stringifyJSON\n}, {\n  identify: value => typeof value === 'boolean',\n  default: true,\n  tag: 'tag:yaml.org,2002:bool',\n  test: /^true|false$/,\n  resolve: str => str === 'true',\n  stringify: stringifyJSON\n}, {\n  identify: intIdentify$1,\n  default: true,\n  tag: 'tag:yaml.org,2002:int',\n  test: /^-?(?:0|[1-9][0-9]*)$/,\n  resolve: str => resolveSeq.intOptions.asBigInt ? BigInt(str) : parseInt(str, 10),\n  stringify: ({\n    value\n  }) => intIdentify$1(value) ? value.toString() : JSON.stringify(value)\n}, {\n  identify: value => typeof value === 'number',\n  default: true,\n  tag: 'tag:yaml.org,2002:float',\n  test: /^-?(?:0|[1-9][0-9]*)(?:\\.[0-9]*)?(?:[eE][-+]?[0-9]+)?$/,\n  resolve: str => parseFloat(str),\n  stringify: stringifyJSON\n}];\n\njson.scalarFallback = str => {\n  throw new SyntaxError(`Unresolved plain scalar ${JSON.stringify(str)}`);\n};\n\n/* global BigInt */\n\nconst boolStringify = ({\n  value\n}) => value ? resolveSeq.boolOptions.trueStr : resolveSeq.boolOptions.falseStr;\n\nconst intIdentify$2 = value => typeof value === 'bigint' || Number.isInteger(value);\n\nfunction intResolve$1(sign, src, radix) {\n  let str = src.replace(/_/g, '');\n\n  if (resolveSeq.intOptions.asBigInt) {\n    switch (radix) {\n      case 2:\n        str = `0b${str}`;\n        break;\n\n      case 8:\n        str = `0o${str}`;\n        break;\n\n      case 16:\n        str = `0x${str}`;\n        break;\n    }\n\n    const n = BigInt(str);\n    return sign === '-' ? BigInt(-1) * n : n;\n  }\n\n  const n = parseInt(str, radix);\n  return sign === '-' ? -1 * n : n;\n}\n\nfunction intStringify$1(node, radix, prefix) {\n  const {\n    value\n  } = node;\n\n  if (intIdentify$2(value)) {\n    const str = value.toString(radix);\n    return value < 0 ? '-' + prefix + str.substr(1) : prefix + str;\n  }\n\n  return resolveSeq.stringifyNumber(node);\n}\n\nconst yaml11 = failsafe.concat([{\n  identify: value => value == null,\n  createNode: (schema, value, ctx) => ctx.wrapScalars ? new resolveSeq.Scalar(null) : null,\n  default: true,\n  tag: 'tag:yaml.org,2002:null',\n  test: /^(?:~|[Nn]ull|NULL)?$/,\n  resolve: () => null,\n  options: resolveSeq.nullOptions,\n  stringify: () => resolveSeq.nullOptions.nullStr\n}, {\n  identify: value => typeof value === 'boolean',\n  default: true,\n  tag: 'tag:yaml.org,2002:bool',\n  test: /^(?:Y|y|[Yy]es|YES|[Tt]rue|TRUE|[Oo]n|ON)$/,\n  resolve: () => true,\n  options: resolveSeq.boolOptions,\n  stringify: boolStringify\n}, {\n  identify: value => typeof value === 'boolean',\n  default: true,\n  tag: 'tag:yaml.org,2002:bool',\n  test: /^(?:N|n|[Nn]o|NO|[Ff]alse|FALSE|[Oo]ff|OFF)$/i,\n  resolve: () => false,\n  options: resolveSeq.boolOptions,\n  stringify: boolStringify\n}, {\n  identify: intIdentify$2,\n  default: true,\n  tag: 'tag:yaml.org,2002:int',\n  format: 'BIN',\n  test: /^([-+]?)0b([0-1_]+)$/,\n  resolve: (str, sign, bin) => intResolve$1(sign, bin, 2),\n  stringify: node => intStringify$1(node, 2, '0b')\n}, {\n  identify: intIdentify$2,\n  default: true,\n  tag: 'tag:yaml.org,2002:int',\n  format: 'OCT',\n  test: /^([-+]?)0([0-7_]+)$/,\n  resolve: (str, sign, oct) => intResolve$1(sign, oct, 8),\n  stringify: node => intStringify$1(node, 8, '0')\n}, {\n  identify: intIdentify$2,\n  default: true,\n  tag: 'tag:yaml.org,2002:int',\n  test: /^([-+]?)([0-9][0-9_]*)$/,\n  resolve: (str, sign, abs) => intResolve$1(sign, abs, 10),\n  stringify: resolveSeq.stringifyNumber\n}, {\n  identify: intIdentify$2,\n  default: true,\n  tag: 'tag:yaml.org,2002:int',\n  format: 'HEX',\n  test: /^([-+]?)0x([0-9a-fA-F_]+)$/,\n  resolve: (str, sign, hex) => intResolve$1(sign, hex, 16),\n  stringify: node => intStringify$1(node, 16, '0x')\n}, {\n  identify: value => typeof value === 'number',\n  default: true,\n  tag: 'tag:yaml.org,2002:float',\n  test: /^(?:[-+]?\\.inf|(\\.nan))$/i,\n  resolve: (str, nan) => nan ? NaN : str[0] === '-' ? Number.NEGATIVE_INFINITY : Number.POSITIVE_INFINITY,\n  stringify: resolveSeq.stringifyNumber\n}, {\n  identify: value => typeof value === 'number',\n  default: true,\n  tag: 'tag:yaml.org,2002:float',\n  format: 'EXP',\n  test: /^[-+]?([0-9][0-9_]*)?(\\.[0-9_]*)?[eE][-+]?[0-9]+$/,\n  resolve: str => parseFloat(str.replace(/_/g, '')),\n  stringify: ({\n    value\n  }) => Number(value).toExponential()\n}, {\n  identify: value => typeof value === 'number',\n  default: true,\n  tag: 'tag:yaml.org,2002:float',\n  test: /^[-+]?(?:[0-9][0-9_]*)?\\.([0-9_]*)$/,\n\n  resolve(str, frac) {\n    const node = new resolveSeq.Scalar(parseFloat(str.replace(/_/g, '')));\n\n    if (frac) {\n      const f = frac.replace(/_/g, '');\n      if (f[f.length - 1] === '0') node.minFractionDigits = f.length;\n    }\n\n    return node;\n  },\n\n  stringify: resolveSeq.stringifyNumber\n}], warnings.binary, warnings.omap, warnings.pairs, warnings.set, warnings.intTime, warnings.floatTime, warnings.timestamp);\n\nconst schemas = {\n  core,\n  failsafe,\n  json,\n  yaml11\n};\nconst tags = {\n  binary: warnings.binary,\n  bool: boolObj,\n  float: floatObj,\n  floatExp: expObj,\n  floatNaN: nanObj,\n  floatTime: warnings.floatTime,\n  int: intObj,\n  intHex: hexObj,\n  intOct: octObj,\n  intTime: warnings.intTime,\n  map,\n  null: nullObj,\n  omap: warnings.omap,\n  pairs: warnings.pairs,\n  seq,\n  set: warnings.set,\n  timestamp: warnings.timestamp\n};\n\nfunction findTagObject(value, tagName, tags) {\n  if (tagName) {\n    const match = tags.filter(t => t.tag === tagName);\n    const tagObj = match.find(t => !t.format) || match[0];\n    if (!tagObj) throw new Error(`Tag ${tagName} not found`);\n    return tagObj;\n  } // TODO: deprecate/remove class check\n\n\n  return tags.find(t => (t.identify && t.identify(value) || t.class && value instanceof t.class) && !t.format);\n}\n\nfunction createNode(value, tagName, ctx) {\n  if (value instanceof resolveSeq.Node) return value;\n  const {\n    defaultPrefix,\n    onTagObj,\n    prevObjects,\n    schema,\n    wrapScalars\n  } = ctx;\n  if (tagName && tagName.startsWith('!!')) tagName = defaultPrefix + tagName.slice(2);\n  let tagObj = findTagObject(value, tagName, schema.tags);\n\n  if (!tagObj) {\n    if (typeof value.toJSON === 'function') value = value.toJSON();\n    if (typeof value !== 'object') return wrapScalars ? new resolveSeq.Scalar(value) : value;\n    tagObj = value instanceof Map ? map : value[Symbol.iterator] ? seq : map;\n  }\n\n  if (onTagObj) {\n    onTagObj(tagObj);\n    delete ctx.onTagObj;\n  } // Detect duplicate references to the same object & use Alias nodes for all\n  // after first. The `obj` wrapper allows for circular references to resolve.\n\n\n  const obj = {};\n\n  if (value && typeof value === 'object' && prevObjects) {\n    const prev = prevObjects.get(value);\n\n    if (prev) {\n      const alias = new resolveSeq.Alias(prev); // leaves source dirty; must be cleaned by caller\n\n      ctx.aliasNodes.push(alias); // defined along with prevObjects\n\n      return alias;\n    }\n\n    obj.value = value;\n    prevObjects.set(value, obj);\n  }\n\n  obj.node = tagObj.createNode ? tagObj.createNode(ctx.schema, value, ctx) : wrapScalars ? new resolveSeq.Scalar(value) : value;\n  if (tagName && obj.node instanceof resolveSeq.Node) obj.node.tag = tagName;\n  return obj.node;\n}\n\nfunction getSchemaTags(schemas, knownTags, customTags, schemaId) {\n  let tags = schemas[schemaId.replace(/\\W/g, '')]; // 'yaml-1.1' -> 'yaml11'\n\n  if (!tags) {\n    const keys = Object.keys(schemas).map(key => JSON.stringify(key)).join(', ');\n    throw new Error(`Unknown schema \"${schemaId}\"; use one of ${keys}`);\n  }\n\n  if (Array.isArray(customTags)) {\n    for (const tag of customTags) tags = tags.concat(tag);\n  } else if (typeof customTags === 'function') {\n    tags = customTags(tags.slice());\n  }\n\n  for (let i = 0; i < tags.length; ++i) {\n    const tag = tags[i];\n\n    if (typeof tag === 'string') {\n      const tagObj = knownTags[tag];\n\n      if (!tagObj) {\n        const keys = Object.keys(knownTags).map(key => JSON.stringify(key)).join(', ');\n        throw new Error(`Unknown custom tag \"${tag}\"; use one of ${keys}`);\n      }\n\n      tags[i] = tagObj;\n    }\n  }\n\n  return tags;\n}\n\nconst sortMapEntriesByKey = (a, b) => a.key < b.key ? -1 : a.key > b.key ? 1 : 0;\n\nclass Schema {\n  // TODO: remove in v2\n  // TODO: remove in v2\n  constructor({\n    customTags,\n    merge,\n    schema,\n    sortMapEntries,\n    tags: deprecatedCustomTags\n  }) {\n    this.merge = !!merge;\n    this.name = schema;\n    this.sortMapEntries = sortMapEntries === true ? sortMapEntriesByKey : sortMapEntries || null;\n    if (!customTags && deprecatedCustomTags) warnings.warnOptionDeprecation('tags', 'customTags');\n    this.tags = getSchemaTags(schemas, tags, customTags || deprecatedCustomTags, schema);\n  }\n\n  createNode(value, wrapScalars, tagName, ctx) {\n    const baseCtx = {\n      defaultPrefix: Schema.defaultPrefix,\n      schema: this,\n      wrapScalars\n    };\n    const createCtx = ctx ? Object.assign(ctx, baseCtx) : baseCtx;\n    return createNode(value, tagName, createCtx);\n  }\n\n  createPair(key, value, ctx) {\n    if (!ctx) ctx = {\n      wrapScalars: true\n    };\n    const k = this.createNode(key, ctx.wrapScalars, null, ctx);\n    const v = this.createNode(value, ctx.wrapScalars, null, ctx);\n    return new resolveSeq.Pair(k, v);\n  }\n\n}\n\nPlainValue._defineProperty(Schema, \"defaultPrefix\", PlainValue.defaultTagPrefix);\n\nPlainValue._defineProperty(Schema, \"defaultTags\", PlainValue.defaultTags);\n\nexports.Schema = Schema;\n","'use strict';\n\nvar PlainValue = require('./PlainValue-ec8e588e.js');\nvar parseCst = require('./parse-cst.js');\nrequire('./resolveSeq-4a68b39b.js');\nvar Document$1 = require('./Document-2cf6b08c.js');\nvar Schema = require('./Schema-42e9705c.js');\nvar warnings = require('./warnings-39684f17.js');\n\nfunction createNode(value, wrapScalars = true, tag) {\n  if (tag === undefined && typeof wrapScalars === 'string') {\n    tag = wrapScalars;\n    wrapScalars = true;\n  }\n\n  const options = Object.assign({}, Document$1.Document.defaults[Document$1.defaultOptions.version], Document$1.defaultOptions);\n  const schema = new Schema.Schema(options);\n  return schema.createNode(value, wrapScalars, tag);\n}\n\nclass Document extends Document$1.Document {\n  constructor(options) {\n    super(Object.assign({}, Document$1.defaultOptions, options));\n  }\n\n}\n\nfunction parseAllDocuments(src, options) {\n  const stream = [];\n  let prev;\n\n  for (const cstDoc of parseCst.parse(src)) {\n    const doc = new Document(options);\n    doc.parse(cstDoc, prev);\n    stream.push(doc);\n    prev = doc;\n  }\n\n  return stream;\n}\n\nfunction parseDocument(src, options) {\n  const cst = parseCst.parse(src);\n  const doc = new Document(options).parse(cst[0]);\n\n  if (cst.length > 1) {\n    const errMsg = 'Source contains multiple documents; please use YAML.parseAllDocuments()';\n    doc.errors.unshift(new PlainValue.YAMLSemanticError(cst[1], errMsg));\n  }\n\n  return doc;\n}\n\nfunction parse(src, options) {\n  const doc = parseDocument(src, options);\n  doc.warnings.forEach(warning => warnings.warn(warning));\n  if (doc.errors.length > 0) throw doc.errors[0];\n  return doc.toJSON();\n}\n\nfunction stringify(value, options) {\n  const doc = new Document(options);\n  doc.contents = value;\n  return String(doc);\n}\n\nconst YAML = {\n  createNode,\n  defaultOptions: Document$1.defaultOptions,\n  Document,\n  parse,\n  parseAllDocuments,\n  parseCST: parseCst.parse,\n  parseDocument,\n  scalarOptions: Document$1.scalarOptions,\n  stringify\n};\n\nexports.YAML = YAML;\n","'use strict';\n\nvar PlainValue = require('./PlainValue-ec8e588e.js');\n\nclass BlankLine extends PlainValue.Node {\n  constructor() {\n    super(PlainValue.Type.BLANK_LINE);\n  }\n  /* istanbul ignore next */\n\n\n  get includesTrailingLines() {\n    // This is never called from anywhere, but if it were,\n    // this is the value it should return.\n    return true;\n  }\n  /**\n   * Parses a blank line from the source\n   *\n   * @param {ParseContext} context\n   * @param {number} start - Index of first \\n character\n   * @returns {number} - Index of the character after this\n   */\n\n\n  parse(context, start) {\n    this.context = context;\n    this.range = new PlainValue.Range(start, start + 1);\n    return start + 1;\n  }\n\n}\n\nclass CollectionItem extends PlainValue.Node {\n  constructor(type, props) {\n    super(type, props);\n    this.node = null;\n  }\n\n  get includesTrailingLines() {\n    return !!this.node && this.node.includesTrailingLines;\n  }\n  /**\n   * @param {ParseContext} context\n   * @param {number} start - Index of first character\n   * @returns {number} - Index of the character after this\n   */\n\n\n  parse(context, start) {\n    this.context = context;\n    const {\n      parseNode,\n      src\n    } = context;\n    let {\n      atLineStart,\n      lineStart\n    } = context;\n    if (!atLineStart && this.type === PlainValue.Type.SEQ_ITEM) this.error = new PlainValue.YAMLSemanticError(this, 'Sequence items must not have preceding content on the same line');\n    const indent = atLineStart ? start - lineStart : context.indent;\n    let offset = PlainValue.Node.endOfWhiteSpace(src, start + 1);\n    let ch = src[offset];\n    const inlineComment = ch === '#';\n    const comments = [];\n    let blankLine = null;\n\n    while (ch === '\\n' || ch === '#') {\n      if (ch === '#') {\n        const end = PlainValue.Node.endOfLine(src, offset + 1);\n        comments.push(new PlainValue.Range(offset, end));\n        offset = end;\n      } else {\n        atLineStart = true;\n        lineStart = offset + 1;\n        const wsEnd = PlainValue.Node.endOfWhiteSpace(src, lineStart);\n\n        if (src[wsEnd] === '\\n' && comments.length === 0) {\n          blankLine = new BlankLine();\n          lineStart = blankLine.parse({\n            src\n          }, lineStart);\n        }\n\n        offset = PlainValue.Node.endOfIndent(src, lineStart);\n      }\n\n      ch = src[offset];\n    }\n\n    if (PlainValue.Node.nextNodeIsIndented(ch, offset - (lineStart + indent), this.type !== PlainValue.Type.SEQ_ITEM)) {\n      this.node = parseNode({\n        atLineStart,\n        inCollection: false,\n        indent,\n        lineStart,\n        parent: this\n      }, offset);\n    } else if (ch && lineStart > start + 1) {\n      offset = lineStart - 1;\n    }\n\n    if (this.node) {\n      if (blankLine) {\n        // Only blank lines preceding non-empty nodes are captured. Note that\n        // this means that collection item range start indices do not always\n        // increase monotonically. -- eemeli/yaml#126\n        const items = context.parent.items || context.parent.contents;\n        if (items) items.push(blankLine);\n      }\n\n      if (comments.length) Array.prototype.push.apply(this.props, comments);\n      offset = this.node.range.end;\n    } else {\n      if (inlineComment) {\n        const c = comments[0];\n        this.props.push(c);\n        offset = c.end;\n      } else {\n        offset = PlainValue.Node.endOfLine(src, start + 1);\n      }\n    }\n\n    const end = this.node ? this.node.valueRange.end : offset;\n    this.valueRange = new PlainValue.Range(start, end);\n    return offset;\n  }\n\n  setOrigRanges(cr, offset) {\n    offset = super.setOrigRanges(cr, offset);\n    return this.node ? this.node.setOrigRanges(cr, offset) : offset;\n  }\n\n  toString() {\n    const {\n      context: {\n        src\n      },\n      node,\n      range,\n      value\n    } = this;\n    if (value != null) return value;\n    const str = node ? src.slice(range.start, node.range.start) + String(node) : src.slice(range.start, range.end);\n    return PlainValue.Node.addStringTerminator(src, range.end, str);\n  }\n\n}\n\nclass Comment extends PlainValue.Node {\n  constructor() {\n    super(PlainValue.Type.COMMENT);\n  }\n  /**\n   * Parses a comment line from the source\n   *\n   * @param {ParseContext} context\n   * @param {number} start - Index of first character\n   * @returns {number} - Index of the character after this scalar\n   */\n\n\n  parse(context, start) {\n    this.context = context;\n    const offset = this.parseComment(start);\n    this.range = new PlainValue.Range(start, offset);\n    return offset;\n  }\n\n}\n\nfunction grabCollectionEndComments(node) {\n  let cnode = node;\n\n  while (cnode instanceof CollectionItem) cnode = cnode.node;\n\n  if (!(cnode instanceof Collection)) return null;\n  const len = cnode.items.length;\n  let ci = -1;\n\n  for (let i = len - 1; i >= 0; --i) {\n    const n = cnode.items[i];\n\n    if (n.type === PlainValue.Type.COMMENT) {\n      // Keep sufficiently indented comments with preceding node\n      const {\n        indent,\n        lineStart\n      } = n.context;\n      if (indent > 0 && n.range.start >= lineStart + indent) break;\n      ci = i;\n    } else if (n.type === PlainValue.Type.BLANK_LINE) ci = i;else break;\n  }\n\n  if (ci === -1) return null;\n  const ca = cnode.items.splice(ci, len - ci);\n  const prevEnd = ca[0].range.start;\n\n  while (true) {\n    cnode.range.end = prevEnd;\n    if (cnode.valueRange && cnode.valueRange.end > prevEnd) cnode.valueRange.end = prevEnd;\n    if (cnode === node) break;\n    cnode = cnode.context.parent;\n  }\n\n  return ca;\n}\nclass Collection extends PlainValue.Node {\n  static nextContentHasIndent(src, offset, indent) {\n    const lineStart = PlainValue.Node.endOfLine(src, offset) + 1;\n    offset = PlainValue.Node.endOfWhiteSpace(src, lineStart);\n    const ch = src[offset];\n    if (!ch) return false;\n    if (offset >= lineStart + indent) return true;\n    if (ch !== '#' && ch !== '\\n') return false;\n    return Collection.nextContentHasIndent(src, offset, indent);\n  }\n\n  constructor(firstItem) {\n    super(firstItem.type === PlainValue.Type.SEQ_ITEM ? PlainValue.Type.SEQ : PlainValue.Type.MAP);\n\n    for (let i = firstItem.props.length - 1; i >= 0; --i) {\n      if (firstItem.props[i].start < firstItem.context.lineStart) {\n        // props on previous line are assumed by the collection\n        this.props = firstItem.props.slice(0, i + 1);\n        firstItem.props = firstItem.props.slice(i + 1);\n        const itemRange = firstItem.props[0] || firstItem.valueRange;\n        firstItem.range.start = itemRange.start;\n        break;\n      }\n    }\n\n    this.items = [firstItem];\n    const ec = grabCollectionEndComments(firstItem);\n    if (ec) Array.prototype.push.apply(this.items, ec);\n  }\n\n  get includesTrailingLines() {\n    return this.items.length > 0;\n  }\n  /**\n   * @param {ParseContext} context\n   * @param {number} start - Index of first character\n   * @returns {number} - Index of the character after this\n   */\n\n\n  parse(context, start) {\n    this.context = context;\n    const {\n      parseNode,\n      src\n    } = context; // It's easier to recalculate lineStart here rather than tracking down the\n    // last context from which to read it -- eemeli/yaml#2\n\n    let lineStart = PlainValue.Node.startOfLine(src, start);\n    const firstItem = this.items[0]; // First-item context needs to be correct for later comment handling\n    // -- eemeli/yaml#17\n\n    firstItem.context.parent = this;\n    this.valueRange = PlainValue.Range.copy(firstItem.valueRange);\n    const indent = firstItem.range.start - firstItem.context.lineStart;\n    let offset = start;\n    offset = PlainValue.Node.normalizeOffset(src, offset);\n    let ch = src[offset];\n    let atLineStart = PlainValue.Node.endOfWhiteSpace(src, lineStart) === offset;\n    let prevIncludesTrailingLines = false;\n\n    while (ch) {\n      while (ch === '\\n' || ch === '#') {\n        if (atLineStart && ch === '\\n' && !prevIncludesTrailingLines) {\n          const blankLine = new BlankLine();\n          offset = blankLine.parse({\n            src\n          }, offset);\n          this.valueRange.end = offset;\n\n          if (offset >= src.length) {\n            ch = null;\n            break;\n          }\n\n          this.items.push(blankLine);\n          offset -= 1; // blankLine.parse() consumes terminal newline\n        } else if (ch === '#') {\n          if (offset < lineStart + indent && !Collection.nextContentHasIndent(src, offset, indent)) {\n            return offset;\n          }\n\n          const comment = new Comment();\n          offset = comment.parse({\n            indent,\n            lineStart,\n            src\n          }, offset);\n          this.items.push(comment);\n          this.valueRange.end = offset;\n\n          if (offset >= src.length) {\n            ch = null;\n            break;\n          }\n        }\n\n        lineStart = offset + 1;\n        offset = PlainValue.Node.endOfIndent(src, lineStart);\n\n        if (PlainValue.Node.atBlank(src, offset)) {\n          const wsEnd = PlainValue.Node.endOfWhiteSpace(src, offset);\n          const next = src[wsEnd];\n\n          if (!next || next === '\\n' || next === '#') {\n            offset = wsEnd;\n          }\n        }\n\n        ch = src[offset];\n        atLineStart = true;\n      }\n\n      if (!ch) {\n        break;\n      }\n\n      if (offset !== lineStart + indent && (atLineStart || ch !== ':')) {\n        if (offset < lineStart + indent) {\n          if (lineStart > start) offset = lineStart;\n          break;\n        } else if (!this.error) {\n          const msg = 'All collection items must start at the same column';\n          this.error = new PlainValue.YAMLSyntaxError(this, msg);\n        }\n      }\n\n      if (firstItem.type === PlainValue.Type.SEQ_ITEM) {\n        if (ch !== '-') {\n          if (lineStart > start) offset = lineStart;\n          break;\n        }\n      } else if (ch === '-' && !this.error) {\n        // map key may start with -, as long as it's followed by a non-whitespace char\n        const next = src[offset + 1];\n\n        if (!next || next === '\\n' || next === '\\t' || next === ' ') {\n          const msg = 'A collection cannot be both a mapping and a sequence';\n          this.error = new PlainValue.YAMLSyntaxError(this, msg);\n        }\n      }\n\n      const node = parseNode({\n        atLineStart,\n        inCollection: true,\n        indent,\n        lineStart,\n        parent: this\n      }, offset);\n      if (!node) return offset; // at next document start\n\n      this.items.push(node);\n      this.valueRange.end = node.valueRange.end;\n      offset = PlainValue.Node.normalizeOffset(src, node.range.end);\n      ch = src[offset];\n      atLineStart = false;\n      prevIncludesTrailingLines = node.includesTrailingLines; // Need to reset lineStart and atLineStart here if preceding node's range\n      // has advanced to check the current line's indentation level\n      // -- eemeli/yaml#10 & eemeli/yaml#38\n\n      if (ch) {\n        let ls = offset - 1;\n        let prev = src[ls];\n\n        while (prev === ' ' || prev === '\\t') prev = src[--ls];\n\n        if (prev === '\\n') {\n          lineStart = ls + 1;\n          atLineStart = true;\n        }\n      }\n\n      const ec = grabCollectionEndComments(node);\n      if (ec) Array.prototype.push.apply(this.items, ec);\n    }\n\n    return offset;\n  }\n\n  setOrigRanges(cr, offset) {\n    offset = super.setOrigRanges(cr, offset);\n    this.items.forEach(node => {\n      offset = node.setOrigRanges(cr, offset);\n    });\n    return offset;\n  }\n\n  toString() {\n    const {\n      context: {\n        src\n      },\n      items,\n      range,\n      value\n    } = this;\n    if (value != null) return value;\n    let str = src.slice(range.start, items[0].range.start) + String(items[0]);\n\n    for (let i = 1; i < items.length; ++i) {\n      const item = items[i];\n      const {\n        atLineStart,\n        indent\n      } = item.context;\n      if (atLineStart) for (let i = 0; i < indent; ++i) str += ' ';\n      str += String(item);\n    }\n\n    return PlainValue.Node.addStringTerminator(src, range.end, str);\n  }\n\n}\n\nclass Directive extends PlainValue.Node {\n  constructor() {\n    super(PlainValue.Type.DIRECTIVE);\n    this.name = null;\n  }\n\n  get parameters() {\n    const raw = this.rawValue;\n    return raw ? raw.trim().split(/[ \\t]+/) : [];\n  }\n\n  parseName(start) {\n    const {\n      src\n    } = this.context;\n    let offset = start;\n    let ch = src[offset];\n\n    while (ch && ch !== '\\n' && ch !== '\\t' && ch !== ' ') ch = src[offset += 1];\n\n    this.name = src.slice(start, offset);\n    return offset;\n  }\n\n  parseParameters(start) {\n    const {\n      src\n    } = this.context;\n    let offset = start;\n    let ch = src[offset];\n\n    while (ch && ch !== '\\n' && ch !== '#') ch = src[offset += 1];\n\n    this.valueRange = new PlainValue.Range(start, offset);\n    return offset;\n  }\n\n  parse(context, start) {\n    this.context = context;\n    let offset = this.parseName(start + 1);\n    offset = this.parseParameters(offset);\n    offset = this.parseComment(offset);\n    this.range = new PlainValue.Range(start, offset);\n    return offset;\n  }\n\n}\n\nclass Document extends PlainValue.Node {\n  static startCommentOrEndBlankLine(src, start) {\n    const offset = PlainValue.Node.endOfWhiteSpace(src, start);\n    const ch = src[offset];\n    return ch === '#' || ch === '\\n' ? offset : start;\n  }\n\n  constructor() {\n    super(PlainValue.Type.DOCUMENT);\n    this.directives = null;\n    this.contents = null;\n    this.directivesEndMarker = null;\n    this.documentEndMarker = null;\n  }\n\n  parseDirectives(start) {\n    const {\n      src\n    } = this.context;\n    this.directives = [];\n    let atLineStart = true;\n    let hasDirectives = false;\n    let offset = start;\n\n    while (!PlainValue.Node.atDocumentBoundary(src, offset, PlainValue.Char.DIRECTIVES_END)) {\n      offset = Document.startCommentOrEndBlankLine(src, offset);\n\n      switch (src[offset]) {\n        case '\\n':\n          if (atLineStart) {\n            const blankLine = new BlankLine();\n            offset = blankLine.parse({\n              src\n            }, offset);\n\n            if (offset < src.length) {\n              this.directives.push(blankLine);\n            }\n          } else {\n            offset += 1;\n            atLineStart = true;\n          }\n\n          break;\n\n        case '#':\n          {\n            const comment = new Comment();\n            offset = comment.parse({\n              src\n            }, offset);\n            this.directives.push(comment);\n            atLineStart = false;\n          }\n          break;\n\n        case '%':\n          {\n            const directive = new Directive();\n            offset = directive.parse({\n              parent: this,\n              src\n            }, offset);\n            this.directives.push(directive);\n            hasDirectives = true;\n            atLineStart = false;\n          }\n          break;\n\n        default:\n          if (hasDirectives) {\n            this.error = new PlainValue.YAMLSemanticError(this, 'Missing directives-end indicator line');\n          } else if (this.directives.length > 0) {\n            this.contents = this.directives;\n            this.directives = [];\n          }\n\n          return offset;\n      }\n    }\n\n    if (src[offset]) {\n      this.directivesEndMarker = new PlainValue.Range(offset, offset + 3);\n      return offset + 3;\n    }\n\n    if (hasDirectives) {\n      this.error = new PlainValue.YAMLSemanticError(this, 'Missing directives-end indicator line');\n    } else if (this.directives.length > 0) {\n      this.contents = this.directives;\n      this.directives = [];\n    }\n\n    return offset;\n  }\n\n  parseContents(start) {\n    const {\n      parseNode,\n      src\n    } = this.context;\n    if (!this.contents) this.contents = [];\n    let lineStart = start;\n\n    while (src[lineStart - 1] === '-') lineStart -= 1;\n\n    let offset = PlainValue.Node.endOfWhiteSpace(src, start);\n    let atLineStart = lineStart === start;\n    this.valueRange = new PlainValue.Range(offset);\n\n    while (!PlainValue.Node.atDocumentBoundary(src, offset, PlainValue.Char.DOCUMENT_END)) {\n      switch (src[offset]) {\n        case '\\n':\n          if (atLineStart) {\n            const blankLine = new BlankLine();\n            offset = blankLine.parse({\n              src\n            }, offset);\n\n            if (offset < src.length) {\n              this.contents.push(blankLine);\n            }\n          } else {\n            offset += 1;\n            atLineStart = true;\n          }\n\n          lineStart = offset;\n          break;\n\n        case '#':\n          {\n            const comment = new Comment();\n            offset = comment.parse({\n              src\n            }, offset);\n            this.contents.push(comment);\n            atLineStart = false;\n          }\n          break;\n\n        default:\n          {\n            const iEnd = PlainValue.Node.endOfIndent(src, offset);\n            const context = {\n              atLineStart,\n              indent: -1,\n              inFlow: false,\n              inCollection: false,\n              lineStart,\n              parent: this\n            };\n            const node = parseNode(context, iEnd);\n            if (!node) return this.valueRange.end = iEnd; // at next document start\n\n            this.contents.push(node);\n            offset = node.range.end;\n            atLineStart = false;\n            const ec = grabCollectionEndComments(node);\n            if (ec) Array.prototype.push.apply(this.contents, ec);\n          }\n      }\n\n      offset = Document.startCommentOrEndBlankLine(src, offset);\n    }\n\n    this.valueRange.end = offset;\n\n    if (src[offset]) {\n      this.documentEndMarker = new PlainValue.Range(offset, offset + 3);\n      offset += 3;\n\n      if (src[offset]) {\n        offset = PlainValue.Node.endOfWhiteSpace(src, offset);\n\n        if (src[offset] === '#') {\n          const comment = new Comment();\n          offset = comment.parse({\n            src\n          }, offset);\n          this.contents.push(comment);\n        }\n\n        switch (src[offset]) {\n          case '\\n':\n            offset += 1;\n            break;\n\n          case undefined:\n            break;\n\n          default:\n            this.error = new PlainValue.YAMLSyntaxError(this, 'Document end marker line cannot have a non-comment suffix');\n        }\n      }\n    }\n\n    return offset;\n  }\n  /**\n   * @param {ParseContext} context\n   * @param {number} start - Index of first character\n   * @returns {number} - Index of the character after this\n   */\n\n\n  parse(context, start) {\n    context.root = this;\n    this.context = context;\n    const {\n      src\n    } = context;\n    let offset = src.charCodeAt(start) === 0xfeff ? start + 1 : start; // skip BOM\n\n    offset = this.parseDirectives(offset);\n    offset = this.parseContents(offset);\n    return offset;\n  }\n\n  setOrigRanges(cr, offset) {\n    offset = super.setOrigRanges(cr, offset);\n    this.directives.forEach(node => {\n      offset = node.setOrigRanges(cr, offset);\n    });\n    if (this.directivesEndMarker) offset = this.directivesEndMarker.setOrigRange(cr, offset);\n    this.contents.forEach(node => {\n      offset = node.setOrigRanges(cr, offset);\n    });\n    if (this.documentEndMarker) offset = this.documentEndMarker.setOrigRange(cr, offset);\n    return offset;\n  }\n\n  toString() {\n    const {\n      contents,\n      directives,\n      value\n    } = this;\n    if (value != null) return value;\n    let str = directives.join('');\n\n    if (contents.length > 0) {\n      if (directives.length > 0 || contents[0].type === PlainValue.Type.COMMENT) str += '---\\n';\n      str += contents.join('');\n    }\n\n    if (str[str.length - 1] !== '\\n') str += '\\n';\n    return str;\n  }\n\n}\n\nclass Alias extends PlainValue.Node {\n  /**\n   * Parses an *alias from the source\n   *\n   * @param {ParseContext} context\n   * @param {number} start - Index of first character\n   * @returns {number} - Index of the character after this scalar\n   */\n  parse(context, start) {\n    this.context = context;\n    const {\n      src\n    } = context;\n    let offset = PlainValue.Node.endOfIdentifier(src, start + 1);\n    this.valueRange = new PlainValue.Range(start + 1, offset);\n    offset = PlainValue.Node.endOfWhiteSpace(src, offset);\n    offset = this.parseComment(offset);\n    return offset;\n  }\n\n}\n\nconst Chomp = {\n  CLIP: 'CLIP',\n  KEEP: 'KEEP',\n  STRIP: 'STRIP'\n};\nclass BlockValue extends PlainValue.Node {\n  constructor(type, props) {\n    super(type, props);\n    this.blockIndent = null;\n    this.chomping = Chomp.CLIP;\n    this.header = null;\n  }\n\n  get includesTrailingLines() {\n    return this.chomping === Chomp.KEEP;\n  }\n\n  get strValue() {\n    if (!this.valueRange || !this.context) return null;\n    let {\n      start,\n      end\n    } = this.valueRange;\n    const {\n      indent,\n      src\n    } = this.context;\n    if (this.valueRange.isEmpty()) return '';\n    let lastNewLine = null;\n    let ch = src[end - 1];\n\n    while (ch === '\\n' || ch === '\\t' || ch === ' ') {\n      end -= 1;\n\n      if (end <= start) {\n        if (this.chomping === Chomp.KEEP) break;else return ''; // probably never happens\n      }\n\n      if (ch === '\\n') lastNewLine = end;\n      ch = src[end - 1];\n    }\n\n    let keepStart = end + 1;\n\n    if (lastNewLine) {\n      if (this.chomping === Chomp.KEEP) {\n        keepStart = lastNewLine;\n        end = this.valueRange.end;\n      } else {\n        end = lastNewLine;\n      }\n    }\n\n    const bi = indent + this.blockIndent;\n    const folded = this.type === PlainValue.Type.BLOCK_FOLDED;\n    let atStart = true;\n    let str = '';\n    let sep = '';\n    let prevMoreIndented = false;\n\n    for (let i = start; i < end; ++i) {\n      for (let j = 0; j < bi; ++j) {\n        if (src[i] !== ' ') break;\n        i += 1;\n      }\n\n      const ch = src[i];\n\n      if (ch === '\\n') {\n        if (sep === '\\n') str += '\\n';else sep = '\\n';\n      } else {\n        const lineEnd = PlainValue.Node.endOfLine(src, i);\n        const line = src.slice(i, lineEnd);\n        i = lineEnd;\n\n        if (folded && (ch === ' ' || ch === '\\t') && i < keepStart) {\n          if (sep === ' ') sep = '\\n';else if (!prevMoreIndented && !atStart && sep === '\\n') sep = '\\n\\n';\n          str += sep + line; //+ ((lineEnd < end && src[lineEnd]) || '')\n\n          sep = lineEnd < end && src[lineEnd] || '';\n          prevMoreIndented = true;\n        } else {\n          str += sep + line;\n          sep = folded && i < keepStart ? ' ' : '\\n';\n          prevMoreIndented = false;\n        }\n\n        if (atStart && line !== '') atStart = false;\n      }\n    }\n\n    return this.chomping === Chomp.STRIP ? str : str + '\\n';\n  }\n\n  parseBlockHeader(start) {\n    const {\n      src\n    } = this.context;\n    let offset = start + 1;\n    let bi = '';\n\n    while (true) {\n      const ch = src[offset];\n\n      switch (ch) {\n        case '-':\n          this.chomping = Chomp.STRIP;\n          break;\n\n        case '+':\n          this.chomping = Chomp.KEEP;\n          break;\n\n        case '0':\n        case '1':\n        case '2':\n        case '3':\n        case '4':\n        case '5':\n        case '6':\n        case '7':\n        case '8':\n        case '9':\n          bi += ch;\n          break;\n\n        default:\n          this.blockIndent = Number(bi) || null;\n          this.header = new PlainValue.Range(start, offset);\n          return offset;\n      }\n\n      offset += 1;\n    }\n  }\n\n  parseBlockValue(start) {\n    const {\n      indent,\n      src\n    } = this.context;\n    const explicit = !!this.blockIndent;\n    let offset = start;\n    let valueEnd = start;\n    let minBlockIndent = 1;\n\n    for (let ch = src[offset]; ch === '\\n'; ch = src[offset]) {\n      offset += 1;\n      if (PlainValue.Node.atDocumentBoundary(src, offset)) break;\n      const end = PlainValue.Node.endOfBlockIndent(src, indent, offset); // should not include tab?\n\n      if (end === null) break;\n      const ch = src[end];\n      const lineIndent = end - (offset + indent);\n\n      if (!this.blockIndent) {\n        // no explicit block indent, none yet detected\n        if (src[end] !== '\\n') {\n          // first line with non-whitespace content\n          if (lineIndent < minBlockIndent) {\n            const msg = 'Block scalars with more-indented leading empty lines must use an explicit indentation indicator';\n            this.error = new PlainValue.YAMLSemanticError(this, msg);\n          }\n\n          this.blockIndent = lineIndent;\n        } else if (lineIndent > minBlockIndent) {\n          // empty line with more whitespace\n          minBlockIndent = lineIndent;\n        }\n      } else if (ch && ch !== '\\n' && lineIndent < this.blockIndent) {\n        if (src[end] === '#') break;\n\n        if (!this.error) {\n          const src = explicit ? 'explicit indentation indicator' : 'first line';\n          const msg = `Block scalars must not be less indented than their ${src}`;\n          this.error = new PlainValue.YAMLSemanticError(this, msg);\n        }\n      }\n\n      if (src[end] === '\\n') {\n        offset = end;\n      } else {\n        offset = valueEnd = PlainValue.Node.endOfLine(src, end);\n      }\n    }\n\n    if (this.chomping !== Chomp.KEEP) {\n      offset = src[valueEnd] ? valueEnd + 1 : valueEnd;\n    }\n\n    this.valueRange = new PlainValue.Range(start + 1, offset);\n    return offset;\n  }\n  /**\n   * Parses a block value from the source\n   *\n   * Accepted forms are:\n   * ```\n   * BS\n   * block\n   * lines\n   *\n   * BS #comment\n   * block\n   * lines\n   * ```\n   * where the block style BS matches the regexp `[|>][-+1-9]*` and block lines\n   * are empty or have an indent level greater than `indent`.\n   *\n   * @param {ParseContext} context\n   * @param {number} start - Index of first character\n   * @returns {number} - Index of the character after this block\n   */\n\n\n  parse(context, start) {\n    this.context = context;\n    const {\n      src\n    } = context;\n    let offset = this.parseBlockHeader(start);\n    offset = PlainValue.Node.endOfWhiteSpace(src, offset);\n    offset = this.parseComment(offset);\n    offset = this.parseBlockValue(offset);\n    return offset;\n  }\n\n  setOrigRanges(cr, offset) {\n    offset = super.setOrigRanges(cr, offset);\n    return this.header ? this.header.setOrigRange(cr, offset) : offset;\n  }\n\n}\n\nclass FlowCollection extends PlainValue.Node {\n  constructor(type, props) {\n    super(type, props);\n    this.items = null;\n  }\n\n  prevNodeIsJsonLike(idx = this.items.length) {\n    const node = this.items[idx - 1];\n    return !!node && (node.jsonLike || node.type === PlainValue.Type.COMMENT && this.prevNodeIsJsonLike(idx - 1));\n  }\n  /**\n   * @param {ParseContext} context\n   * @param {number} start - Index of first character\n   * @returns {number} - Index of the character after this\n   */\n\n\n  parse(context, start) {\n    this.context = context;\n    const {\n      parseNode,\n      src\n    } = context;\n    let {\n      indent,\n      lineStart\n    } = context;\n    let char = src[start]; // { or [\n\n    this.items = [{\n      char,\n      offset: start\n    }];\n    let offset = PlainValue.Node.endOfWhiteSpace(src, start + 1);\n    char = src[offset];\n\n    while (char && char !== ']' && char !== '}') {\n      switch (char) {\n        case '\\n':\n          {\n            lineStart = offset + 1;\n            const wsEnd = PlainValue.Node.endOfWhiteSpace(src, lineStart);\n\n            if (src[wsEnd] === '\\n') {\n              const blankLine = new BlankLine();\n              lineStart = blankLine.parse({\n                src\n              }, lineStart);\n              this.items.push(blankLine);\n            }\n\n            offset = PlainValue.Node.endOfIndent(src, lineStart);\n\n            if (offset <= lineStart + indent) {\n              char = src[offset];\n\n              if (offset < lineStart + indent || char !== ']' && char !== '}') {\n                const msg = 'Insufficient indentation in flow collection';\n                this.error = new PlainValue.YAMLSemanticError(this, msg);\n              }\n            }\n          }\n          break;\n\n        case ',':\n          {\n            this.items.push({\n              char,\n              offset\n            });\n            offset += 1;\n          }\n          break;\n\n        case '#':\n          {\n            const comment = new Comment();\n            offset = comment.parse({\n              src\n            }, offset);\n            this.items.push(comment);\n          }\n          break;\n\n        case '?':\n        case ':':\n          {\n            const next = src[offset + 1];\n\n            if (next === '\\n' || next === '\\t' || next === ' ' || next === ',' || // in-flow : after JSON-like key does not need to be followed by whitespace\n            char === ':' && this.prevNodeIsJsonLike()) {\n              this.items.push({\n                char,\n                offset\n              });\n              offset += 1;\n              break;\n            }\n          }\n        // fallthrough\n\n        default:\n          {\n            const node = parseNode({\n              atLineStart: false,\n              inCollection: false,\n              inFlow: true,\n              indent: -1,\n              lineStart,\n              parent: this\n            }, offset);\n\n            if (!node) {\n              // at next document start\n              this.valueRange = new PlainValue.Range(start, offset);\n              return offset;\n            }\n\n            this.items.push(node);\n            offset = PlainValue.Node.normalizeOffset(src, node.range.end);\n          }\n      }\n\n      offset = PlainValue.Node.endOfWhiteSpace(src, offset);\n      char = src[offset];\n    }\n\n    this.valueRange = new PlainValue.Range(start, offset + 1);\n\n    if (char) {\n      this.items.push({\n        char,\n        offset\n      });\n      offset = PlainValue.Node.endOfWhiteSpace(src, offset + 1);\n      offset = this.parseComment(offset);\n    }\n\n    return offset;\n  }\n\n  setOrigRanges(cr, offset) {\n    offset = super.setOrigRanges(cr, offset);\n    this.items.forEach(node => {\n      if (node instanceof PlainValue.Node) {\n        offset = node.setOrigRanges(cr, offset);\n      } else if (cr.length === 0) {\n        node.origOffset = node.offset;\n      } else {\n        let i = offset;\n\n        while (i < cr.length) {\n          if (cr[i] > node.offset) break;else ++i;\n        }\n\n        node.origOffset = node.offset + i;\n        offset = i;\n      }\n    });\n    return offset;\n  }\n\n  toString() {\n    const {\n      context: {\n        src\n      },\n      items,\n      range,\n      value\n    } = this;\n    if (value != null) return value;\n    const nodes = items.filter(item => item instanceof PlainValue.Node);\n    let str = '';\n    let prevEnd = range.start;\n    nodes.forEach(node => {\n      const prefix = src.slice(prevEnd, node.range.start);\n      prevEnd = node.range.end;\n      str += prefix + String(node);\n\n      if (str[str.length - 1] === '\\n' && src[prevEnd - 1] !== '\\n' && src[prevEnd] === '\\n') {\n        // Comment range does not include the terminal newline, but its\n        // stringified value does. Without this fix, newlines at comment ends\n        // get duplicated.\n        prevEnd += 1;\n      }\n    });\n    str += src.slice(prevEnd, range.end);\n    return PlainValue.Node.addStringTerminator(src, range.end, str);\n  }\n\n}\n\nclass QuoteDouble extends PlainValue.Node {\n  static endOfQuote(src, offset) {\n    let ch = src[offset];\n\n    while (ch && ch !== '\"') {\n      offset += ch === '\\\\' ? 2 : 1;\n      ch = src[offset];\n    }\n\n    return offset + 1;\n  }\n  /**\n   * @returns {string | { str: string, errors: YAMLSyntaxError[] }}\n   */\n\n\n  get strValue() {\n    if (!this.valueRange || !this.context) return null;\n    const errors = [];\n    const {\n      start,\n      end\n    } = this.valueRange;\n    const {\n      indent,\n      src\n    } = this.context;\n    if (src[end - 1] !== '\"') errors.push(new PlainValue.YAMLSyntaxError(this, 'Missing closing \"quote')); // Using String#replace is too painful with escaped newlines preceded by\n    // escaped backslashes; also, this should be faster.\n\n    let str = '';\n\n    for (let i = start + 1; i < end - 1; ++i) {\n      const ch = src[i];\n\n      if (ch === '\\n') {\n        if (PlainValue.Node.atDocumentBoundary(src, i + 1)) errors.push(new PlainValue.YAMLSemanticError(this, 'Document boundary indicators are not allowed within string values'));\n        const {\n          fold,\n          offset,\n          error\n        } = PlainValue.Node.foldNewline(src, i, indent);\n        str += fold;\n        i = offset;\n        if (error) errors.push(new PlainValue.YAMLSemanticError(this, 'Multi-line double-quoted string needs to be sufficiently indented'));\n      } else if (ch === '\\\\') {\n        i += 1;\n\n        switch (src[i]) {\n          case '0':\n            str += '\\0';\n            break;\n          // null character\n\n          case 'a':\n            str += '\\x07';\n            break;\n          // bell character\n\n          case 'b':\n            str += '\\b';\n            break;\n          // backspace\n\n          case 'e':\n            str += '\\x1b';\n            break;\n          // escape character\n\n          case 'f':\n            str += '\\f';\n            break;\n          // form feed\n\n          case 'n':\n            str += '\\n';\n            break;\n          // line feed\n\n          case 'r':\n            str += '\\r';\n            break;\n          // carriage return\n\n          case 't':\n            str += '\\t';\n            break;\n          // horizontal tab\n\n          case 'v':\n            str += '\\v';\n            break;\n          // vertical tab\n\n          case 'N':\n            str += '\\u0085';\n            break;\n          // Unicode next line\n\n          case '_':\n            str += '\\u00a0';\n            break;\n          // Unicode non-breaking space\n\n          case 'L':\n            str += '\\u2028';\n            break;\n          // Unicode line separator\n\n          case 'P':\n            str += '\\u2029';\n            break;\n          // Unicode paragraph separator\n\n          case ' ':\n            str += ' ';\n            break;\n\n          case '\"':\n            str += '\"';\n            break;\n\n          case '/':\n            str += '/';\n            break;\n\n          case '\\\\':\n            str += '\\\\';\n            break;\n\n          case '\\t':\n            str += '\\t';\n            break;\n\n          case 'x':\n            str += this.parseCharCode(i + 1, 2, errors);\n            i += 2;\n            break;\n\n          case 'u':\n            str += this.parseCharCode(i + 1, 4, errors);\n            i += 4;\n            break;\n\n          case 'U':\n            str += this.parseCharCode(i + 1, 8, errors);\n            i += 8;\n            break;\n\n          case '\\n':\n            // skip escaped newlines, but still trim the following line\n            while (src[i + 1] === ' ' || src[i + 1] === '\\t') i += 1;\n\n            break;\n\n          default:\n            errors.push(new PlainValue.YAMLSyntaxError(this, `Invalid escape sequence ${src.substr(i - 1, 2)}`));\n            str += '\\\\' + src[i];\n        }\n      } else if (ch === ' ' || ch === '\\t') {\n        // trim trailing whitespace\n        const wsStart = i;\n        let next = src[i + 1];\n\n        while (next === ' ' || next === '\\t') {\n          i += 1;\n          next = src[i + 1];\n        }\n\n        if (next !== '\\n') str += i > wsStart ? src.slice(wsStart, i + 1) : ch;\n      } else {\n        str += ch;\n      }\n    }\n\n    return errors.length > 0 ? {\n      errors,\n      str\n    } : str;\n  }\n\n  parseCharCode(offset, length, errors) {\n    const {\n      src\n    } = this.context;\n    const cc = src.substr(offset, length);\n    const ok = cc.length === length && /^[0-9a-fA-F]+$/.test(cc);\n    const code = ok ? parseInt(cc, 16) : NaN;\n\n    if (isNaN(code)) {\n      errors.push(new PlainValue.YAMLSyntaxError(this, `Invalid escape sequence ${src.substr(offset - 2, length + 2)}`));\n      return src.substr(offset - 2, length + 2);\n    }\n\n    return String.fromCodePoint(code);\n  }\n  /**\n   * Parses a \"double quoted\" value from the source\n   *\n   * @param {ParseContext} context\n   * @param {number} start - Index of first character\n   * @returns {number} - Index of the character after this scalar\n   */\n\n\n  parse(context, start) {\n    this.context = context;\n    const {\n      src\n    } = context;\n    let offset = QuoteDouble.endOfQuote(src, start + 1);\n    this.valueRange = new PlainValue.Range(start, offset);\n    offset = PlainValue.Node.endOfWhiteSpace(src, offset);\n    offset = this.parseComment(offset);\n    return offset;\n  }\n\n}\n\nclass QuoteSingle extends PlainValue.Node {\n  static endOfQuote(src, offset) {\n    let ch = src[offset];\n\n    while (ch) {\n      if (ch === \"'\") {\n        if (src[offset + 1] !== \"'\") break;\n        ch = src[offset += 2];\n      } else {\n        ch = src[offset += 1];\n      }\n    }\n\n    return offset + 1;\n  }\n  /**\n   * @returns {string | { str: string, errors: YAMLSyntaxError[] }}\n   */\n\n\n  get strValue() {\n    if (!this.valueRange || !this.context) return null;\n    const errors = [];\n    const {\n      start,\n      end\n    } = this.valueRange;\n    const {\n      indent,\n      src\n    } = this.context;\n    if (src[end - 1] !== \"'\") errors.push(new PlainValue.YAMLSyntaxError(this, \"Missing closing 'quote\"));\n    let str = '';\n\n    for (let i = start + 1; i < end - 1; ++i) {\n      const ch = src[i];\n\n      if (ch === '\\n') {\n        if (PlainValue.Node.atDocumentBoundary(src, i + 1)) errors.push(new PlainValue.YAMLSemanticError(this, 'Document boundary indicators are not allowed within string values'));\n        const {\n          fold,\n          offset,\n          error\n        } = PlainValue.Node.foldNewline(src, i, indent);\n        str += fold;\n        i = offset;\n        if (error) errors.push(new PlainValue.YAMLSemanticError(this, 'Multi-line single-quoted string needs to be sufficiently indented'));\n      } else if (ch === \"'\") {\n        str += ch;\n        i += 1;\n        if (src[i] !== \"'\") errors.push(new PlainValue.YAMLSyntaxError(this, 'Unescaped single quote? This should not happen.'));\n      } else if (ch === ' ' || ch === '\\t') {\n        // trim trailing whitespace\n        const wsStart = i;\n        let next = src[i + 1];\n\n        while (next === ' ' || next === '\\t') {\n          i += 1;\n          next = src[i + 1];\n        }\n\n        if (next !== '\\n') str += i > wsStart ? src.slice(wsStart, i + 1) : ch;\n      } else {\n        str += ch;\n      }\n    }\n\n    return errors.length > 0 ? {\n      errors,\n      str\n    } : str;\n  }\n  /**\n   * Parses a 'single quoted' value from the source\n   *\n   * @param {ParseContext} context\n   * @param {number} start - Index of first character\n   * @returns {number} - Index of the character after this scalar\n   */\n\n\n  parse(context, start) {\n    this.context = context;\n    const {\n      src\n    } = context;\n    let offset = QuoteSingle.endOfQuote(src, start + 1);\n    this.valueRange = new PlainValue.Range(start, offset);\n    offset = PlainValue.Node.endOfWhiteSpace(src, offset);\n    offset = this.parseComment(offset);\n    return offset;\n  }\n\n}\n\nfunction createNewNode(type, props) {\n  switch (type) {\n    case PlainValue.Type.ALIAS:\n      return new Alias(type, props);\n\n    case PlainValue.Type.BLOCK_FOLDED:\n    case PlainValue.Type.BLOCK_LITERAL:\n      return new BlockValue(type, props);\n\n    case PlainValue.Type.FLOW_MAP:\n    case PlainValue.Type.FLOW_SEQ:\n      return new FlowCollection(type, props);\n\n    case PlainValue.Type.MAP_KEY:\n    case PlainValue.Type.MAP_VALUE:\n    case PlainValue.Type.SEQ_ITEM:\n      return new CollectionItem(type, props);\n\n    case PlainValue.Type.COMMENT:\n    case PlainValue.Type.PLAIN:\n      return new PlainValue.PlainValue(type, props);\n\n    case PlainValue.Type.QUOTE_DOUBLE:\n      return new QuoteDouble(type, props);\n\n    case PlainValue.Type.QUOTE_SINGLE:\n      return new QuoteSingle(type, props);\n\n    /* istanbul ignore next */\n\n    default:\n      return null;\n    // should never happen\n  }\n}\n/**\n * @param {boolean} atLineStart - Node starts at beginning of line\n * @param {boolean} inFlow - true if currently in a flow context\n * @param {boolean} inCollection - true if currently in a collection context\n * @param {number} indent - Current level of indentation\n * @param {number} lineStart - Start of the current line\n * @param {Node} parent - The parent of the node\n * @param {string} src - Source of the YAML document\n */\n\n\nclass ParseContext {\n  static parseType(src, offset, inFlow) {\n    switch (src[offset]) {\n      case '*':\n        return PlainValue.Type.ALIAS;\n\n      case '>':\n        return PlainValue.Type.BLOCK_FOLDED;\n\n      case '|':\n        return PlainValue.Type.BLOCK_LITERAL;\n\n      case '{':\n        return PlainValue.Type.FLOW_MAP;\n\n      case '[':\n        return PlainValue.Type.FLOW_SEQ;\n\n      case '?':\n        return !inFlow && PlainValue.Node.atBlank(src, offset + 1, true) ? PlainValue.Type.MAP_KEY : PlainValue.Type.PLAIN;\n\n      case ':':\n        return !inFlow && PlainValue.Node.atBlank(src, offset + 1, true) ? PlainValue.Type.MAP_VALUE : PlainValue.Type.PLAIN;\n\n      case '-':\n        return !inFlow && PlainValue.Node.atBlank(src, offset + 1, true) ? PlainValue.Type.SEQ_ITEM : PlainValue.Type.PLAIN;\n\n      case '\"':\n        return PlainValue.Type.QUOTE_DOUBLE;\n\n      case \"'\":\n        return PlainValue.Type.QUOTE_SINGLE;\n\n      default:\n        return PlainValue.Type.PLAIN;\n    }\n  }\n\n  constructor(orig = {}, {\n    atLineStart,\n    inCollection,\n    inFlow,\n    indent,\n    lineStart,\n    parent\n  } = {}) {\n    PlainValue._defineProperty(this, \"parseNode\", (overlay, start) => {\n      if (PlainValue.Node.atDocumentBoundary(this.src, start)) return null;\n      const context = new ParseContext(this, overlay);\n      const {\n        props,\n        type,\n        valueStart\n      } = context.parseProps(start);\n      const node = createNewNode(type, props);\n      let offset = node.parse(context, valueStart);\n      node.range = new PlainValue.Range(start, offset);\n      /* istanbul ignore if */\n\n      if (offset <= start) {\n        // This should never happen, but if it does, let's make sure to at least\n        // step one character forward to avoid a busy loop.\n        node.error = new Error(`Node#parse consumed no characters`);\n        node.error.parseEnd = offset;\n        node.error.source = node;\n        node.range.end = start + 1;\n      }\n\n      if (context.nodeStartsCollection(node)) {\n        if (!node.error && !context.atLineStart && context.parent.type === PlainValue.Type.DOCUMENT) {\n          node.error = new PlainValue.YAMLSyntaxError(node, 'Block collection must not have preceding content here (e.g. directives-end indicator)');\n        }\n\n        const collection = new Collection(node);\n        offset = collection.parse(new ParseContext(context), offset);\n        collection.range = new PlainValue.Range(start, offset);\n        return collection;\n      }\n\n      return node;\n    });\n\n    this.atLineStart = atLineStart != null ? atLineStart : orig.atLineStart || false;\n    this.inCollection = inCollection != null ? inCollection : orig.inCollection || false;\n    this.inFlow = inFlow != null ? inFlow : orig.inFlow || false;\n    this.indent = indent != null ? indent : orig.indent;\n    this.lineStart = lineStart != null ? lineStart : orig.lineStart;\n    this.parent = parent != null ? parent : orig.parent || {};\n    this.root = orig.root;\n    this.src = orig.src;\n  }\n\n  nodeStartsCollection(node) {\n    const {\n      inCollection,\n      inFlow,\n      src\n    } = this;\n    if (inCollection || inFlow) return false;\n    if (node instanceof CollectionItem) return true; // check for implicit key\n\n    let offset = node.range.end;\n    if (src[offset] === '\\n' || src[offset - 1] === '\\n') return false;\n    offset = PlainValue.Node.endOfWhiteSpace(src, offset);\n    return src[offset] === ':';\n  } // Anchor and tag are before type, which determines the node implementation\n  // class; hence this intermediate step.\n\n\n  parseProps(offset) {\n    const {\n      inFlow,\n      parent,\n      src\n    } = this;\n    const props = [];\n    let lineHasProps = false;\n    offset = this.atLineStart ? PlainValue.Node.endOfIndent(src, offset) : PlainValue.Node.endOfWhiteSpace(src, offset);\n    let ch = src[offset];\n\n    while (ch === PlainValue.Char.ANCHOR || ch === PlainValue.Char.COMMENT || ch === PlainValue.Char.TAG || ch === '\\n') {\n      if (ch === '\\n') {\n        const lineStart = offset + 1;\n        const inEnd = PlainValue.Node.endOfIndent(src, lineStart);\n        const indentDiff = inEnd - (lineStart + this.indent);\n        const noIndicatorAsIndent = parent.type === PlainValue.Type.SEQ_ITEM && parent.context.atLineStart;\n        if (!PlainValue.Node.nextNodeIsIndented(src[inEnd], indentDiff, !noIndicatorAsIndent)) break;\n        this.atLineStart = true;\n        this.lineStart = lineStart;\n        lineHasProps = false;\n        offset = inEnd;\n      } else if (ch === PlainValue.Char.COMMENT) {\n        const end = PlainValue.Node.endOfLine(src, offset + 1);\n        props.push(new PlainValue.Range(offset, end));\n        offset = end;\n      } else {\n        let end = PlainValue.Node.endOfIdentifier(src, offset + 1);\n\n        if (ch === PlainValue.Char.TAG && src[end] === ',' && /^[a-zA-Z0-9-]+\\.[a-zA-Z0-9-]+,\\d\\d\\d\\d(-\\d\\d){0,2}\\/\\S/.test(src.slice(offset + 1, end + 13))) {\n          // Let's presume we're dealing with a YAML 1.0 domain tag here, rather\n          // than an empty but 'foo.bar' private-tagged node in a flow collection\n          // followed without whitespace by a plain string starting with a year\n          // or date divided by something.\n          end = PlainValue.Node.endOfIdentifier(src, end + 5);\n        }\n\n        props.push(new PlainValue.Range(offset, end));\n        lineHasProps = true;\n        offset = PlainValue.Node.endOfWhiteSpace(src, end);\n      }\n\n      ch = src[offset];\n    } // '- &a : b' has an anchor on an empty node\n\n\n    if (lineHasProps && ch === ':' && PlainValue.Node.atBlank(src, offset + 1, true)) offset -= 1;\n    const type = ParseContext.parseType(src, offset, inFlow);\n    return {\n      props,\n      type,\n      valueStart: offset\n    };\n  }\n  /**\n   * Parses a node from the source\n   * @param {ParseContext} overlay\n   * @param {number} start - Index of first non-whitespace character for the node\n   * @returns {?Node} - null if at a document boundary\n   */\n\n\n}\n\n// Published as 'yaml/parse-cst'\nfunction parse(src) {\n  const cr = [];\n\n  if (src.indexOf('\\r') !== -1) {\n    src = src.replace(/\\r\\n?/g, (match, offset) => {\n      if (match.length > 1) cr.push(offset);\n      return '\\n';\n    });\n  }\n\n  const documents = [];\n  let offset = 0;\n\n  do {\n    const doc = new Document();\n    const context = new ParseContext({\n      src\n    });\n    offset = doc.parse(context, offset);\n    documents.push(doc);\n  } while (offset < src.length);\n\n  documents.setOrigRanges = () => {\n    if (cr.length === 0) return false;\n\n    for (let i = 1; i < cr.length; ++i) cr[i] -= i;\n\n    let crOffset = 0;\n\n    for (let i = 0; i < documents.length; ++i) {\n      crOffset = documents[i].setOrigRanges(cr, crOffset);\n    }\n\n    cr.splice(0, cr.length);\n    return true;\n  };\n\n  documents.toString = () => documents.join('...\\n');\n\n  return documents;\n}\n\nexports.parse = parse;\n","'use strict';\n\nvar PlainValue = require('./PlainValue-ec8e588e.js');\n\nfunction addCommentBefore(str, indent, comment) {\n  if (!comment) return str;\n  const cc = comment.replace(/[\\s\\S]^/gm, `$&${indent}#`);\n  return `#${cc}\\n${indent}${str}`;\n}\nfunction addComment(str, indent, comment) {\n  return !comment ? str : comment.indexOf('\\n') === -1 ? `${str} #${comment}` : `${str}\\n` + comment.replace(/^/gm, `${indent || ''}#`);\n}\n\nclass Node {}\n\nfunction toJSON(value, arg, ctx) {\n  if (Array.isArray(value)) return value.map((v, i) => toJSON(v, String(i), ctx));\n\n  if (value && typeof value.toJSON === 'function') {\n    const anchor = ctx && ctx.anchors && ctx.anchors.get(value);\n    if (anchor) ctx.onCreate = res => {\n      anchor.res = res;\n      delete ctx.onCreate;\n    };\n    const res = value.toJSON(arg, ctx);\n    if (anchor && ctx.onCreate) ctx.onCreate(res);\n    return res;\n  }\n\n  if ((!ctx || !ctx.keep) && typeof value === 'bigint') return Number(value);\n  return value;\n}\n\nclass Scalar extends Node {\n  constructor(value) {\n    super();\n    this.value = value;\n  }\n\n  toJSON(arg, ctx) {\n    return ctx && ctx.keep ? this.value : toJSON(this.value, arg, ctx);\n  }\n\n  toString() {\n    return String(this.value);\n  }\n\n}\n\nfunction collectionFromPath(schema, path, value) {\n  let v = value;\n\n  for (let i = path.length - 1; i >= 0; --i) {\n    const k = path[i];\n    const o = Number.isInteger(k) && k >= 0 ? [] : {};\n    o[k] = v;\n    v = o;\n  }\n\n  return schema.createNode(v, false);\n} // null, undefined, or an empty non-string iterable (e.g. [])\n\n\nconst isEmptyPath = path => path == null || typeof path === 'object' && path[Symbol.iterator]().next().done;\nclass Collection extends Node {\n  constructor(schema) {\n    super();\n\n    PlainValue._defineProperty(this, \"items\", []);\n\n    this.schema = schema;\n  }\n\n  addIn(path, value) {\n    if (isEmptyPath(path)) this.add(value);else {\n      const [key, ...rest] = path;\n      const node = this.get(key, true);\n      if (node instanceof Collection) node.addIn(rest, value);else if (node === undefined && this.schema) this.set(key, collectionFromPath(this.schema, rest, value));else throw new Error(`Expected YAML collection at ${key}. Remaining path: ${rest}`);\n    }\n  }\n\n  deleteIn([key, ...rest]) {\n    if (rest.length === 0) return this.delete(key);\n    const node = this.get(key, true);\n    if (node instanceof Collection) return node.deleteIn(rest);else throw new Error(`Expected YAML collection at ${key}. Remaining path: ${rest}`);\n  }\n\n  getIn([key, ...rest], keepScalar) {\n    const node = this.get(key, true);\n    if (rest.length === 0) return !keepScalar && node instanceof Scalar ? node.value : node;else return node instanceof Collection ? node.getIn(rest, keepScalar) : undefined;\n  }\n\n  hasAllNullValues() {\n    return this.items.every(node => {\n      if (!node || node.type !== 'PAIR') return false;\n      const n = node.value;\n      return n == null || n instanceof Scalar && n.value == null && !n.commentBefore && !n.comment && !n.tag;\n    });\n  }\n\n  hasIn([key, ...rest]) {\n    if (rest.length === 0) return this.has(key);\n    const node = this.get(key, true);\n    return node instanceof Collection ? node.hasIn(rest) : false;\n  }\n\n  setIn([key, ...rest], value) {\n    if (rest.length === 0) {\n      this.set(key, value);\n    } else {\n      const node = this.get(key, true);\n      if (node instanceof Collection) node.setIn(rest, value);else if (node === undefined && this.schema) this.set(key, collectionFromPath(this.schema, rest, value));else throw new Error(`Expected YAML collection at ${key}. Remaining path: ${rest}`);\n    }\n  } // overridden in implementations\n\n  /* istanbul ignore next */\n\n\n  toJSON() {\n    return null;\n  }\n\n  toString(ctx, {\n    blockItem,\n    flowChars,\n    isMap,\n    itemIndent\n  }, onComment, onChompKeep) {\n    const {\n      indent,\n      indentStep,\n      stringify\n    } = ctx;\n    const inFlow = this.type === PlainValue.Type.FLOW_MAP || this.type === PlainValue.Type.FLOW_SEQ || ctx.inFlow;\n    if (inFlow) itemIndent += indentStep;\n    const allNullValues = isMap && this.hasAllNullValues();\n    ctx = Object.assign({}, ctx, {\n      allNullValues,\n      indent: itemIndent,\n      inFlow,\n      type: null\n    });\n    let chompKeep = false;\n    let hasItemWithNewLine = false;\n    const nodes = this.items.reduce((nodes, item, i) => {\n      let comment;\n\n      if (item) {\n        if (!chompKeep && item.spaceBefore) nodes.push({\n          type: 'comment',\n          str: ''\n        });\n        if (item.commentBefore) item.commentBefore.match(/^.*$/gm).forEach(line => {\n          nodes.push({\n            type: 'comment',\n            str: `#${line}`\n          });\n        });\n        if (item.comment) comment = item.comment;\n        if (inFlow && (!chompKeep && item.spaceBefore || item.commentBefore || item.comment || item.key && (item.key.commentBefore || item.key.comment) || item.value && (item.value.commentBefore || item.value.comment))) hasItemWithNewLine = true;\n      }\n\n      chompKeep = false;\n      let str = stringify(item, ctx, () => comment = null, () => chompKeep = true);\n      if (inFlow && !hasItemWithNewLine && str.includes('\\n')) hasItemWithNewLine = true;\n      if (inFlow && i < this.items.length - 1) str += ',';\n      str = addComment(str, itemIndent, comment);\n      if (chompKeep && (comment || inFlow)) chompKeep = false;\n      nodes.push({\n        type: 'item',\n        str\n      });\n      return nodes;\n    }, []);\n    let str;\n\n    if (nodes.length === 0) {\n      str = flowChars.start + flowChars.end;\n    } else if (inFlow) {\n      const {\n        start,\n        end\n      } = flowChars;\n      const strings = nodes.map(n => n.str);\n\n      if (hasItemWithNewLine || strings.reduce((sum, str) => sum + str.length + 2, 2) > Collection.maxFlowStringSingleLineLength) {\n        str = start;\n\n        for (const s of strings) {\n          str += s ? `\\n${indentStep}${indent}${s}` : '\\n';\n        }\n\n        str += `\\n${indent}${end}`;\n      } else {\n        str = `${start} ${strings.join(' ')} ${end}`;\n      }\n    } else {\n      const strings = nodes.map(blockItem);\n      str = strings.shift();\n\n      for (const s of strings) str += s ? `\\n${indent}${s}` : '\\n';\n    }\n\n    if (this.comment) {\n      str += '\\n' + this.comment.replace(/^/gm, `${indent}#`);\n      if (onComment) onComment();\n    } else if (chompKeep && onChompKeep) onChompKeep();\n\n    return str;\n  }\n\n}\n\nPlainValue._defineProperty(Collection, \"maxFlowStringSingleLineLength\", 60);\n\nfunction asItemIndex(key) {\n  let idx = key instanceof Scalar ? key.value : key;\n  if (idx && typeof idx === 'string') idx = Number(idx);\n  return Number.isInteger(idx) && idx >= 0 ? idx : null;\n}\n\nclass YAMLSeq extends Collection {\n  add(value) {\n    this.items.push(value);\n  }\n\n  delete(key) {\n    const idx = asItemIndex(key);\n    if (typeof idx !== 'number') return false;\n    const del = this.items.splice(idx, 1);\n    return del.length > 0;\n  }\n\n  get(key, keepScalar) {\n    const idx = asItemIndex(key);\n    if (typeof idx !== 'number') return undefined;\n    const it = this.items[idx];\n    return !keepScalar && it instanceof Scalar ? it.value : it;\n  }\n\n  has(key) {\n    const idx = asItemIndex(key);\n    return typeof idx === 'number' && idx < this.items.length;\n  }\n\n  set(key, value) {\n    const idx = asItemIndex(key);\n    if (typeof idx !== 'number') throw new Error(`Expected a valid index, not ${key}.`);\n    this.items[idx] = value;\n  }\n\n  toJSON(_, ctx) {\n    const seq = [];\n    if (ctx && ctx.onCreate) ctx.onCreate(seq);\n    let i = 0;\n\n    for (const item of this.items) seq.push(toJSON(item, String(i++), ctx));\n\n    return seq;\n  }\n\n  toString(ctx, onComment, onChompKeep) {\n    if (!ctx) return JSON.stringify(this);\n    return super.toString(ctx, {\n      blockItem: n => n.type === 'comment' ? n.str : `- ${n.str}`,\n      flowChars: {\n        start: '[',\n        end: ']'\n      },\n      isMap: false,\n      itemIndent: (ctx.indent || '') + '  '\n    }, onComment, onChompKeep);\n  }\n\n}\n\nconst stringifyKey = (key, jsKey, ctx) => {\n  if (jsKey === null) return '';\n  if (typeof jsKey !== 'object') return String(jsKey);\n  if (key instanceof Node && ctx && ctx.doc) return key.toString({\n    anchors: {},\n    doc: ctx.doc,\n    indent: '',\n    indentStep: ctx.indentStep,\n    inFlow: true,\n    inStringifyKey: true,\n    stringify: ctx.stringify\n  });\n  return JSON.stringify(jsKey);\n};\n\nclass Pair extends Node {\n  constructor(key, value = null) {\n    super();\n    this.key = key;\n    this.value = value;\n    this.type = Pair.Type.PAIR;\n  }\n\n  get commentBefore() {\n    return this.key instanceof Node ? this.key.commentBefore : undefined;\n  }\n\n  set commentBefore(cb) {\n    if (this.key == null) this.key = new Scalar(null);\n    if (this.key instanceof Node) this.key.commentBefore = cb;else {\n      const msg = 'Pair.commentBefore is an alias for Pair.key.commentBefore. To set it, the key must be a Node.';\n      throw new Error(msg);\n    }\n  }\n\n  addToJSMap(ctx, map) {\n    const key = toJSON(this.key, '', ctx);\n\n    if (map instanceof Map) {\n      const value = toJSON(this.value, key, ctx);\n      map.set(key, value);\n    } else if (map instanceof Set) {\n      map.add(key);\n    } else {\n      const stringKey = stringifyKey(this.key, key, ctx);\n      map[stringKey] = toJSON(this.value, stringKey, ctx);\n    }\n\n    return map;\n  }\n\n  toJSON(_, ctx) {\n    const pair = ctx && ctx.mapAsMap ? new Map() : {};\n    return this.addToJSMap(ctx, pair);\n  }\n\n  toString(ctx, onComment, onChompKeep) {\n    if (!ctx || !ctx.doc) return JSON.stringify(this);\n    const {\n      indent: indentSize,\n      indentSeq,\n      simpleKeys\n    } = ctx.doc.options;\n    let {\n      key,\n      value\n    } = this;\n    let keyComment = key instanceof Node && key.comment;\n\n    if (simpleKeys) {\n      if (keyComment) {\n        throw new Error('With simple keys, key nodes cannot have comments');\n      }\n\n      if (key instanceof Collection) {\n        const msg = 'With simple keys, collection cannot be used as a key value';\n        throw new Error(msg);\n      }\n    }\n\n    const explicitKey = !simpleKeys && (!key || keyComment || key instanceof Collection || key.type === PlainValue.Type.BLOCK_FOLDED || key.type === PlainValue.Type.BLOCK_LITERAL);\n    const {\n      doc,\n      indent,\n      indentStep,\n      stringify\n    } = ctx;\n    ctx = Object.assign({}, ctx, {\n      implicitKey: !explicitKey,\n      indent: indent + indentStep\n    });\n    let chompKeep = false;\n    let str = stringify(key, ctx, () => keyComment = null, () => chompKeep = true);\n    str = addComment(str, ctx.indent, keyComment);\n\n    if (ctx.allNullValues && !simpleKeys) {\n      if (this.comment) {\n        str = addComment(str, ctx.indent, this.comment);\n        if (onComment) onComment();\n      } else if (chompKeep && !keyComment && onChompKeep) onChompKeep();\n\n      return ctx.inFlow ? str : `? ${str}`;\n    }\n\n    str = explicitKey ? `? ${str}\\n${indent}:` : `${str}:`;\n\n    if (this.comment) {\n      // expected (but not strictly required) to be a single-line comment\n      str = addComment(str, ctx.indent, this.comment);\n      if (onComment) onComment();\n    }\n\n    let vcb = '';\n    let valueComment = null;\n\n    if (value instanceof Node) {\n      if (value.spaceBefore) vcb = '\\n';\n\n      if (value.commentBefore) {\n        const cs = value.commentBefore.replace(/^/gm, `${ctx.indent}#`);\n        vcb += `\\n${cs}`;\n      }\n\n      valueComment = value.comment;\n    } else if (value && typeof value === 'object') {\n      value = doc.schema.createNode(value, true);\n    }\n\n    ctx.implicitKey = false;\n    if (!explicitKey && !this.comment && value instanceof Scalar) ctx.indentAtStart = str.length + 1;\n    chompKeep = false;\n\n    if (!indentSeq && indentSize >= 2 && !ctx.inFlow && !explicitKey && value instanceof YAMLSeq && value.type !== PlainValue.Type.FLOW_SEQ && !value.tag && !doc.anchors.getName(value)) {\n      // If indentSeq === false, consider '- ' as part of indentation where possible\n      ctx.indent = ctx.indent.substr(2);\n    }\n\n    const valueStr = stringify(value, ctx, () => valueComment = null, () => chompKeep = true);\n    let ws = ' ';\n\n    if (vcb || this.comment) {\n      ws = `${vcb}\\n${ctx.indent}`;\n    } else if (!explicitKey && value instanceof Collection) {\n      const flow = valueStr[0] === '[' || valueStr[0] === '{';\n      if (!flow || valueStr.includes('\\n')) ws = `\\n${ctx.indent}`;\n    }\n\n    if (chompKeep && !valueComment && onChompKeep) onChompKeep();\n    return addComment(str + ws + valueStr, ctx.indent, valueComment);\n  }\n\n}\n\nPlainValue._defineProperty(Pair, \"Type\", {\n  PAIR: 'PAIR',\n  MERGE_PAIR: 'MERGE_PAIR'\n});\n\nconst getAliasCount = (node, anchors) => {\n  if (node instanceof Alias) {\n    const anchor = anchors.get(node.source);\n    return anchor.count * anchor.aliasCount;\n  } else if (node instanceof Collection) {\n    let count = 0;\n\n    for (const item of node.items) {\n      const c = getAliasCount(item, anchors);\n      if (c > count) count = c;\n    }\n\n    return count;\n  } else if (node instanceof Pair) {\n    const kc = getAliasCount(node.key, anchors);\n    const vc = getAliasCount(node.value, anchors);\n    return Math.max(kc, vc);\n  }\n\n  return 1;\n};\n\nclass Alias extends Node {\n  static stringify({\n    range,\n    source\n  }, {\n    anchors,\n    doc,\n    implicitKey,\n    inStringifyKey\n  }) {\n    let anchor = Object.keys(anchors).find(a => anchors[a] === source);\n    if (!anchor && inStringifyKey) anchor = doc.anchors.getName(source) || doc.anchors.newName();\n    if (anchor) return `*${anchor}${implicitKey ? ' ' : ''}`;\n    const msg = doc.anchors.getName(source) ? 'Alias node must be after source node' : 'Source node not found for alias node';\n    throw new Error(`${msg} [${range}]`);\n  }\n\n  constructor(source) {\n    super();\n    this.source = source;\n    this.type = PlainValue.Type.ALIAS;\n  }\n\n  set tag(t) {\n    throw new Error('Alias nodes cannot have tags');\n  }\n\n  toJSON(arg, ctx) {\n    if (!ctx) return toJSON(this.source, arg, ctx);\n    const {\n      anchors,\n      maxAliasCount\n    } = ctx;\n    const anchor = anchors.get(this.source);\n    /* istanbul ignore if */\n\n    if (!anchor || anchor.res === undefined) {\n      const msg = 'This should not happen: Alias anchor was not resolved?';\n      if (this.cstNode) throw new PlainValue.YAMLReferenceError(this.cstNode, msg);else throw new ReferenceError(msg);\n    }\n\n    if (maxAliasCount >= 0) {\n      anchor.count += 1;\n      if (anchor.aliasCount === 0) anchor.aliasCount = getAliasCount(this.source, anchors);\n\n      if (anchor.count * anchor.aliasCount > maxAliasCount) {\n        const msg = 'Excessive alias count indicates a resource exhaustion attack';\n        if (this.cstNode) throw new PlainValue.YAMLReferenceError(this.cstNode, msg);else throw new ReferenceError(msg);\n      }\n    }\n\n    return anchor.res;\n  } // Only called when stringifying an alias mapping key while constructing\n  // Object output.\n\n\n  toString(ctx) {\n    return Alias.stringify(this, ctx);\n  }\n\n}\n\nPlainValue._defineProperty(Alias, \"default\", true);\n\nfunction findPair(items, key) {\n  const k = key instanceof Scalar ? key.value : key;\n\n  for (const it of items) {\n    if (it instanceof Pair) {\n      if (it.key === key || it.key === k) return it;\n      if (it.key && it.key.value === k) return it;\n    }\n  }\n\n  return undefined;\n}\nclass YAMLMap extends Collection {\n  add(pair, overwrite) {\n    if (!pair) pair = new Pair(pair);else if (!(pair instanceof Pair)) pair = new Pair(pair.key || pair, pair.value);\n    const prev = findPair(this.items, pair.key);\n    const sortEntries = this.schema && this.schema.sortMapEntries;\n\n    if (prev) {\n      if (overwrite) prev.value = pair.value;else throw new Error(`Key ${pair.key} already set`);\n    } else if (sortEntries) {\n      const i = this.items.findIndex(item => sortEntries(pair, item) < 0);\n      if (i === -1) this.items.push(pair);else this.items.splice(i, 0, pair);\n    } else {\n      this.items.push(pair);\n    }\n  }\n\n  delete(key) {\n    const it = findPair(this.items, key);\n    if (!it) return false;\n    const del = this.items.splice(this.items.indexOf(it), 1);\n    return del.length > 0;\n  }\n\n  get(key, keepScalar) {\n    const it = findPair(this.items, key);\n    const node = it && it.value;\n    return !keepScalar && node instanceof Scalar ? node.value : node;\n  }\n\n  has(key) {\n    return !!findPair(this.items, key);\n  }\n\n  set(key, value) {\n    this.add(new Pair(key, value), true);\n  }\n  /**\n   * @param {*} arg ignored\n   * @param {*} ctx Conversion context, originally set in Document#toJSON()\n   * @param {Class} Type If set, forces the returned collection type\n   * @returns {*} Instance of Type, Map, or Object\n   */\n\n\n  toJSON(_, ctx, Type) {\n    const map = Type ? new Type() : ctx && ctx.mapAsMap ? new Map() : {};\n    if (ctx && ctx.onCreate) ctx.onCreate(map);\n\n    for (const item of this.items) item.addToJSMap(ctx, map);\n\n    return map;\n  }\n\n  toString(ctx, onComment, onChompKeep) {\n    if (!ctx) return JSON.stringify(this);\n\n    for (const item of this.items) {\n      if (!(item instanceof Pair)) throw new Error(`Map items must all be pairs; found ${JSON.stringify(item)} instead`);\n    }\n\n    return super.toString(ctx, {\n      blockItem: n => n.str,\n      flowChars: {\n        start: '{',\n        end: '}'\n      },\n      isMap: true,\n      itemIndent: ctx.indent || ''\n    }, onComment, onChompKeep);\n  }\n\n}\n\nconst MERGE_KEY = '<<';\nclass Merge extends Pair {\n  constructor(pair) {\n    if (pair instanceof Pair) {\n      let seq = pair.value;\n\n      if (!(seq instanceof YAMLSeq)) {\n        seq = new YAMLSeq();\n        seq.items.push(pair.value);\n        seq.range = pair.value.range;\n      }\n\n      super(pair.key, seq);\n      this.range = pair.range;\n    } else {\n      super(new Scalar(MERGE_KEY), new YAMLSeq());\n    }\n\n    this.type = Pair.Type.MERGE_PAIR;\n  } // If the value associated with a merge key is a single mapping node, each of\n  // its key/value pairs is inserted into the current mapping, unless the key\n  // already exists in it. If the value associated with the merge key is a\n  // sequence, then this sequence is expected to contain mapping nodes and each\n  // of these nodes is merged in turn according to its order in the sequence.\n  // Keys in mapping nodes earlier in the sequence override keys specified in\n  // later mapping nodes. -- http://yaml.org/type/merge.html\n\n\n  addToJSMap(ctx, map) {\n    for (const {\n      source\n    } of this.value.items) {\n      if (!(source instanceof YAMLMap)) throw new Error('Merge sources must be maps');\n      const srcMap = source.toJSON(null, ctx, Map);\n\n      for (const [key, value] of srcMap) {\n        if (map instanceof Map) {\n          if (!map.has(key)) map.set(key, value);\n        } else if (map instanceof Set) {\n          map.add(key);\n        } else {\n          if (!Object.prototype.hasOwnProperty.call(map, key)) map[key] = value;\n        }\n      }\n    }\n\n    return map;\n  }\n\n  toString(ctx, onComment) {\n    const seq = this.value;\n    if (seq.items.length > 1) return super.toString(ctx, onComment);\n    this.value = seq.items[0];\n    const str = super.toString(ctx, onComment);\n    this.value = seq;\n    return str;\n  }\n\n}\n\nconst binaryOptions = {\n  defaultType: PlainValue.Type.BLOCK_LITERAL,\n  lineWidth: 76\n};\nconst boolOptions = {\n  trueStr: 'true',\n  falseStr: 'false'\n};\nconst intOptions = {\n  asBigInt: false\n};\nconst nullOptions = {\n  nullStr: 'null'\n};\nconst strOptions = {\n  defaultType: PlainValue.Type.PLAIN,\n  doubleQuoted: {\n    jsonEncoding: false,\n    minMultiLineLength: 40\n  },\n  fold: {\n    lineWidth: 80,\n    minContentWidth: 20\n  }\n};\n\nfunction resolveScalar(str, tags, scalarFallback) {\n  for (const {\n    format,\n    test,\n    resolve\n  } of tags) {\n    if (test) {\n      const match = str.match(test);\n\n      if (match) {\n        let res = resolve.apply(null, match);\n        if (!(res instanceof Scalar)) res = new Scalar(res);\n        if (format) res.format = format;\n        return res;\n      }\n    }\n  }\n\n  if (scalarFallback) str = scalarFallback(str);\n  return new Scalar(str);\n}\n\nconst FOLD_FLOW = 'flow';\nconst FOLD_BLOCK = 'block';\nconst FOLD_QUOTED = 'quoted'; // presumes i+1 is at the start of a line\n// returns index of last newline in more-indented block\n\nconst consumeMoreIndentedLines = (text, i) => {\n  let ch = text[i + 1];\n\n  while (ch === ' ' || ch === '\\t') {\n    do {\n      ch = text[i += 1];\n    } while (ch && ch !== '\\n');\n\n    ch = text[i + 1];\n  }\n\n  return i;\n};\n/**\n * Tries to keep input at up to `lineWidth` characters, splitting only on spaces\n * not followed by newlines or spaces unless `mode` is `'quoted'`. Lines are\n * terminated with `\\n` and started with `indent`.\n *\n * @param {string} text\n * @param {string} indent\n * @param {string} [mode='flow'] `'block'` prevents more-indented lines\n *   from being folded; `'quoted'` allows for `\\` escapes, including escaped\n *   newlines\n * @param {Object} options\n * @param {number} [options.indentAtStart] Accounts for leading contents on\n *   the first line, defaulting to `indent.length`\n * @param {number} [options.lineWidth=80]\n * @param {number} [options.minContentWidth=20] Allow highly indented lines to\n *   stretch the line width\n * @param {function} options.onFold Called once if the text is folded\n * @param {function} options.onFold Called once if any line of text exceeds\n *   lineWidth characters\n */\n\n\nfunction foldFlowLines(text, indent, mode, {\n  indentAtStart,\n  lineWidth = 80,\n  minContentWidth = 20,\n  onFold,\n  onOverflow\n}) {\n  if (!lineWidth || lineWidth < 0) return text;\n  const endStep = Math.max(1 + minContentWidth, 1 + lineWidth - indent.length);\n  if (text.length <= endStep) return text;\n  const folds = [];\n  const escapedFolds = {};\n  let end = lineWidth - (typeof indentAtStart === 'number' ? indentAtStart : indent.length);\n  let split = undefined;\n  let prev = undefined;\n  let overflow = false;\n  let i = -1;\n\n  if (mode === FOLD_BLOCK) {\n    i = consumeMoreIndentedLines(text, i);\n    if (i !== -1) end = i + endStep;\n  }\n\n  for (let ch; ch = text[i += 1];) {\n    if (mode === FOLD_QUOTED && ch === '\\\\') {\n      switch (text[i + 1]) {\n        case 'x':\n          i += 3;\n          break;\n\n        case 'u':\n          i += 5;\n          break;\n\n        case 'U':\n          i += 9;\n          break;\n\n        default:\n          i += 1;\n      }\n    }\n\n    if (ch === '\\n') {\n      if (mode === FOLD_BLOCK) i = consumeMoreIndentedLines(text, i);\n      end = i + endStep;\n      split = undefined;\n    } else {\n      if (ch === ' ' && prev && prev !== ' ' && prev !== '\\n' && prev !== '\\t') {\n        // space surrounded by non-space can be replaced with newline + indent\n        const next = text[i + 1];\n        if (next && next !== ' ' && next !== '\\n' && next !== '\\t') split = i;\n      }\n\n      if (i >= end) {\n        if (split) {\n          folds.push(split);\n          end = split + endStep;\n          split = undefined;\n        } else if (mode === FOLD_QUOTED) {\n          // white-space collected at end may stretch past lineWidth\n          while (prev === ' ' || prev === '\\t') {\n            prev = ch;\n            ch = text[i += 1];\n            overflow = true;\n          } // i - 2 accounts for not-dropped last char + newline-escaping \\\n\n\n          folds.push(i - 2);\n          escapedFolds[i - 2] = true;\n          end = i - 2 + endStep;\n          split = undefined;\n        } else {\n          overflow = true;\n        }\n      }\n    }\n\n    prev = ch;\n  }\n\n  if (overflow && onOverflow) onOverflow();\n  if (folds.length === 0) return text;\n  if (onFold) onFold();\n  let res = text.slice(0, folds[0]);\n\n  for (let i = 0; i < folds.length; ++i) {\n    const fold = folds[i];\n    const end = folds[i + 1] || text.length;\n    if (mode === FOLD_QUOTED && escapedFolds[fold]) res += `${text[fold]}\\\\`;\n    res += `\\n${indent}${text.slice(fold + 1, end)}`;\n  }\n\n  return res;\n}\n\nconst getFoldOptions = ({\n  indentAtStart\n}) => indentAtStart ? Object.assign({\n  indentAtStart\n}, strOptions.fold) : strOptions.fold; // Also checks for lines starting with %, as parsing the output as YAML 1.1 will\n// presume that's starting a new document.\n\n\nconst containsDocumentMarker = str => /^(%|---|\\.\\.\\.)/m.test(str);\n\nfunction lineLengthOverLimit(str, limit) {\n  const strLen = str.length;\n  if (strLen <= limit) return false;\n\n  for (let i = 0, start = 0; i < strLen; ++i) {\n    if (str[i] === '\\n') {\n      if (i - start > limit) return true;\n      start = i + 1;\n      if (strLen - start <= limit) return false;\n    }\n  }\n\n  return true;\n}\n\nfunction doubleQuotedString(value, ctx) {\n  const {\n    implicitKey\n  } = ctx;\n  const {\n    jsonEncoding,\n    minMultiLineLength\n  } = strOptions.doubleQuoted;\n  const json = JSON.stringify(value);\n  if (jsonEncoding) return json;\n  const indent = ctx.indent || (containsDocumentMarker(value) ? '  ' : '');\n  let str = '';\n  let start = 0;\n\n  for (let i = 0, ch = json[i]; ch; ch = json[++i]) {\n    if (ch === ' ' && json[i + 1] === '\\\\' && json[i + 2] === 'n') {\n      // space before newline needs to be escaped to not be folded\n      str += json.slice(start, i) + '\\\\ ';\n      i += 1;\n      start = i;\n      ch = '\\\\';\n    }\n\n    if (ch === '\\\\') switch (json[i + 1]) {\n      case 'u':\n        {\n          str += json.slice(start, i);\n          const code = json.substr(i + 2, 4);\n\n          switch (code) {\n            case '0000':\n              str += '\\\\0';\n              break;\n\n            case '0007':\n              str += '\\\\a';\n              break;\n\n            case '000b':\n              str += '\\\\v';\n              break;\n\n            case '001b':\n              str += '\\\\e';\n              break;\n\n            case '0085':\n              str += '\\\\N';\n              break;\n\n            case '00a0':\n              str += '\\\\_';\n              break;\n\n            case '2028':\n              str += '\\\\L';\n              break;\n\n            case '2029':\n              str += '\\\\P';\n              break;\n\n            default:\n              if (code.substr(0, 2) === '00') str += '\\\\x' + code.substr(2);else str += json.substr(i, 6);\n          }\n\n          i += 5;\n          start = i + 1;\n        }\n        break;\n\n      case 'n':\n        if (implicitKey || json[i + 2] === '\"' || json.length < minMultiLineLength) {\n          i += 1;\n        } else {\n          // folding will eat first newline\n          str += json.slice(start, i) + '\\n\\n';\n\n          while (json[i + 2] === '\\\\' && json[i + 3] === 'n' && json[i + 4] !== '\"') {\n            str += '\\n';\n            i += 2;\n          }\n\n          str += indent; // space after newline needs to be escaped to not be folded\n\n          if (json[i + 2] === ' ') str += '\\\\';\n          i += 1;\n          start = i + 1;\n        }\n\n        break;\n\n      default:\n        i += 1;\n    }\n  }\n\n  str = start ? str + json.slice(start) : json;\n  return implicitKey ? str : foldFlowLines(str, indent, FOLD_QUOTED, getFoldOptions(ctx));\n}\n\nfunction singleQuotedString(value, ctx) {\n  if (ctx.implicitKey) {\n    if (/\\n/.test(value)) return doubleQuotedString(value, ctx);\n  } else {\n    // single quoted string can't have leading or trailing whitespace around newline\n    if (/[ \\t]\\n|\\n[ \\t]/.test(value)) return doubleQuotedString(value, ctx);\n  }\n\n  const indent = ctx.indent || (containsDocumentMarker(value) ? '  ' : '');\n  const res = \"'\" + value.replace(/'/g, \"''\").replace(/\\n+/g, `$&\\n${indent}`) + \"'\";\n  return ctx.implicitKey ? res : foldFlowLines(res, indent, FOLD_FLOW, getFoldOptions(ctx));\n}\n\nfunction blockString({\n  comment,\n  type,\n  value\n}, ctx, onComment, onChompKeep) {\n  // 1. Block can't end in whitespace unless the last line is non-empty.\n  // 2. Strings consisting of only whitespace are best rendered explicitly.\n  if (/\\n[\\t ]+$/.test(value) || /^\\s*$/.test(value)) {\n    return doubleQuotedString(value, ctx);\n  }\n\n  const indent = ctx.indent || (ctx.forceBlockIndent || containsDocumentMarker(value) ? '  ' : '');\n  const indentSize = indent ? '2' : '1'; // root is at -1\n\n  const literal = type === PlainValue.Type.BLOCK_FOLDED ? false : type === PlainValue.Type.BLOCK_LITERAL ? true : !lineLengthOverLimit(value, strOptions.fold.lineWidth - indent.length);\n  let header = literal ? '|' : '>';\n  if (!value) return header + '\\n';\n  let wsStart = '';\n  let wsEnd = '';\n  value = value.replace(/[\\n\\t ]*$/, ws => {\n    const n = ws.indexOf('\\n');\n\n    if (n === -1) {\n      header += '-'; // strip\n    } else if (value === ws || n !== ws.length - 1) {\n      header += '+'; // keep\n\n      if (onChompKeep) onChompKeep();\n    }\n\n    wsEnd = ws.replace(/\\n$/, '');\n    return '';\n  }).replace(/^[\\n ]*/, ws => {\n    if (ws.indexOf(' ') !== -1) header += indentSize;\n    const m = ws.match(/ +$/);\n\n    if (m) {\n      wsStart = ws.slice(0, -m[0].length);\n      return m[0];\n    } else {\n      wsStart = ws;\n      return '';\n    }\n  });\n  if (wsEnd) wsEnd = wsEnd.replace(/\\n+(?!\\n|$)/g, `$&${indent}`);\n  if (wsStart) wsStart = wsStart.replace(/\\n+/g, `$&${indent}`);\n\n  if (comment) {\n    header += ' #' + comment.replace(/ ?[\\r\\n]+/g, ' ');\n    if (onComment) onComment();\n  }\n\n  if (!value) return `${header}${indentSize}\\n${indent}${wsEnd}`;\n\n  if (literal) {\n    value = value.replace(/\\n+/g, `$&${indent}`);\n    return `${header}\\n${indent}${wsStart}${value}${wsEnd}`;\n  }\n\n  value = value.replace(/\\n+/g, '\\n$&').replace(/(?:^|\\n)([\\t ].*)(?:([\\n\\t ]*)\\n(?![\\n\\t ]))?/g, '$1$2') // more-indented lines aren't folded\n  //         ^ ind.line  ^ empty     ^ capture next empty lines only at end of indent\n  .replace(/\\n+/g, `$&${indent}`);\n  const body = foldFlowLines(`${wsStart}${value}${wsEnd}`, indent, FOLD_BLOCK, strOptions.fold);\n  return `${header}\\n${indent}${body}`;\n}\n\nfunction plainString(item, ctx, onComment, onChompKeep) {\n  const {\n    comment,\n    type,\n    value\n  } = item;\n  const {\n    actualString,\n    implicitKey,\n    indent,\n    inFlow\n  } = ctx;\n\n  if (implicitKey && /[\\n[\\]{},]/.test(value) || inFlow && /[[\\]{},]/.test(value)) {\n    return doubleQuotedString(value, ctx);\n  }\n\n  if (!value || /^[\\n\\t ,[\\]{}#&*!|>'\"%@`]|^[?-]$|^[?-][ \\t]|[\\n:][ \\t]|[ \\t]\\n|[\\n\\t ]#|[\\n\\t :]$/.test(value)) {\n    // not allowed:\n    // - empty string, '-' or '?'\n    // - start with an indicator character (except [?:-]) or /[?-] /\n    // - '\\n ', ': ' or ' \\n' anywhere\n    // - '#' not preceded by a non-space char\n    // - end with ' ' or ':'\n    return implicitKey || inFlow || value.indexOf('\\n') === -1 ? value.indexOf('\"') !== -1 && value.indexOf(\"'\") === -1 ? singleQuotedString(value, ctx) : doubleQuotedString(value, ctx) : blockString(item, ctx, onComment, onChompKeep);\n  }\n\n  if (!implicitKey && !inFlow && type !== PlainValue.Type.PLAIN && value.indexOf('\\n') !== -1) {\n    // Where allowed & type not set explicitly, prefer block style for multiline strings\n    return blockString(item, ctx, onComment, onChompKeep);\n  }\n\n  if (indent === '' && containsDocumentMarker(value)) {\n    ctx.forceBlockIndent = true;\n    return blockString(item, ctx, onComment, onChompKeep);\n  }\n\n  const str = value.replace(/\\n+/g, `$&\\n${indent}`); // Verify that output will be parsed as a string, as e.g. plain numbers and\n  // booleans get parsed with those types in v1.2 (e.g. '42', 'true' & '0.9e-3'),\n  // and others in v1.1.\n\n  if (actualString) {\n    const {\n      tags\n    } = ctx.doc.schema;\n    const resolved = resolveScalar(str, tags, tags.scalarFallback).value;\n    if (typeof resolved !== 'string') return doubleQuotedString(value, ctx);\n  }\n\n  const body = implicitKey ? str : foldFlowLines(str, indent, FOLD_FLOW, getFoldOptions(ctx));\n\n  if (comment && !inFlow && (body.indexOf('\\n') !== -1 || comment.indexOf('\\n') !== -1)) {\n    if (onComment) onComment();\n    return addCommentBefore(body, indent, comment);\n  }\n\n  return body;\n}\n\nfunction stringifyString(item, ctx, onComment, onChompKeep) {\n  const {\n    defaultType\n  } = strOptions;\n  const {\n    implicitKey,\n    inFlow\n  } = ctx;\n  let {\n    type,\n    value\n  } = item;\n\n  if (typeof value !== 'string') {\n    value = String(value);\n    item = Object.assign({}, item, {\n      value\n    });\n  }\n\n  const _stringify = _type => {\n    switch (_type) {\n      case PlainValue.Type.BLOCK_FOLDED:\n      case PlainValue.Type.BLOCK_LITERAL:\n        return blockString(item, ctx, onComment, onChompKeep);\n\n      case PlainValue.Type.QUOTE_DOUBLE:\n        return doubleQuotedString(value, ctx);\n\n      case PlainValue.Type.QUOTE_SINGLE:\n        return singleQuotedString(value, ctx);\n\n      case PlainValue.Type.PLAIN:\n        return plainString(item, ctx, onComment, onChompKeep);\n\n      default:\n        return null;\n    }\n  };\n\n  if (type !== PlainValue.Type.QUOTE_DOUBLE && /[\\x00-\\x08\\x0b-\\x1f\\x7f-\\x9f]/.test(value)) {\n    // force double quotes on control characters\n    type = PlainValue.Type.QUOTE_DOUBLE;\n  } else if ((implicitKey || inFlow) && (type === PlainValue.Type.BLOCK_FOLDED || type === PlainValue.Type.BLOCK_LITERAL)) {\n    // should not happen; blocks are not valid inside flow containers\n    type = PlainValue.Type.QUOTE_DOUBLE;\n  }\n\n  let res = _stringify(type);\n\n  if (res === null) {\n    res = _stringify(defaultType);\n    if (res === null) throw new Error(`Unsupported default string type ${defaultType}`);\n  }\n\n  return res;\n}\n\nfunction stringifyNumber({\n  format,\n  minFractionDigits,\n  tag,\n  value\n}) {\n  if (typeof value === 'bigint') return String(value);\n  if (!isFinite(value)) return isNaN(value) ? '.nan' : value < 0 ? '-.inf' : '.inf';\n  let n = JSON.stringify(value);\n\n  if (!format && minFractionDigits && (!tag || tag === 'tag:yaml.org,2002:float') && /^\\d/.test(n)) {\n    let i = n.indexOf('.');\n\n    if (i < 0) {\n      i = n.length;\n      n += '.';\n    }\n\n    let d = minFractionDigits - (n.length - i - 1);\n\n    while (d-- > 0) n += '0';\n  }\n\n  return n;\n}\n\nfunction checkFlowCollectionEnd(errors, cst) {\n  let char, name;\n\n  switch (cst.type) {\n    case PlainValue.Type.FLOW_MAP:\n      char = '}';\n      name = 'flow map';\n      break;\n\n    case PlainValue.Type.FLOW_SEQ:\n      char = ']';\n      name = 'flow sequence';\n      break;\n\n    default:\n      errors.push(new PlainValue.YAMLSemanticError(cst, 'Not a flow collection!?'));\n      return;\n  }\n\n  let lastItem;\n\n  for (let i = cst.items.length - 1; i >= 0; --i) {\n    const item = cst.items[i];\n\n    if (!item || item.type !== PlainValue.Type.COMMENT) {\n      lastItem = item;\n      break;\n    }\n  }\n\n  if (lastItem && lastItem.char !== char) {\n    const msg = `Expected ${name} to end with ${char}`;\n    let err;\n\n    if (typeof lastItem.offset === 'number') {\n      err = new PlainValue.YAMLSemanticError(cst, msg);\n      err.offset = lastItem.offset + 1;\n    } else {\n      err = new PlainValue.YAMLSemanticError(lastItem, msg);\n      if (lastItem.range && lastItem.range.end) err.offset = lastItem.range.end - lastItem.range.start;\n    }\n\n    errors.push(err);\n  }\n}\nfunction checkFlowCommentSpace(errors, comment) {\n  const prev = comment.context.src[comment.range.start - 1];\n\n  if (prev !== '\\n' && prev !== '\\t' && prev !== ' ') {\n    const msg = 'Comments must be separated from other tokens by white space characters';\n    errors.push(new PlainValue.YAMLSemanticError(comment, msg));\n  }\n}\nfunction getLongKeyError(source, key) {\n  const sk = String(key);\n  const k = sk.substr(0, 8) + '...' + sk.substr(-8);\n  return new PlainValue.YAMLSemanticError(source, `The \"${k}\" key is too long`);\n}\nfunction resolveComments(collection, comments) {\n  for (const {\n    afterKey,\n    before,\n    comment\n  } of comments) {\n    let item = collection.items[before];\n\n    if (!item) {\n      if (comment !== undefined) {\n        if (collection.comment) collection.comment += '\\n' + comment;else collection.comment = comment;\n      }\n    } else {\n      if (afterKey && item.value) item = item.value;\n\n      if (comment === undefined) {\n        if (afterKey || !item.commentBefore) item.spaceBefore = true;\n      } else {\n        if (item.commentBefore) item.commentBefore += '\\n' + comment;else item.commentBefore = comment;\n      }\n    }\n  }\n}\n\n// on error, will return { str: string, errors: Error[] }\nfunction resolveString(doc, node) {\n  const res = node.strValue;\n  if (!res) return '';\n  if (typeof res === 'string') return res;\n  res.errors.forEach(error => {\n    if (!error.source) error.source = node;\n    doc.errors.push(error);\n  });\n  return res.str;\n}\n\nfunction resolveTagHandle(doc, node) {\n  const {\n    handle,\n    suffix\n  } = node.tag;\n  let prefix = doc.tagPrefixes.find(p => p.handle === handle);\n\n  if (!prefix) {\n    const dtp = doc.getDefaults().tagPrefixes;\n    if (dtp) prefix = dtp.find(p => p.handle === handle);\n    if (!prefix) throw new PlainValue.YAMLSemanticError(node, `The ${handle} tag handle is non-default and was not declared.`);\n  }\n\n  if (!suffix) throw new PlainValue.YAMLSemanticError(node, `The ${handle} tag has no suffix.`);\n\n  if (handle === '!' && (doc.version || doc.options.version) === '1.0') {\n    if (suffix[0] === '^') {\n      doc.warnings.push(new PlainValue.YAMLWarning(node, 'YAML 1.0 ^ tag expansion is not supported'));\n      return suffix;\n    }\n\n    if (/[:/]/.test(suffix)) {\n      // word/foo -> tag:word.yaml.org,2002:foo\n      const vocab = suffix.match(/^([a-z0-9-]+)\\/(.*)/i);\n      return vocab ? `tag:${vocab[1]}.yaml.org,2002:${vocab[2]}` : `tag:${suffix}`;\n    }\n  }\n\n  return prefix.prefix + decodeURIComponent(suffix);\n}\n\nfunction resolveTagName(doc, node) {\n  const {\n    tag,\n    type\n  } = node;\n  let nonSpecific = false;\n\n  if (tag) {\n    const {\n      handle,\n      suffix,\n      verbatim\n    } = tag;\n\n    if (verbatim) {\n      if (verbatim !== '!' && verbatim !== '!!') return verbatim;\n      const msg = `Verbatim tags aren't resolved, so ${verbatim} is invalid.`;\n      doc.errors.push(new PlainValue.YAMLSemanticError(node, msg));\n    } else if (handle === '!' && !suffix) {\n      nonSpecific = true;\n    } else {\n      try {\n        return resolveTagHandle(doc, node);\n      } catch (error) {\n        doc.errors.push(error);\n      }\n    }\n  }\n\n  switch (type) {\n    case PlainValue.Type.BLOCK_FOLDED:\n    case PlainValue.Type.BLOCK_LITERAL:\n    case PlainValue.Type.QUOTE_DOUBLE:\n    case PlainValue.Type.QUOTE_SINGLE:\n      return PlainValue.defaultTags.STR;\n\n    case PlainValue.Type.FLOW_MAP:\n    case PlainValue.Type.MAP:\n      return PlainValue.defaultTags.MAP;\n\n    case PlainValue.Type.FLOW_SEQ:\n    case PlainValue.Type.SEQ:\n      return PlainValue.defaultTags.SEQ;\n\n    case PlainValue.Type.PLAIN:\n      return nonSpecific ? PlainValue.defaultTags.STR : null;\n\n    default:\n      return null;\n  }\n}\n\nfunction resolveByTagName(doc, node, tagName) {\n  const {\n    tags\n  } = doc.schema;\n  const matchWithTest = [];\n\n  for (const tag of tags) {\n    if (tag.tag === tagName) {\n      if (tag.test) matchWithTest.push(tag);else {\n        const res = tag.resolve(doc, node);\n        return res instanceof Collection ? res : new Scalar(res);\n      }\n    }\n  }\n\n  const str = resolveString(doc, node);\n  if (typeof str === 'string' && matchWithTest.length > 0) return resolveScalar(str, matchWithTest, tags.scalarFallback);\n  return null;\n}\n\nfunction getFallbackTagName({\n  type\n}) {\n  switch (type) {\n    case PlainValue.Type.FLOW_MAP:\n    case PlainValue.Type.MAP:\n      return PlainValue.defaultTags.MAP;\n\n    case PlainValue.Type.FLOW_SEQ:\n    case PlainValue.Type.SEQ:\n      return PlainValue.defaultTags.SEQ;\n\n    default:\n      return PlainValue.defaultTags.STR;\n  }\n}\n\nfunction resolveTag(doc, node, tagName) {\n  try {\n    const res = resolveByTagName(doc, node, tagName);\n\n    if (res) {\n      if (tagName && node.tag) res.tag = tagName;\n      return res;\n    }\n  } catch (error) {\n    /* istanbul ignore if */\n    if (!error.source) error.source = node;\n    doc.errors.push(error);\n    return null;\n  }\n\n  try {\n    const fallback = getFallbackTagName(node);\n    if (!fallback) throw new Error(`The tag ${tagName} is unavailable`);\n    const msg = `The tag ${tagName} is unavailable, falling back to ${fallback}`;\n    doc.warnings.push(new PlainValue.YAMLWarning(node, msg));\n    const res = resolveByTagName(doc, node, fallback);\n    res.tag = tagName;\n    return res;\n  } catch (error) {\n    const refError = new PlainValue.YAMLReferenceError(node, error.message);\n    refError.stack = error.stack;\n    doc.errors.push(refError);\n    return null;\n  }\n}\n\nconst isCollectionItem = node => {\n  if (!node) return false;\n  const {\n    type\n  } = node;\n  return type === PlainValue.Type.MAP_KEY || type === PlainValue.Type.MAP_VALUE || type === PlainValue.Type.SEQ_ITEM;\n};\n\nfunction resolveNodeProps(errors, node) {\n  const comments = {\n    before: [],\n    after: []\n  };\n  let hasAnchor = false;\n  let hasTag = false;\n  const props = isCollectionItem(node.context.parent) ? node.context.parent.props.concat(node.props) : node.props;\n\n  for (const {\n    start,\n    end\n  } of props) {\n    switch (node.context.src[start]) {\n      case PlainValue.Char.COMMENT:\n        {\n          if (!node.commentHasRequiredWhitespace(start)) {\n            const msg = 'Comments must be separated from other tokens by white space characters';\n            errors.push(new PlainValue.YAMLSemanticError(node, msg));\n          }\n\n          const {\n            header,\n            valueRange\n          } = node;\n          const cc = valueRange && (start > valueRange.start || header && start > header.start) ? comments.after : comments.before;\n          cc.push(node.context.src.slice(start + 1, end));\n          break;\n        }\n      // Actual anchor & tag resolution is handled by schema, here we just complain\n\n      case PlainValue.Char.ANCHOR:\n        if (hasAnchor) {\n          const msg = 'A node can have at most one anchor';\n          errors.push(new PlainValue.YAMLSemanticError(node, msg));\n        }\n\n        hasAnchor = true;\n        break;\n\n      case PlainValue.Char.TAG:\n        if (hasTag) {\n          const msg = 'A node can have at most one tag';\n          errors.push(new PlainValue.YAMLSemanticError(node, msg));\n        }\n\n        hasTag = true;\n        break;\n    }\n  }\n\n  return {\n    comments,\n    hasAnchor,\n    hasTag\n  };\n}\n\nfunction resolveNodeValue(doc, node) {\n  const {\n    anchors,\n    errors,\n    schema\n  } = doc;\n\n  if (node.type === PlainValue.Type.ALIAS) {\n    const name = node.rawValue;\n    const src = anchors.getNode(name);\n\n    if (!src) {\n      const msg = `Aliased anchor not found: ${name}`;\n      errors.push(new PlainValue.YAMLReferenceError(node, msg));\n      return null;\n    } // Lazy resolution for circular references\n\n\n    const res = new Alias(src);\n\n    anchors._cstAliases.push(res);\n\n    return res;\n  }\n\n  const tagName = resolveTagName(doc, node);\n  if (tagName) return resolveTag(doc, node, tagName);\n\n  if (node.type !== PlainValue.Type.PLAIN) {\n    const msg = `Failed to resolve ${node.type} node here`;\n    errors.push(new PlainValue.YAMLSyntaxError(node, msg));\n    return null;\n  }\n\n  try {\n    const str = resolveString(doc, node);\n    return resolveScalar(str, schema.tags, schema.tags.scalarFallback);\n  } catch (error) {\n    if (!error.source) error.source = node;\n    errors.push(error);\n    return null;\n  }\n} // sets node.resolved on success\n\n\nfunction resolveNode(doc, node) {\n  if (!node) return null;\n  if (node.error) doc.errors.push(node.error);\n  const {\n    comments,\n    hasAnchor,\n    hasTag\n  } = resolveNodeProps(doc.errors, node);\n\n  if (hasAnchor) {\n    const {\n      anchors\n    } = doc;\n    const name = node.anchor;\n    const prev = anchors.getNode(name); // At this point, aliases for any preceding node with the same anchor\n    // name have already been resolved, so it may safely be renamed.\n\n    if (prev) anchors.map[anchors.newName(name)] = prev; // During parsing, we need to store the CST node in anchors.map as\n    // anchors need to be available during resolution to allow for\n    // circular references.\n\n    anchors.map[name] = node;\n  }\n\n  if (node.type === PlainValue.Type.ALIAS && (hasAnchor || hasTag)) {\n    const msg = 'An alias node must not specify any properties';\n    doc.errors.push(new PlainValue.YAMLSemanticError(node, msg));\n  }\n\n  const res = resolveNodeValue(doc, node);\n\n  if (res) {\n    res.range = [node.range.start, node.range.end];\n    if (doc.options.keepCstNodes) res.cstNode = node;\n    if (doc.options.keepNodeTypes) res.type = node.type;\n    const cb = comments.before.join('\\n');\n\n    if (cb) {\n      res.commentBefore = res.commentBefore ? `${res.commentBefore}\\n${cb}` : cb;\n    }\n\n    const ca = comments.after.join('\\n');\n    if (ca) res.comment = res.comment ? `${res.comment}\\n${ca}` : ca;\n  }\n\n  return node.resolved = res;\n}\n\nfunction resolveMap(doc, cst) {\n  if (cst.type !== PlainValue.Type.MAP && cst.type !== PlainValue.Type.FLOW_MAP) {\n    const msg = `A ${cst.type} node cannot be resolved as a mapping`;\n    doc.errors.push(new PlainValue.YAMLSyntaxError(cst, msg));\n    return null;\n  }\n\n  const {\n    comments,\n    items\n  } = cst.type === PlainValue.Type.FLOW_MAP ? resolveFlowMapItems(doc, cst) : resolveBlockMapItems(doc, cst);\n  const map = new YAMLMap();\n  map.items = items;\n  resolveComments(map, comments);\n  let hasCollectionKey = false;\n\n  for (let i = 0; i < items.length; ++i) {\n    const {\n      key: iKey\n    } = items[i];\n    if (iKey instanceof Collection) hasCollectionKey = true;\n\n    if (doc.schema.merge && iKey && iKey.value === MERGE_KEY) {\n      items[i] = new Merge(items[i]);\n      const sources = items[i].value.items;\n      let error = null;\n      sources.some(node => {\n        if (node instanceof Alias) {\n          // During parsing, alias sources are CST nodes; to account for\n          // circular references their resolved values can't be used here.\n          const {\n            type\n          } = node.source;\n          if (type === PlainValue.Type.MAP || type === PlainValue.Type.FLOW_MAP) return false;\n          return error = 'Merge nodes aliases can only point to maps';\n        }\n\n        return error = 'Merge nodes can only have Alias nodes as values';\n      });\n      if (error) doc.errors.push(new PlainValue.YAMLSemanticError(cst, error));\n    } else {\n      for (let j = i + 1; j < items.length; ++j) {\n        const {\n          key: jKey\n        } = items[j];\n\n        if (iKey === jKey || iKey && jKey && Object.prototype.hasOwnProperty.call(iKey, 'value') && iKey.value === jKey.value) {\n          const msg = `Map keys must be unique; \"${iKey}\" is repeated`;\n          doc.errors.push(new PlainValue.YAMLSemanticError(cst, msg));\n          break;\n        }\n      }\n    }\n  }\n\n  if (hasCollectionKey && !doc.options.mapAsMap) {\n    const warn = 'Keys with collection values will be stringified as YAML due to JS Object restrictions. Use mapAsMap: true to avoid this.';\n    doc.warnings.push(new PlainValue.YAMLWarning(cst, warn));\n  }\n\n  cst.resolved = map;\n  return map;\n}\n\nconst valueHasPairComment = ({\n  context: {\n    lineStart,\n    node,\n    src\n  },\n  props\n}) => {\n  if (props.length === 0) return false;\n  const {\n    start\n  } = props[0];\n  if (node && start > node.valueRange.start) return false;\n  if (src[start] !== PlainValue.Char.COMMENT) return false;\n\n  for (let i = lineStart; i < start; ++i) if (src[i] === '\\n') return false;\n\n  return true;\n};\n\nfunction resolvePairComment(item, pair) {\n  if (!valueHasPairComment(item)) return;\n  const comment = item.getPropValue(0, PlainValue.Char.COMMENT, true);\n  let found = false;\n  const cb = pair.value.commentBefore;\n\n  if (cb && cb.startsWith(comment)) {\n    pair.value.commentBefore = cb.substr(comment.length + 1);\n    found = true;\n  } else {\n    const cc = pair.value.comment;\n\n    if (!item.node && cc && cc.startsWith(comment)) {\n      pair.value.comment = cc.substr(comment.length + 1);\n      found = true;\n    }\n  }\n\n  if (found) pair.comment = comment;\n}\n\nfunction resolveBlockMapItems(doc, cst) {\n  const comments = [];\n  const items = [];\n  let key = undefined;\n  let keyStart = null;\n\n  for (let i = 0; i < cst.items.length; ++i) {\n    const item = cst.items[i];\n\n    switch (item.type) {\n      case PlainValue.Type.BLANK_LINE:\n        comments.push({\n          afterKey: !!key,\n          before: items.length\n        });\n        break;\n\n      case PlainValue.Type.COMMENT:\n        comments.push({\n          afterKey: !!key,\n          before: items.length,\n          comment: item.comment\n        });\n        break;\n\n      case PlainValue.Type.MAP_KEY:\n        if (key !== undefined) items.push(new Pair(key));\n        if (item.error) doc.errors.push(item.error);\n        key = resolveNode(doc, item.node);\n        keyStart = null;\n        break;\n\n      case PlainValue.Type.MAP_VALUE:\n        {\n          if (key === undefined) key = null;\n          if (item.error) doc.errors.push(item.error);\n\n          if (!item.context.atLineStart && item.node && item.node.type === PlainValue.Type.MAP && !item.node.context.atLineStart) {\n            const msg = 'Nested mappings are not allowed in compact mappings';\n            doc.errors.push(new PlainValue.YAMLSemanticError(item.node, msg));\n          }\n\n          let valueNode = item.node;\n\n          if (!valueNode && item.props.length > 0) {\n            // Comments on an empty mapping value need to be preserved, so we\n            // need to construct a minimal empty node here to use instead of the\n            // missing `item.node`. -- eemeli/yaml#19\n            valueNode = new PlainValue.PlainValue(PlainValue.Type.PLAIN, []);\n            valueNode.context = {\n              parent: item,\n              src: item.context.src\n            };\n            const pos = item.range.start + 1;\n            valueNode.range = {\n              start: pos,\n              end: pos\n            };\n            valueNode.valueRange = {\n              start: pos,\n              end: pos\n            };\n\n            if (typeof item.range.origStart === 'number') {\n              const origPos = item.range.origStart + 1;\n              valueNode.range.origStart = valueNode.range.origEnd = origPos;\n              valueNode.valueRange.origStart = valueNode.valueRange.origEnd = origPos;\n            }\n          }\n\n          const pair = new Pair(key, resolveNode(doc, valueNode));\n          resolvePairComment(item, pair);\n          items.push(pair);\n\n          if (key && typeof keyStart === 'number') {\n            if (item.range.start > keyStart + 1024) doc.errors.push(getLongKeyError(cst, key));\n          }\n\n          key = undefined;\n          keyStart = null;\n        }\n        break;\n\n      default:\n        if (key !== undefined) items.push(new Pair(key));\n        key = resolveNode(doc, item);\n        keyStart = item.range.start;\n        if (item.error) doc.errors.push(item.error);\n\n        next: for (let j = i + 1;; ++j) {\n          const nextItem = cst.items[j];\n\n          switch (nextItem && nextItem.type) {\n            case PlainValue.Type.BLANK_LINE:\n            case PlainValue.Type.COMMENT:\n              continue next;\n\n            case PlainValue.Type.MAP_VALUE:\n              break next;\n\n            default:\n              {\n                const msg = 'Implicit map keys need to be followed by map values';\n                doc.errors.push(new PlainValue.YAMLSemanticError(item, msg));\n                break next;\n              }\n          }\n        }\n\n        if (item.valueRangeContainsNewline) {\n          const msg = 'Implicit map keys need to be on a single line';\n          doc.errors.push(new PlainValue.YAMLSemanticError(item, msg));\n        }\n\n    }\n  }\n\n  if (key !== undefined) items.push(new Pair(key));\n  return {\n    comments,\n    items\n  };\n}\n\nfunction resolveFlowMapItems(doc, cst) {\n  const comments = [];\n  const items = [];\n  let key = undefined;\n  let explicitKey = false;\n  let next = '{';\n\n  for (let i = 0; i < cst.items.length; ++i) {\n    const item = cst.items[i];\n\n    if (typeof item.char === 'string') {\n      const {\n        char,\n        offset\n      } = item;\n\n      if (char === '?' && key === undefined && !explicitKey) {\n        explicitKey = true;\n        next = ':';\n        continue;\n      }\n\n      if (char === ':') {\n        if (key === undefined) key = null;\n\n        if (next === ':') {\n          next = ',';\n          continue;\n        }\n      } else {\n        if (explicitKey) {\n          if (key === undefined && char !== ',') key = null;\n          explicitKey = false;\n        }\n\n        if (key !== undefined) {\n          items.push(new Pair(key));\n          key = undefined;\n\n          if (char === ',') {\n            next = ':';\n            continue;\n          }\n        }\n      }\n\n      if (char === '}') {\n        if (i === cst.items.length - 1) continue;\n      } else if (char === next) {\n        next = ':';\n        continue;\n      }\n\n      const msg = `Flow map contains an unexpected ${char}`;\n      const err = new PlainValue.YAMLSyntaxError(cst, msg);\n      err.offset = offset;\n      doc.errors.push(err);\n    } else if (item.type === PlainValue.Type.BLANK_LINE) {\n      comments.push({\n        afterKey: !!key,\n        before: items.length\n      });\n    } else if (item.type === PlainValue.Type.COMMENT) {\n      checkFlowCommentSpace(doc.errors, item);\n      comments.push({\n        afterKey: !!key,\n        before: items.length,\n        comment: item.comment\n      });\n    } else if (key === undefined) {\n      if (next === ',') doc.errors.push(new PlainValue.YAMLSemanticError(item, 'Separator , missing in flow map'));\n      key = resolveNode(doc, item);\n    } else {\n      if (next !== ',') doc.errors.push(new PlainValue.YAMLSemanticError(item, 'Indicator : missing in flow map entry'));\n      items.push(new Pair(key, resolveNode(doc, item)));\n      key = undefined;\n      explicitKey = false;\n    }\n  }\n\n  checkFlowCollectionEnd(doc.errors, cst);\n  if (key !== undefined) items.push(new Pair(key));\n  return {\n    comments,\n    items\n  };\n}\n\nfunction resolveSeq(doc, cst) {\n  if (cst.type !== PlainValue.Type.SEQ && cst.type !== PlainValue.Type.FLOW_SEQ) {\n    const msg = `A ${cst.type} node cannot be resolved as a sequence`;\n    doc.errors.push(new PlainValue.YAMLSyntaxError(cst, msg));\n    return null;\n  }\n\n  const {\n    comments,\n    items\n  } = cst.type === PlainValue.Type.FLOW_SEQ ? resolveFlowSeqItems(doc, cst) : resolveBlockSeqItems(doc, cst);\n  const seq = new YAMLSeq();\n  seq.items = items;\n  resolveComments(seq, comments);\n\n  if (!doc.options.mapAsMap && items.some(it => it instanceof Pair && it.key instanceof Collection)) {\n    const warn = 'Keys with collection values will be stringified as YAML due to JS Object restrictions. Use mapAsMap: true to avoid this.';\n    doc.warnings.push(new PlainValue.YAMLWarning(cst, warn));\n  }\n\n  cst.resolved = seq;\n  return seq;\n}\n\nfunction resolveBlockSeqItems(doc, cst) {\n  const comments = [];\n  const items = [];\n\n  for (let i = 0; i < cst.items.length; ++i) {\n    const item = cst.items[i];\n\n    switch (item.type) {\n      case PlainValue.Type.BLANK_LINE:\n        comments.push({\n          before: items.length\n        });\n        break;\n\n      case PlainValue.Type.COMMENT:\n        comments.push({\n          comment: item.comment,\n          before: items.length\n        });\n        break;\n\n      case PlainValue.Type.SEQ_ITEM:\n        if (item.error) doc.errors.push(item.error);\n        items.push(resolveNode(doc, item.node));\n\n        if (item.hasProps) {\n          const msg = 'Sequence items cannot have tags or anchors before the - indicator';\n          doc.errors.push(new PlainValue.YAMLSemanticError(item, msg));\n        }\n\n        break;\n\n      default:\n        if (item.error) doc.errors.push(item.error);\n        doc.errors.push(new PlainValue.YAMLSyntaxError(item, `Unexpected ${item.type} node in sequence`));\n    }\n  }\n\n  return {\n    comments,\n    items\n  };\n}\n\nfunction resolveFlowSeqItems(doc, cst) {\n  const comments = [];\n  const items = [];\n  let explicitKey = false;\n  let key = undefined;\n  let keyStart = null;\n  let next = '[';\n  let prevItem = null;\n\n  for (let i = 0; i < cst.items.length; ++i) {\n    const item = cst.items[i];\n\n    if (typeof item.char === 'string') {\n      const {\n        char,\n        offset\n      } = item;\n\n      if (char !== ':' && (explicitKey || key !== undefined)) {\n        if (explicitKey && key === undefined) key = next ? items.pop() : null;\n        items.push(new Pair(key));\n        explicitKey = false;\n        key = undefined;\n        keyStart = null;\n      }\n\n      if (char === next) {\n        next = null;\n      } else if (!next && char === '?') {\n        explicitKey = true;\n      } else if (next !== '[' && char === ':' && key === undefined) {\n        if (next === ',') {\n          key = items.pop();\n\n          if (key instanceof Pair) {\n            const msg = 'Chaining flow sequence pairs is invalid';\n            const err = new PlainValue.YAMLSemanticError(cst, msg);\n            err.offset = offset;\n            doc.errors.push(err);\n          }\n\n          if (!explicitKey && typeof keyStart === 'number') {\n            const keyEnd = item.range ? item.range.start : item.offset;\n            if (keyEnd > keyStart + 1024) doc.errors.push(getLongKeyError(cst, key));\n            const {\n              src\n            } = prevItem.context;\n\n            for (let i = keyStart; i < keyEnd; ++i) if (src[i] === '\\n') {\n              const msg = 'Implicit keys of flow sequence pairs need to be on a single line';\n              doc.errors.push(new PlainValue.YAMLSemanticError(prevItem, msg));\n              break;\n            }\n          }\n        } else {\n          key = null;\n        }\n\n        keyStart = null;\n        explicitKey = false;\n        next = null;\n      } else if (next === '[' || char !== ']' || i < cst.items.length - 1) {\n        const msg = `Flow sequence contains an unexpected ${char}`;\n        const err = new PlainValue.YAMLSyntaxError(cst, msg);\n        err.offset = offset;\n        doc.errors.push(err);\n      }\n    } else if (item.type === PlainValue.Type.BLANK_LINE) {\n      comments.push({\n        before: items.length\n      });\n    } else if (item.type === PlainValue.Type.COMMENT) {\n      checkFlowCommentSpace(doc.errors, item);\n      comments.push({\n        comment: item.comment,\n        before: items.length\n      });\n    } else {\n      if (next) {\n        const msg = `Expected a ${next} in flow sequence`;\n        doc.errors.push(new PlainValue.YAMLSemanticError(item, msg));\n      }\n\n      const value = resolveNode(doc, item);\n\n      if (key === undefined) {\n        items.push(value);\n        prevItem = item;\n      } else {\n        items.push(new Pair(key, value));\n        key = undefined;\n      }\n\n      keyStart = item.range.start;\n      next = ',';\n    }\n  }\n\n  checkFlowCollectionEnd(doc.errors, cst);\n  if (key !== undefined) items.push(new Pair(key));\n  return {\n    comments,\n    items\n  };\n}\n\nexports.Alias = Alias;\nexports.Collection = Collection;\nexports.Merge = Merge;\nexports.Node = Node;\nexports.Pair = Pair;\nexports.Scalar = Scalar;\nexports.YAMLMap = YAMLMap;\nexports.YAMLSeq = YAMLSeq;\nexports.addComment = addComment;\nexports.binaryOptions = binaryOptions;\nexports.boolOptions = boolOptions;\nexports.findPair = findPair;\nexports.intOptions = intOptions;\nexports.isEmptyPath = isEmptyPath;\nexports.nullOptions = nullOptions;\nexports.resolveMap = resolveMap;\nexports.resolveNode = resolveNode;\nexports.resolveSeq = resolveSeq;\nexports.resolveString = resolveString;\nexports.strOptions = strOptions;\nexports.stringifyNumber = stringifyNumber;\nexports.stringifyString = stringifyString;\nexports.toJSON = toJSON;\n","'use strict';\n\nvar PlainValue = require('./PlainValue-ec8e588e.js');\nvar resolveSeq = require('./resolveSeq-4a68b39b.js');\n\n/* global atob, btoa, Buffer */\nconst binary = {\n  identify: value => value instanceof Uint8Array,\n  // Buffer inherits from Uint8Array\n  default: false,\n  tag: 'tag:yaml.org,2002:binary',\n\n  /**\n   * Returns a Buffer in node and an Uint8Array in browsers\n   *\n   * To use the resulting buffer as an image, you'll want to do something like:\n   *\n   *   const blob = new Blob([buffer], { type: 'image/jpeg' })\n   *   document.querySelector('#photo').src = URL.createObjectURL(blob)\n   */\n  resolve: (doc, node) => {\n    const src = resolveSeq.resolveString(doc, node);\n\n    if (typeof Buffer === 'function') {\n      return Buffer.from(src, 'base64');\n    } else if (typeof atob === 'function') {\n      // On IE 11, atob() can't handle newlines\n      const str = atob(src.replace(/[\\n\\r]/g, ''));\n      const buffer = new Uint8Array(str.length);\n\n      for (let i = 0; i < str.length; ++i) buffer[i] = str.charCodeAt(i);\n\n      return buffer;\n    } else {\n      const msg = 'This environment does not support reading binary tags; either Buffer or atob is required';\n      doc.errors.push(new PlainValue.YAMLReferenceError(node, msg));\n      return null;\n    }\n  },\n  options: resolveSeq.binaryOptions,\n  stringify: ({\n    comment,\n    type,\n    value\n  }, ctx, onComment, onChompKeep) => {\n    let src;\n\n    if (typeof Buffer === 'function') {\n      src = value instanceof Buffer ? value.toString('base64') : Buffer.from(value.buffer).toString('base64');\n    } else if (typeof btoa === 'function') {\n      let s = '';\n\n      for (let i = 0; i < value.length; ++i) s += String.fromCharCode(value[i]);\n\n      src = btoa(s);\n    } else {\n      throw new Error('This environment does not support writing binary tags; either Buffer or btoa is required');\n    }\n\n    if (!type) type = resolveSeq.binaryOptions.defaultType;\n\n    if (type === PlainValue.Type.QUOTE_DOUBLE) {\n      value = src;\n    } else {\n      const {\n        lineWidth\n      } = resolveSeq.binaryOptions;\n      const n = Math.ceil(src.length / lineWidth);\n      const lines = new Array(n);\n\n      for (let i = 0, o = 0; i < n; ++i, o += lineWidth) {\n        lines[i] = src.substr(o, lineWidth);\n      }\n\n      value = lines.join(type === PlainValue.Type.BLOCK_LITERAL ? '\\n' : ' ');\n    }\n\n    return resolveSeq.stringifyString({\n      comment,\n      type,\n      value\n    }, ctx, onComment, onChompKeep);\n  }\n};\n\nfunction parsePairs(doc, cst) {\n  const seq = resolveSeq.resolveSeq(doc, cst);\n\n  for (let i = 0; i < seq.items.length; ++i) {\n    let item = seq.items[i];\n    if (item instanceof resolveSeq.Pair) continue;else if (item instanceof resolveSeq.YAMLMap) {\n      if (item.items.length > 1) {\n        const msg = 'Each pair must have its own sequence indicator';\n        throw new PlainValue.YAMLSemanticError(cst, msg);\n      }\n\n      const pair = item.items[0] || new resolveSeq.Pair();\n      if (item.commentBefore) pair.commentBefore = pair.commentBefore ? `${item.commentBefore}\\n${pair.commentBefore}` : item.commentBefore;\n      if (item.comment) pair.comment = pair.comment ? `${item.comment}\\n${pair.comment}` : item.comment;\n      item = pair;\n    }\n    seq.items[i] = item instanceof resolveSeq.Pair ? item : new resolveSeq.Pair(item);\n  }\n\n  return seq;\n}\nfunction createPairs(schema, iterable, ctx) {\n  const pairs = new resolveSeq.YAMLSeq(schema);\n  pairs.tag = 'tag:yaml.org,2002:pairs';\n\n  for (const it of iterable) {\n    let key, value;\n\n    if (Array.isArray(it)) {\n      if (it.length === 2) {\n        key = it[0];\n        value = it[1];\n      } else throw new TypeError(`Expected [key, value] tuple: ${it}`);\n    } else if (it && it instanceof Object) {\n      const keys = Object.keys(it);\n\n      if (keys.length === 1) {\n        key = keys[0];\n        value = it[key];\n      } else throw new TypeError(`Expected { key: value } tuple: ${it}`);\n    } else {\n      key = it;\n    }\n\n    const pair = schema.createPair(key, value, ctx);\n    pairs.items.push(pair);\n  }\n\n  return pairs;\n}\nconst pairs = {\n  default: false,\n  tag: 'tag:yaml.org,2002:pairs',\n  resolve: parsePairs,\n  createNode: createPairs\n};\n\nclass YAMLOMap extends resolveSeq.YAMLSeq {\n  constructor() {\n    super();\n\n    PlainValue._defineProperty(this, \"add\", resolveSeq.YAMLMap.prototype.add.bind(this));\n\n    PlainValue._defineProperty(this, \"delete\", resolveSeq.YAMLMap.prototype.delete.bind(this));\n\n    PlainValue._defineProperty(this, \"get\", resolveSeq.YAMLMap.prototype.get.bind(this));\n\n    PlainValue._defineProperty(this, \"has\", resolveSeq.YAMLMap.prototype.has.bind(this));\n\n    PlainValue._defineProperty(this, \"set\", resolveSeq.YAMLMap.prototype.set.bind(this));\n\n    this.tag = YAMLOMap.tag;\n  }\n\n  toJSON(_, ctx) {\n    const map = new Map();\n    if (ctx && ctx.onCreate) ctx.onCreate(map);\n\n    for (const pair of this.items) {\n      let key, value;\n\n      if (pair instanceof resolveSeq.Pair) {\n        key = resolveSeq.toJSON(pair.key, '', ctx);\n        value = resolveSeq.toJSON(pair.value, key, ctx);\n      } else {\n        key = resolveSeq.toJSON(pair, '', ctx);\n      }\n\n      if (map.has(key)) throw new Error('Ordered maps must not include duplicate keys');\n      map.set(key, value);\n    }\n\n    return map;\n  }\n\n}\n\nPlainValue._defineProperty(YAMLOMap, \"tag\", 'tag:yaml.org,2002:omap');\n\nfunction parseOMap(doc, cst) {\n  const pairs = parsePairs(doc, cst);\n  const seenKeys = [];\n\n  for (const {\n    key\n  } of pairs.items) {\n    if (key instanceof resolveSeq.Scalar) {\n      if (seenKeys.includes(key.value)) {\n        const msg = 'Ordered maps must not include duplicate keys';\n        throw new PlainValue.YAMLSemanticError(cst, msg);\n      } else {\n        seenKeys.push(key.value);\n      }\n    }\n  }\n\n  return Object.assign(new YAMLOMap(), pairs);\n}\n\nfunction createOMap(schema, iterable, ctx) {\n  const pairs = createPairs(schema, iterable, ctx);\n  const omap = new YAMLOMap();\n  omap.items = pairs.items;\n  return omap;\n}\n\nconst omap = {\n  identify: value => value instanceof Map,\n  nodeClass: YAMLOMap,\n  default: false,\n  tag: 'tag:yaml.org,2002:omap',\n  resolve: parseOMap,\n  createNode: createOMap\n};\n\nclass YAMLSet extends resolveSeq.YAMLMap {\n  constructor() {\n    super();\n    this.tag = YAMLSet.tag;\n  }\n\n  add(key) {\n    const pair = key instanceof resolveSeq.Pair ? key : new resolveSeq.Pair(key);\n    const prev = resolveSeq.findPair(this.items, pair.key);\n    if (!prev) this.items.push(pair);\n  }\n\n  get(key, keepPair) {\n    const pair = resolveSeq.findPair(this.items, key);\n    return !keepPair && pair instanceof resolveSeq.Pair ? pair.key instanceof resolveSeq.Scalar ? pair.key.value : pair.key : pair;\n  }\n\n  set(key, value) {\n    if (typeof value !== 'boolean') throw new Error(`Expected boolean value for set(key, value) in a YAML set, not ${typeof value}`);\n    const prev = resolveSeq.findPair(this.items, key);\n\n    if (prev && !value) {\n      this.items.splice(this.items.indexOf(prev), 1);\n    } else if (!prev && value) {\n      this.items.push(new resolveSeq.Pair(key));\n    }\n  }\n\n  toJSON(_, ctx) {\n    return super.toJSON(_, ctx, Set);\n  }\n\n  toString(ctx, onComment, onChompKeep) {\n    if (!ctx) return JSON.stringify(this);\n    if (this.hasAllNullValues()) return super.toString(ctx, onComment, onChompKeep);else throw new Error('Set items must all have null values');\n  }\n\n}\n\nPlainValue._defineProperty(YAMLSet, \"tag\", 'tag:yaml.org,2002:set');\n\nfunction parseSet(doc, cst) {\n  const map = resolveSeq.resolveMap(doc, cst);\n  if (!map.hasAllNullValues()) throw new PlainValue.YAMLSemanticError(cst, 'Set items must all have null values');\n  return Object.assign(new YAMLSet(), map);\n}\n\nfunction createSet(schema, iterable, ctx) {\n  const set = new YAMLSet();\n\n  for (const value of iterable) set.items.push(schema.createPair(value, null, ctx));\n\n  return set;\n}\n\nconst set = {\n  identify: value => value instanceof Set,\n  nodeClass: YAMLSet,\n  default: false,\n  tag: 'tag:yaml.org,2002:set',\n  resolve: parseSet,\n  createNode: createSet\n};\n\nconst parseSexagesimal = (sign, parts) => {\n  const n = parts.split(':').reduce((n, p) => n * 60 + Number(p), 0);\n  return sign === '-' ? -n : n;\n}; // hhhh:mm:ss.sss\n\n\nconst stringifySexagesimal = ({\n  value\n}) => {\n  if (isNaN(value) || !isFinite(value)) return resolveSeq.stringifyNumber(value);\n  let sign = '';\n\n  if (value < 0) {\n    sign = '-';\n    value = Math.abs(value);\n  }\n\n  const parts = [value % 60]; // seconds, including ms\n\n  if (value < 60) {\n    parts.unshift(0); // at least one : is required\n  } else {\n    value = Math.round((value - parts[0]) / 60);\n    parts.unshift(value % 60); // minutes\n\n    if (value >= 60) {\n      value = Math.round((value - parts[0]) / 60);\n      parts.unshift(value); // hours\n    }\n  }\n\n  return sign + parts.map(n => n < 10 ? '0' + String(n) : String(n)).join(':').replace(/000000\\d*$/, '') // % 60 may introduce error\n  ;\n};\n\nconst intTime = {\n  identify: value => typeof value === 'number',\n  default: true,\n  tag: 'tag:yaml.org,2002:int',\n  format: 'TIME',\n  test: /^([-+]?)([0-9][0-9_]*(?::[0-5]?[0-9])+)$/,\n  resolve: (str, sign, parts) => parseSexagesimal(sign, parts.replace(/_/g, '')),\n  stringify: stringifySexagesimal\n};\nconst floatTime = {\n  identify: value => typeof value === 'number',\n  default: true,\n  tag: 'tag:yaml.org,2002:float',\n  format: 'TIME',\n  test: /^([-+]?)([0-9][0-9_]*(?::[0-5]?[0-9])+\\.[0-9_]*)$/,\n  resolve: (str, sign, parts) => parseSexagesimal(sign, parts.replace(/_/g, '')),\n  stringify: stringifySexagesimal\n};\nconst timestamp = {\n  identify: value => value instanceof Date,\n  default: true,\n  tag: 'tag:yaml.org,2002:timestamp',\n  // If the time zone is omitted, the timestamp is assumed to be specified in UTC. The time part\n  // may be omitted altogether, resulting in a date format. In such a case, the time part is\n  // assumed to be 00:00:00Z (start of day, UTC).\n  test: RegExp('^(?:' + '([0-9]{4})-([0-9]{1,2})-([0-9]{1,2})' + // YYYY-Mm-Dd\n  '(?:(?:t|T|[ \\\\t]+)' + // t | T | whitespace\n  '([0-9]{1,2}):([0-9]{1,2}):([0-9]{1,2}(\\\\.[0-9]+)?)' + // Hh:Mm:Ss(.ss)?\n  '(?:[ \\\\t]*(Z|[-+][012]?[0-9](?::[0-9]{2})?))?' + // Z | +5 | -03:30\n  ')?' + ')$'),\n  resolve: (str, year, month, day, hour, minute, second, millisec, tz) => {\n    if (millisec) millisec = (millisec + '00').substr(1, 3);\n    let date = Date.UTC(year, month - 1, day, hour || 0, minute || 0, second || 0, millisec || 0);\n\n    if (tz && tz !== 'Z') {\n      let d = parseSexagesimal(tz[0], tz.slice(1));\n      if (Math.abs(d) < 30) d *= 60;\n      date -= 60000 * d;\n    }\n\n    return new Date(date);\n  },\n  stringify: ({\n    value\n  }) => value.toISOString().replace(/((T00:00)?:00)?\\.000Z$/, '')\n};\n\n/* global console, process, YAML_SILENCE_DEPRECATION_WARNINGS, YAML_SILENCE_WARNINGS */\nfunction shouldWarn(deprecation) {\n  const env = typeof process !== 'undefined' && process.env || {};\n\n  if (deprecation) {\n    if (typeof YAML_SILENCE_DEPRECATION_WARNINGS !== 'undefined') return !YAML_SILENCE_DEPRECATION_WARNINGS;\n    return !env.YAML_SILENCE_DEPRECATION_WARNINGS;\n  }\n\n  if (typeof YAML_SILENCE_WARNINGS !== 'undefined') return !YAML_SILENCE_WARNINGS;\n  return !env.YAML_SILENCE_WARNINGS;\n}\n\nfunction warn(warning, type) {\n  if (shouldWarn(false)) {\n    const emit = typeof process !== 'undefined' && process.emitWarning; // This will throw in Jest if `warning` is an Error instance due to\n    // https://github.com/facebook/jest/issues/2549\n\n    if (emit) emit(warning, type);else {\n      // eslint-disable-next-line no-console\n      console.warn(type ? `${type}: ${warning}` : warning);\n    }\n  }\n}\nfunction warnFileDeprecation(filename) {\n  if (shouldWarn(true)) {\n    const path = filename.replace(/.*yaml[/\\\\]/i, '').replace(/\\.js$/, '').replace(/\\\\/g, '/');\n    warn(`The endpoint 'yaml/${path}' will be removed in a future release.`, 'DeprecationWarning');\n  }\n}\nconst warned = {};\nfunction warnOptionDeprecation(name, alternative) {\n  if (!warned[name] && shouldWarn(true)) {\n    warned[name] = true;\n    let msg = `The option '${name}' will be removed in a future release`;\n    msg += alternative ? `, use '${alternative}' instead.` : '.';\n    warn(msg, 'DeprecationWarning');\n  }\n}\n\nexports.binary = binary;\nexports.floatTime = floatTime;\nexports.intTime = intTime;\nexports.omap = omap;\nexports.pairs = pairs;\nexports.set = set;\nexports.timestamp = timestamp;\nexports.warn = warn;\nexports.warnFileDeprecation = warnFileDeprecation;\nexports.warnOptionDeprecation = warnOptionDeprecation;\n","module.exports = require('./dist').YAML\n","'use strict'\n\nmodule.exports = factory\n\nvar noop = Function.prototype\nvar own = {}.hasOwnProperty\n\n// Handle values based on a property.\nfunction factory(key, options) {\n  var settings = options || {}\n\n  function one(value) {\n    var fn = one.invalid\n    var handlers = one.handlers\n\n    if (value && own.call(value, key)) {\n      fn = own.call(handlers, value[key]) ? handlers[value[key]] : one.unknown\n    }\n\n    return (fn || noop).apply(this, arguments)\n  }\n\n  one.handlers = settings.handlers || {}\n  one.invalid = settings.invalid\n  one.unknown = settings.unknown\n\n  return one\n}\n",null,"module.exports = require(\"assert\");;","module.exports = require(\"events\");;","module.exports = require(\"fs\");;","module.exports = require(\"http\");;","module.exports = require(\"https\");;","module.exports = require(\"net\");;","module.exports = require(\"os\");;","module.exports = require(\"path\");;","module.exports = require(\"stream\");;","module.exports = require(\"tls\");;","module.exports = require(\"url\");;","module.exports = require(\"util\");;","module.exports = require(\"zlib\");;","// The module cache\nvar __webpack_module_cache__ = {};\n\n// The require function\nfunction __webpack_require__(moduleId) {\n\t// Check if module is in cache\n\tif(__webpack_module_cache__[moduleId]) {\n\t\treturn __webpack_module_cache__[moduleId].exports;\n\t}\n\t// Create a new module (and put it into the cache)\n\tvar module = __webpack_module_cache__[moduleId] = {\n\t\t// no module.id needed\n\t\t// no module.loaded needed\n\t\texports: {}\n\t};\n\n\t// Execute the module function\n\tvar threw = true;\n\ttry {\n\t\t__webpack_modules__[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\t\tthrew = false;\n\t} finally {\n\t\tif(threw) delete __webpack_module_cache__[moduleId];\n\t}\n\n\t// Return the exports of the module\n\treturn module.exports;\n}\n\n","\n__webpack_require__.ab = __dirname + \"/\";","// module exports must be returned from runtime so entry inlining is disabled\n// startup\n// Load entry module and return exports\nreturn __webpack_require__(3109);\n"],"mappings":";;;;;;;;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACVA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACtGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;AC9EA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACnEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;AC/EA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;AC9OA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;AC7BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACnBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;AClDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACpCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;AC3CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACtDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACxhBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;AC1DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;AClDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;AC/KA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACvYA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACvCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;AC7GA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACrIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACnpCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACxDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACrJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACvCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;ACVA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;AC1DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;AC/CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;AC5BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACpBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACrBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACtHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;AChCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACjIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACXA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACrCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACxzBA;AACA;AACA;AACA;AACA;A;;;;;ACJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;ACzCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;AC/CA;AACA;AACA;A;;;;;ACFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;AC5BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;AChBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;ACrBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;ACjEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;AC/CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;ACtBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;ACjDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;ACXA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;ACtCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;ACtDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;ACrBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;ACtEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;ACvCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;ACvEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;AChDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;ACXA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;ACbA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;ACRA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;ACtBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;ACRA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;ACfA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;AC1EA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;ACtCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;AC/GA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;AC/BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;AChBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;AChBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;AChBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;ACpBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;AChBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;AChBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;AChBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;AChBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;AChDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;AC1DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;ACfA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;ACVA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;AC3BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;AC1BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;AC1BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;AC/BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;AC5IA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;AC9BA;AACA;AACA;A;;;;;ACFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;ACpDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACxKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACRA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACRA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACRA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACbA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACRA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACRA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACRA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACRA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACRA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACRA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACXA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACRA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACNA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACNA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACtEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACPA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACZA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;AChIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACtEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;AC9OA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;AC7DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;AC1MA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACrCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACdA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACxFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;AC3LA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;AC9HA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACpEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACnCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;AC/FA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACjLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACzEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACnKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACpGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACpHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACpIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACzFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;AC/BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;AC5EA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACjCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;AChCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;AClIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACveA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACpbA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;AC3UA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;AC/CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACpCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACtBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACvNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACpBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACtHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACtDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACfA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACvCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;AC1BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;AClDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;AC7TA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACZA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACbA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACnBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACZA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACdA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACrBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;AC3BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACzCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACVA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACjBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;AC5BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACxMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;AClnDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;AC3CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACdA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACpBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACzBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACxBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACvEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;AC3EA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;ACjEA;AACA;AACA;A;;;;;;ACFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACzQA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;ACzcA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACZA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;AC9EA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;ACnDA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;AC9FA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;AC9BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACnBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;AC/FA;AACA;AACA;AACA;AACA;A;;;;;;ACJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;AC9KA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;AC/CA;AACA;AACA;AACA;AACA;A;;;;;;ACJA;AACA;AACA;AACA;AACA;A;;;;;ACJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;ACZA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;AClCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACtvBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;AC72BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;AC3gBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;AChFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACptDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACpkEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;ACjaA;AACA;AACA;A;;;;;;ACFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;AC7BA;AACA;AACA;A;;;;;;;;A;;;;;;ACFA;AACA;A;;;;;;ACDA;AACA;A;;;;;;ACDA;AACA;A;;;;;;ACDA;AACA;A;;;;;;ACDA;AACA;A;;;;;;ACDA;AACA;A;;;;;;ACDA;AACA;A;;;;;;ACDA;AACA;A;;;;;;ACDA;AACA;A;;;;;;ACDA;AACA;A;;;;;;ACDA;AACA;A;;;;;;ACDA;AACA;A;;;;;;ACDA;AACA;A;;;;ACDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AC5BA;AACA;ACDA;AACA;AACA;AACA;;A","sourceRoot":""}